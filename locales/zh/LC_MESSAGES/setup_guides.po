# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020
# This file is distributed under the same license as the Navigation 2 package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2023.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Navigation 2 latest\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-06-18 21:11+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh\n"
"Language-Team: zh <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.12.1\n"


#: ../../setup_guides/algorithm/select_algorithm.rst:4
msgid "Setting Up Navigation Plugins"
msgstr "Setting Up Navigation Plugins"


#: ../../setup_guides/algorithm/select_algorithm.rst:6
msgid "In this part of the guide, we discuss how your robot can utilize different planner and controller algorithms to complete navigation tasks. We will discuss some of the available algorithm plugins you can use based on your robot type and environment."
msgstr "In this part of the guide, we discuss how your robot can utilize different planner and controller algorithms to complete navigation tasks. We will discuss some of the available algorithm plugins you can use based on your robot type and environment."


#: ../../setup_guides/algorithm/select_algorithm.rst:9
msgid "Planner and Controller Servers"
msgstr "Planner and Controller Servers"


#: ../../setup_guides/algorithm/select_algorithm.rst:10
msgid "Navigation algorithms are implemented in Nav2 through the use of plugins running on ROS action servers - the planner, controller and behavior servers (among others). For this section, we discuss the planner and controller servers, which are the heart of the navigation stack. These servers may implement one or more algorithm plugins each with its own configuration tailored for a specific action or robot state. This guide will highlight the different algorithms based on the type of robot and environment the robot is deployed in. This guide will not cover behaviors, smoothers, etc as those are dependent on application and not hardware/environment to offer generalized advice."
msgstr "Navigation algorithms are implemented in Nav2 through the use of plugins running on ROS action servers - the planner, controller and behavior servers (among others). For this section, we discuss the planner and controller servers, which are the heart of the navigation stack. These servers may implement one or more algorithm plugins each with its own configuration tailored for a specific action or robot state. This guide will highlight the different algorithms based on the type of robot and environment the robot is deployed in. This guide will not cover behaviors, smoothers, etc as those are dependent on application and not hardware/environment to offer generalized advice."


#: ../../setup_guides/algorithm/select_algorithm.rst:12
msgid "The planner server is responsible for implementing algorithms that compute the robot's path. For example, one plugin can be configured to compute a simple shortest path between two relatively near locations while another plugin computes for a path to locations that cover the entire robot environment."
msgstr "The planner server is responsible for implementing algorithms that compute the robot's path. For example, one plugin can be configured to compute a simple shortest path between two relatively near locations while another plugin computes for a path to locations that cover the entire robot environment."


#: ../../setup_guides/algorithm/select_algorithm.rst:14
msgid "The controller server generates the appropriate control efforts needed for a robot to complete a task in its local environment. These tasks include but are not limited to: following a path generated by the planner server, avoiding dynamic obstacles along this path, and even charging at a docking station."
msgstr "The controller server generates the appropriate control efforts needed for a robot to complete a task in its local environment. These tasks include but are not limited to: following a path generated by the planner server, avoiding dynamic obstacles along this path, and even charging at a docking station."


#: ../../setup_guides/algorithm/select_algorithm.rst:16
msgid "As mentioned before, the planner and controller servers host a map of one or multiple plugins wherein a certain plugin will be used for a certain environment, scenario, or task. For instance, the controller server can have a plugin for following a path when in long corridors to stay in the middle of the aisle, and then another plugin for avoiding dynamic obstacles in a crowded place. Selecting which planning algorithm to execute based on the robot's task can be done through the behavior tree of your navigation system or application server."
msgstr "As mentioned before, the planner and controller servers host a map of one or multiple plugins wherein a certain plugin will be used for a certain environment, scenario, or task. For instance, the controller server can have a plugin for following a path when in long corridors to stay in the middle of the aisle, and then another plugin for avoiding dynamic obstacles in a crowded place. Selecting which planning algorithm to execute based on the robot's task can be done through the behavior tree of your navigation system or application server."


#: ../../setup_guides/algorithm/select_algorithm.rst:19
msgid "For a more in-depth discussion on Navigation Servers, we suggest to have a look at the `Navigation Servers <https://navigation.ros.org/concepts/index.html#navigation-servers>`_ section under the Navigation Concepts category."
msgstr "For a more in-depth discussion on Navigation Servers, we suggest to have a look at the `Navigation Servers <https://navigation.ros.org/concepts/index.html#navigation-servers>`_ section under the Navigation Concepts category."


#: ../../setup_guides/algorithm/select_algorithm.rst:22
msgid "Selecting the Algorithm Plugins"
msgstr "Selecting the Algorithm Plugins"


#: ../../setup_guides/algorithm/select_algorithm.rst:24
msgid "In this section, we discuss some of the available algorithm plugins for the planner and controller servers. We also discuss the purpose of each algorithm, and for which type of robot they are recommended to be used. Lastly, we show some sample yaml configuration that specifies the plugin to be used for each server."
msgstr "In this section, we discuss some of the available algorithm plugins for the planner and controller servers. We also discuss the purpose of each algorithm, and for which type of robot they are recommended to be used. Lastly, we show some sample yaml configuration that specifies the plugin to be used for each server."


#: ../../setup_guides/algorithm/select_algorithm.rst:27
msgid "The algorithm plugins you can use are not limited to the ones mentioned in this section. You may create custom plugins as well and new plugins are added to Nav2 regularly. For tutorials on how to write your own plugins, please see `Writing a New Planner Plugin <https://navigation.ros.org/plugin_tutorials/docs/writing_new_nav2planner_plugin.html>`_  and `Writing a New Controller Plugin <https://navigation.ros.org/plugin_tutorials/docs/writing_new_nav2controller_plugin.html>`_. The list of all available Nav2 plugins and their descriptions can be found in `Navigation Plugins Section <https://navigation.ros.org/plugins/index.html>`_."
msgstr "The algorithm plugins you can use are not limited to the ones mentioned in this section. You may create custom plugins as well and new plugins are added to Nav2 regularly. For tutorials on how to write your own plugins, please see `Writing a New Planner Plugin <https://navigation.ros.org/plugin_tutorials/docs/writing_new_nav2planner_plugin.html>`_  and `Writing a New Controller Plugin <https://navigation.ros.org/plugin_tutorials/docs/writing_new_nav2controller_plugin.html>`_. The list of all available Nav2 plugins and their descriptions can be found in `Navigation Plugins Section <https://navigation.ros.org/plugins/index.html>`_."


#: ../../setup_guides/algorithm/select_algorithm.rst:30
msgid "Planner Server"
msgstr "Planner Server"


#: ../../setup_guides/algorithm/select_algorithm.rst:32
msgid "The algorithm plugins for the planner server find the robot's path using a representation of its environment captured by its different sensors. Some of these algorithms operate by searching through the environment's grid space while others expand the robot's possible states while accounting for path feasibility."
msgstr "The algorithm plugins for the planner server find the robot's path using a representation of its environment captured by its different sensors. Some of these algorithms operate by searching through the environment's grid space while others expand the robot's possible states while accounting for path feasibility."


#: ../../setup_guides/algorithm/select_algorithm.rst:34
msgid "As mentioned, the planner server may utilize plugins that work on the grid space such as the ``NavFn Planner``, ``Smac Planner 2D``, and ``Theta Star Planner``. The `NavFn planner <https://navigation.ros.org/configuration/packages/configuring-navfn.html>`_ is a navigation function planner that uses either Dijkstra or A*.  Next, the `Smac 2D planner <https://navigation.ros.org/configuration/packages/configuring-smac-planner.html>`_ implements a 2D A* algorithm using 4 or 8 connected neighborhoods with a smoother and multi-resolution query. Lastly, the `Theta Star planner <https://navigation.ros.org/configuration/packages/configuring-thetastar.html#>`_ is an implementation of Theta* using either line of sight to create non-discretely oriented path segments."
msgstr "As mentioned, the planner server may utilize plugins that work on the grid space such as the ``NavFn Planner``, ``Smac Planner 2D``, and ``Theta Star Planner``. The `NavFn planner <https://navigation.ros.org/configuration/packages/configuring-navfn.html>`_ is a navigation function planner that uses either Dijkstra or A*.  Next, the `Smac 2D planner <https://navigation.ros.org/configuration/packages/configuring-smac-planner.html>`_ implements a 2D A* algorithm using 4 or 8 connected neighborhoods with a smoother and multi-resolution query. Lastly, the `Theta Star planner <https://navigation.ros.org/configuration/packages/configuring-thetastar.html#>`_ is an implementation of Theta* using either line of sight to create non-discretely oriented path segments."


#: ../../setup_guides/algorithm/select_algorithm.rst:36
msgid "One issue you may encounter when using algorithms that work on the grid space is that there is no guarantee that a drivable path can be generated for any type of robot. For example, it is not guaranteed that the ``NavFn Planner`` can plan a feasible path for a non-circular robot in a tight space since it uses the circular footprint of a robot (by approximating the robot's largest cross-sectional radius) and checks for collisions per costmap grid cell. In addition, these algorithms are also not suitable for ackermann and legged robots since they have turning constraints. That being said, these plugins are best used on robots that can drive in any direction or rotate safely in place, such as **circular differential and circular omnidirectional** robots."
msgstr "One issue you may encounter when using algorithms that work on the grid space is that there is no guarantee that a drivable path can be generated for any type of robot. For example, it is not guaranteed that the ``NavFn Planner`` can plan a feasible path for a non-circular robot in a tight space since it uses the circular footprint of a robot (by approximating the robot's largest cross-sectional radius) and checks for collisions per costmap grid cell. In addition, these algorithms are also not suitable for ackermann and legged robots since they have turning constraints. That being said, these plugins are best used on robots that can drive in any direction or rotate safely in place, such as **circular differential and circular omnidirectional** robots."


#: ../../setup_guides/algorithm/select_algorithm.rst:38
msgid "Another planner plugin is the `Smac Hybrid-A* planner <https://navigation.ros.org/configuration/packages/configuring-smac-planner.html>`_ that supports **arbitrary shaped ackermann and legged** robots. It is a highly optimized and fully reconfigurable Hybrid-A* implementation supporting Dubin and Reeds-Shepp motion models. This algorithm expands the robot's candidate paths while considering the robot's minimum turning radius constraint and the robot's full footprint for collision avoidance. Thus, this plugin is suitable for arbitrary shaped robots that require full footprint collision checking. It may also be used for high-speed robots that must be navigated carefully to not flip over, skid, or dump load at high speeds."
msgstr "Another planner plugin is the `Smac Hybrid-A* planner <https://navigation.ros.org/configuration/packages/configuring-smac-planner.html>`_ that supports **arbitrary shaped ackermann and legged** robots. It is a highly optimized and fully reconfigurable Hybrid-A* implementation supporting Dubin and Reeds-Shepp motion models. This algorithm expands the robot's candidate paths while considering the robot's minimum turning radius constraint and the robot's full footprint for collision avoidance. Thus, this plugin is suitable for arbitrary shaped robots that require full footprint collision checking. It may also be used for high-speed robots that must be navigated carefully to not flip over, skid, or dump load at high speeds."


#: ../../setup_guides/algorithm/select_algorithm.rst:40
msgid "There is also the ``Smac Lattice planner`` plugin which is based on a State Lattice planner. This plugin functions by expanding the robot state space while ensuring the path complies with the robot's kinematic constraints. The algorithm provides minimum control sets which allows it to support **differential, omnidirectional, and ackermann** vehicles of any shape and size with minimal reconfiguration."
msgstr "There is also the ``Smac Lattice planner`` plugin which is based on a State Lattice planner. This plugin functions by expanding the robot state space while ensuring the path complies with the robot's kinematic constraints. The algorithm provides minimum control sets which allows it to support **differential, omnidirectional, and ackermann** vehicles of any shape and size with minimal reconfiguration."


#: ../../setup_guides/algorithm/select_algorithm.rst:43 ../../setup_guides/algorithm/select_algorithm.rst:85
msgid "Summary"
msgstr "Summary"


#: ../../setup_guides/algorithm/select_algorithm.rst:46 ../../setup_guides/algorithm/select_algorithm.rst:88
msgid "Plugin Name"
msgstr "插件名称"


#: ../../setup_guides/algorithm/select_algorithm.rst:46 ../../setup_guides/algorithm/select_algorithm.rst:88
msgid "Supported Robot Types"
msgstr "支持的机器人类型"


#: ../../setup_guides/algorithm/select_algorithm.rst:48
msgid "NavFn Planner"
msgstr "NavFn规划器"


#: ../../setup_guides/algorithm/select_algorithm.rst:48
msgid "Circular Differential, Circular Omnidirectional"
msgstr "圆形差分，圆形全向"


#: ../../setup_guides/algorithm/select_algorithm.rst:50
msgid "Smac Planner 2D"
msgstr "Smac 2D规划器"


#: ../../setup_guides/algorithm/select_algorithm.rst:52
msgid "Theta Star Planner"
msgstr "Theta Star Planner"


#: ../../setup_guides/algorithm/select_algorithm.rst:54
msgid "Smac Hybrid-A* Planner"
msgstr "Smac混合A*规划器"


#: ../../setup_guides/algorithm/select_algorithm.rst:54
msgid "Non-circular or Circular Ackermann, Non-circular or Circular Legged"
msgstr "非圆形或圆形阿克曼，非圆形或圆形腿式"


#: ../../setup_guides/algorithm/select_algorithm.rst:56
msgid "Smac Lattice Planner"
msgstr "Smac格栅规划器"


#: ../../setup_guides/algorithm/select_algorithm.rst:56
msgid "Non-circular Differential, Non-circular Omnidirectional"
msgstr "Non-circular Differential, Non-circular Omnidirectional"


#: ../../setup_guides/algorithm/select_algorithm.rst:61 ../../setup_guides/algorithm/select_algorithm.rst:100
msgid "Example Configuration"
msgstr "Example Configuration"


#: ../../setup_guides/algorithm/select_algorithm.rst:71
msgid "An example configuration of the planner server is shown above. The ``planner_plugins`` parameter accepts a list of mapped planner plugin names. For each plugin namespace defined in ``planner_plugins`` (``GridBased`` in our example), we specify the type of plugin to be loaded in the ``plugin`` parameter. Additional configurations must then be specified in this namespace based on the algorithm to be used. Please see the `Configuration Guide <https://navigation.ros.org/configuration/index.html>`_ for more details."
msgstr "An example configuration of the planner server is shown above. The ``planner_plugins`` parameter accepts a list of mapped planner plugin names. For each plugin namespace defined in ``planner_plugins`` (``GridBased`` in our example), we specify the type of plugin to be loaded in the ``plugin`` parameter. Additional configurations must then be specified in this namespace based on the algorithm to be used. Please see the `Configuration Guide <https://navigation.ros.org/configuration/index.html>`_ for more details."


#: ../../setup_guides/algorithm/select_algorithm.rst:74
msgid "Controller Server"
msgstr "控制器服务器"


#: ../../setup_guides/algorithm/select_algorithm.rst:76
msgid "The default controller plugin is the `DWB controller <https://navigation.ros.org/configuration/packages/configuring-dwb-controller.html>`_. It implements a modified Dynamic Window Approach (DWA) algorithm with configurable plugins to compute the control commands for the robot. This controller makes use of a ``Trajectory Generator plugin`` that generates the set of possible trajectories. These are then evaluated by one or more ``Critic plugins``, each of which may give a different score based on how they are configured. The sum of the scores from these ``Critic plugins`` determine the overall score of a trajectory. The best scoring trajectory then determines the output command velocity."
msgstr "The default controller plugin is the `DWB controller <https://navigation.ros.org/configuration/packages/configuring-dwb-controller.html>`_. It implements a modified Dynamic Window Approach (DWA) algorithm with configurable plugins to compute the control commands for the robot. This controller makes use of a ``Trajectory Generator plugin`` that generates the set of possible trajectories. These are then evaluated by one or more ``Critic plugins``, each of which may give a different score based on how they are configured. The sum of the scores from these ``Critic plugins`` determine the overall score of a trajectory. The best scoring trajectory then determines the output command velocity."


#: ../../setup_guides/algorithm/select_algorithm.rst:78
msgid "The ``DWB controller`` can be used on **circular or non-circular differential, and circular or non-circular omnidirectional** robots. It may also be configured for **ackerman and legged** robots if it is given a ``Trajectory Generation plugin`` that produces a set of possible trajectories that considers the robot's minimum curvature constraint."
msgstr "The ``DWB controller`` can be used on **circular or non-circular differential, and circular or non-circular omnidirectional** robots. It may also be configured for **ackerman and legged** robots if it is given a ``Trajectory Generation plugin`` that produces a set of possible trajectories that considers the robot's minimum curvature constraint."


#: ../../setup_guides/algorithm/select_algorithm.rst:80
msgid "Another example of a controller server plugin is the `TEB controller <https://github.com/rst-tu-dortmund/teb_local_planner>`_ which is an MPC time optimal controller. It implements the Timed Elastic Band (TEB) approach which optimizes the robot's trajectory based on its execution time, distance from obstacles, and feasibility with respect to the robot's kinematic constraints. This controller can be used on **differential, omnidirectional, ackermann, and legged** robots."
msgstr "Another example of a controller server plugin is the `TEB controller <https://github.com/rst-tu-dortmund/teb_local_planner>`_ which is an MPC time optimal controller. It implements the Timed Elastic Band (TEB) approach which optimizes the robot's trajectory based on its execution time, distance from obstacles, and feasibility with respect to the robot's kinematic constraints. This controller can be used on **differential, omnidirectional, ackermann, and legged** robots."


#: ../../setup_guides/algorithm/select_algorithm.rst:82
msgid "The last example for this section is the `Regulated Pure Pursuit controller (RPP) <https://navigation.ros.org/configuration/packages/configuring-regulated-pp.html>`_ . This controller implements a variant of the pure pursuit algorithm with added regulation heuristic functions to manage collision and velocity constraints. This variation is implemented to target the needs of service or industrial robots and is suitable for use with **differential, ackermann, and legged** robots."
msgstr "The last example for this section is the `Regulated Pure Pursuit controller (RPP) <https://navigation.ros.org/configuration/packages/configuring-regulated-pp.html>`_ . This controller implements a variant of the pure pursuit algorithm with added regulation heuristic functions to manage collision and velocity constraints. This variation is implemented to target the needs of service or industrial robots and is suitable for use with **differential, ackermann, and legged** robots."


#: ../../setup_guides/algorithm/select_algorithm.rst:88
msgid "Task"
msgstr "任务"


#: ../../setup_guides/algorithm/select_algorithm.rst:90
msgid "DWB controller"
msgstr "DWB控制器"


#: ../../setup_guides/algorithm/select_algorithm.rst:90
msgid "Differential, Omnidirectional"
msgstr "差动、全向"


#: ../../setup_guides/algorithm/select_algorithm.rst:90
msgid "Dynamic obstacle avoidance"
msgstr "动态障碍物避免"


#: ../../setup_guides/algorithm/select_algorithm.rst:92
msgid "TEB Controller"
msgstr "TEB 控制器"


#: ../../setup_guides/algorithm/select_algorithm.rst:92
msgid "Differential, Omnidirectional, Ackermann, Legged"
msgstr "差动、全向、阿克曼、腿式"


#: ../../setup_guides/algorithm/select_algorithm.rst:94
msgid "RPP controller"
msgstr "RPP 控制器"


#: ../../setup_guides/algorithm/select_algorithm.rst:94
msgid "Differential, Ackermann, Legged"
msgstr "差动、阿克曼、腿式"


#: ../../setup_guides/algorithm/select_algorithm.rst:94
msgid "Exact path following"
msgstr "精确路径跟随"


#: ../../setup_guides/algorithm/select_algorithm.rst:97
msgid "All of these algorithms work for both circular and non-circular robots."
msgstr "All of these algorithms work for both circular and non-circular robots."


#: ../../setup_guides/algorithm/select_algorithm.rst:110
msgid "Shown above is a sample basic configuration of the controller server. The list of mapped names for controller plugins are defined in the ``controller_plugins`` parameter. Similar to the planner server, each namespace defined in the ``controller_plugins`` (``FollowPath`` in our example) must define the type of plugin it will use in the ``plugin`` parameter. Additional configurations must also be made for the selected algorithm in the namespace. Please see the `Configuration Guide <https://navigation.ros.org/configuration/index.html>`_ for more details."
msgstr "Shown above is a sample basic configuration of the controller server. The list of mapped names for controller plugins are defined in the ``controller_plugins`` parameter. Similar to the planner server, each namespace defined in the ``controller_plugins`` (``FollowPath`` in our example) must define the type of plugin it will use in the ``plugin`` parameter. Additional configurations must also be made for the selected algorithm in the namespace. Please see the `Configuration Guide <https://navigation.ros.org/configuration/index.html>`_ for more details."


#: ../../setup_guides/algorithm/select_algorithm.rst:113
msgid "The planner and controller servers, along with the other servers of Nav2, are launched in ROS 2 through lifecycle nodes. Lifecycle nodes allow for easier bringup and teardown of the servers. Lifecycle node management will be discussed in the next tutorial."
msgstr "The planner and controller servers, along with the other servers of Nav2, are launched in ROS 2 through lifecycle nodes. Lifecycle nodes allow for easier bringup and teardown of the servers. Lifecycle node management will be discussed in the next tutorial."


#: ../../setup_guides/algorithm/select_algorithm.rst:116 ../../setup_guides/footprint/setup_footprint.rst:106 ../../setup_guides/odom/setup_odom.rst:565 ../../setup_guides/sensors/setup_sensors.rst:548 ../../setup_guides/transformation/setup_transforms.rst:109 ../../setup_guides/urdf/setup_urdf.rst:456
msgid "Conclusion"
msgstr "Conclusion"


#: ../../setup_guides/algorithm/select_algorithm.rst:117
msgid "In this tutorial, we have discussed the roles and configuration of Nav2's planner and controller servers. To summarize, these servers host a map of one or more algorithm plugins which are selected depending on your robot's structure and surroundings. We also described a few of the available plugins for the planner and controller servers to help you identify which plugins are suitable for your robot. Lastly, we also provided some simple configuration examples to show how these plugins are instantiated on the servers. You can refer to the configuration guide of the algorithm plugin you will select for more details on its configuration parameters."
msgstr "In this tutorial, we have discussed the roles and configuration of Nav2's planner and controller servers. To summarize, these servers host a map of one or more algorithm plugins which are selected depending on your robot's structure and surroundings. We also described a few of the available plugins for the planner and controller servers to help you identify which plugins are suitable for your robot. Lastly, we also provided some simple configuration examples to show how these plugins are instantiated on the servers. You can refer to the configuration guide of the algorithm plugin you will select for more details on its configuration parameters."


#: ../../setup_guides/footprint/setup_footprint.rst:4
msgid "Setting Up the Robot's Footprint"
msgstr "Setting Up the Robot's Footprint"


#: ../../setup_guides/footprint/setup_footprint.rst:6
msgid "In this guide, we will discuss how to configure the footprint of your robot for the navigation algorithms used by Nav2. We will also show a sample footprint configuration on ``sam_bot``, the simulated robot that we have been building in this series of setup guides. Lastly, we will also show the visualization of ``sam_bot``'s footprint in RViz to ensure that we have set it up correctly."
msgstr "In this guide, we will discuss how to configure the footprint of your robot for the navigation algorithms used by Nav2. We will also show a sample footprint configuration on ``sam_bot``, the simulated robot that we have been building in this series of setup guides. Lastly, we will also show the visualization of ``sam_bot``'s footprint in RViz to ensure that we have set it up correctly."


#: ../../setup_guides/footprint/setup_footprint.rst:9
msgid "Footprint Introduction"
msgstr "Footprint Introduction"


#: ../../setup_guides/footprint/setup_footprint.rst:11
msgid "The footprint outlines the robot's 2D shape when projected to the ground and is primarily used by Nav2 to avoid collisions during planning. The algorithms involved in this task makes sure that the robot does not collide with the obstacles in the costmap while it computes the robot's paths or plans."
msgstr "The footprint outlines the robot's 2D shape when projected to the ground and is primarily used by Nav2 to avoid collisions during planning. The algorithms involved in this task makes sure that the robot does not collide with the obstacles in the costmap while it computes the robot's paths or plans."


#: ../../setup_guides/footprint/setup_footprint.rst:13
msgid "The footprint is set up using the ``footprint`` or ``robot_radius`` parameter of the global and local costmaps which we tackled in the previous tutorials (:ref:`Setting Up Sensors Guide<setup_sensors>`). The value defined in the ``footprint`` parameter is an ordered vector of 2-D points defining the robot's footprint with the ``base_link`` frame as the origin. The first and last points in the vector are joined into the last line segment to close the footprint's shape. As an alternative, you may also use the ``robot_radius`` parameter wherein circular footprint is automatically generated and centered at ``base_link``.  In cases both the ``footprint`` and ``robot_radius`` parameters have been defined in the configuration, the ``footprint`` is used."
msgstr "The footprint is set up using the ``footprint`` or ``robot_radius`` parameter of the global and local costmaps which we tackled in the previous tutorials (:ref:`Setting Up Sensors Guide<setup_sensors>`). The value defined in the ``footprint`` parameter is an ordered vector of 2-D points defining the robot's footprint with the ``base_link`` frame as the origin. The first and last points in the vector are joined into the last line segment to close the footprint's shape. As an alternative, you may also use the ``robot_radius`` parameter wherein circular footprint is automatically generated and centered at ``base_link``.  In cases both the ``footprint`` and ``robot_radius`` parameters have been defined in the configuration, the ``footprint`` is used."


#: ../../setup_guides/footprint/setup_footprint.rst:16
msgid "A section in the previous guide, :ref:`Configuring nav2_costmap_2d<configuring_nav2_costmap_2d>`, explains how to configure basic costmap parameters. Please refer to that guide for more details on costmap configuration."
msgstr "A section in the previous guide, :ref:`Configuring nav2_costmap_2d<configuring_nav2_costmap_2d>`, explains how to configure basic costmap parameters. Please refer to that guide for more details on costmap configuration."


#: ../../setup_guides/footprint/setup_footprint.rst:18
msgid "For the global costmap footprint, the decision to choose between the ``robot_radius`` (circular) or ``footprint`` (polygon) parameter depends on the robot, its environment, and the path planning algorithm you will use. Even if you are working with a non-circular robot, there may be situations where a circular footprint is acceptable. For example, path planning algorithms like `NavFn <https://navigation.ros.org/configuration/packages/configuring-navfn.html>`_ assume that the robot is circular since it only checks for collision per grid cell, so it will not be necessary to outline the robot's exact shape for its footprint. On the other hand, algorithms such as `Smac Planner's Hybrid-A* <https://navigation.ros.org/configuration/packages/configuring-smac-planner.html>`_ perform collision checking on the robot's polygon-shaped footprint if possible and necessary. Hence, it might be useful to use a polygon-shaped footprint. Another example is having a small RC car sized robot roaming a warehouse. This robot is so small it won't need to make confined maneuvers -- thusly approximating it with the largest cross-sectional radius is a good time-saving optimization."
msgstr "For the global costmap footprint, the decision to choose between the ``robot_radius`` (circular) or ``footprint`` (polygon) parameter depends on the robot, its environment, and the path planning algorithm you will use. Even if you are working with a non-circular robot, there may be situations where a circular footprint is acceptable. For example, path planning algorithms like `NavFn <https://navigation.ros.org/configuration/packages/configuring-navfn.html>`_ assume that the robot is circular since it only checks for collision per grid cell, so it will not be necessary to outline the robot's exact shape for its footprint. On the other hand, algorithms such as `Smac Planner's Hybrid-A* <https://navigation.ros.org/configuration/packages/configuring-smac-planner.html>`_ perform collision checking on the robot's polygon-shaped footprint if possible and necessary. Hence, it might be useful to use a polygon-shaped footprint. Another example is having a small RC car sized robot roaming a warehouse. This robot is so small it won't need to make confined maneuvers -- thusly approximating it with the largest cross-sectional radius is a good time-saving optimization."


#: ../../setup_guides/footprint/setup_footprint.rst:20
msgid "For the local costmap footprint, it is typical for non-circular robots to be set up with ``footprint`` (polygon). Some situations where this is not recommended is when you do not have enough computing resources to implement collision avoidance algorithms on a polygon-shaped footprint. Another possible reason to use ``robot_radius`` (circular) for the local costmap is when the robot is very small relative to its environment such that precise collision avoidance is not necessary. However, generally the local trajectory planner should use the actual footprint polygon of the robot."
msgstr "For the local costmap footprint, it is typical for non-circular robots to be set up with ``footprint`` (polygon). Some situations where this is not recommended is when you do not have enough computing resources to implement collision avoidance algorithms on a polygon-shaped footprint. Another possible reason to use ``robot_radius`` (circular) for the local costmap is when the robot is very small relative to its environment such that precise collision avoidance is not necessary. However, generally the local trajectory planner should use the actual footprint polygon of the robot."


#: ../../setup_guides/footprint/setup_footprint.rst:23
msgid "Configuring the Robot's Footprint"
msgstr "Configuring the Robot's Footprint"


#: ../../setup_guides/footprint/setup_footprint.rst:24
msgid "In this section, we will configure the footprint of ``sam_bot`` such that ``footprint`` (polygon) is used for the local costmap and ``robot_radius`` (circular) is used for the global costmap. We will utilize the default configuration file of Nav2 with a modified footprint parameter for the global and local costmaps."
msgstr "In this section, we will configure the footprint of ``sam_bot`` such that ``footprint`` (polygon) is used for the local costmap and ``robot_radius`` (circular) is used for the global costmap. We will utilize the default configuration file of Nav2 with a modified footprint parameter for the global and local costmaps."


#: ../../setup_guides/footprint/setup_footprint.rst:26
msgid "The complete source code for ``sam_bot`` can be found in `navigation2_tutorials <https://github.com/ros-planning/navigation2_tutorials/tree/master/sam_bot_description>`_ repository."
msgstr "The complete source code for ``sam_bot`` can be found in `navigation2_tutorials <https://github.com/ros-planning/navigation2_tutorials/tree/master/sam_bot_description>`_ repository."


#: ../../setup_guides/footprint/setup_footprint.rst:28
msgid "Under the ``config`` directory, create a new file named  ``nav2_params.yaml``. Next, copy the contents of `config/nav2_params.yaml <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/config/nav2_params.yaml>`_ and paste them into the newly created file. The contents of `config/nav2_params.yaml <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/config/nav2_params.yaml>`_ are copied from the default configuration file of Nav2 but with changes in the ``footprint`` and  ``robot_radius`` parameters to match the shape of ``sam_bot``."
msgstr "Under the ``config`` directory, create a new file named  ``nav2_params.yaml``. Next, copy the contents of `config/nav2_params.yaml <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/config/nav2_params.yaml>`_ and paste them into the newly created file. The contents of `config/nav2_params.yaml <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/config/nav2_params.yaml>`_ are copied from the default configuration file of Nav2 but with changes in the ``footprint`` and  ``robot_radius`` parameters to match the shape of ``sam_bot``."


#: ../../setup_guides/footprint/setup_footprint.rst:31
msgid "The default configuration file for Nav2 can be found in the official `Navigation2 repository <https://github.com/ros-planning/navigation2/blob/galactic/nav2_bringup/bringup/params/nav2_params.yaml>`_."
msgstr "The default configuration file for Nav2 can be found in the official `Navigation2 repository <https://github.com/ros-planning/navigation2/blob/galactic/nav2_bringup/bringup/params/nav2_params.yaml>`_."


#: ../../setup_guides/footprint/setup_footprint.rst:33
msgid "Below is the code snippet from ``nav2_params.yaml`` defining the local costmap footprint. In this configuration file, the ``footprint`` parameter of the local costmap has already been set with a rectangular-shaped footprint. This box is centered at the ``base_link`` frame of ``sam_bot``."
msgstr "Below is the code snippet from ``nav2_params.yaml`` defining the local costmap footprint. In this configuration file, the ``footprint`` parameter of the local costmap has already been set with a rectangular-shaped footprint. This box is centered at the ``base_link`` frame of ``sam_bot``."


#: ../../setup_guides/footprint/setup_footprint.rst:42
msgid "For the global costmap, we have already set the ``robot_radius`` parameter to create a circular footprint that matches ``sam_bot``'s size and centered at ``base_link``. The parameter that was modified is shown in the code snippet below."
msgstr "For the global costmap, we have already set the ``robot_radius`` parameter to create a circular footprint that matches ``sam_bot``'s size and centered at ``base_link``. The parameter that was modified is shown in the code snippet below."


#: ../../setup_guides/footprint/setup_footprint.rst:52 ../../setup_guides/odom/setup_odom.rst:294 ../../setup_guides/odom/setup_odom.rst:486 ../../setup_guides/sensors/setup_sensors.rst:248 ../../setup_guides/sensors/setup_sensors.rst:435
msgid "Build, Run and Verification"
msgstr "Build, Run and Verification"


#: ../../setup_guides/footprint/setup_footprint.rst:53
msgid "We will now confirm that we have properly set up ``sam_bot``'s footprint."
msgstr "We will now confirm that we have properly set up ``sam_bot``'s footprint."


#: ../../setup_guides/footprint/setup_footprint.rst:55
msgid "First, we launch `launch/display.launch.py <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/launch/display.launch.py>`_ to launch the robot state publisher, spawn ``sam_bot`` in Gazebo, and visualize ``sam_bot`` and its footprint in Rviz. The robot state publisher publishes the ``base_link`` => ``sensors`` transforms defined in ``sam_bot``'s URDF, while Gazebo's differential drive plugin publishes the ``odom`` => ``base_link`` transform. Open a new terminal and execute the lines below."
msgstr "First, we launch `launch/display.launch.py <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/launch/display.launch.py>`_ to launch the robot state publisher, spawn ``sam_bot`` in Gazebo, and visualize ``sam_bot`` and its footprint in Rviz. The robot state publisher publishes the ``base_link`` => ``sensors`` transforms defined in ``sam_bot``'s URDF, while Gazebo's differential drive plugin publishes the ``odom`` => ``base_link`` transform. Open a new terminal and execute the lines below."


#: ../../setup_guides/footprint/setup_footprint.rst:63
msgid "After launching ``display.launch.py``, RViz and Gazebo should open. RViz should show ``sam_bot``, the frames of ``sam_bot``'s parts, and the ``odom`` frame without errors. Gazebo should show ``sam_bot`` with a sphere and a cube detectable by ``sambot``'s lidar sensor."
msgstr "After launching ``display.launch.py``, RViz and Gazebo should open. RViz should show ``sam_bot``, the frames of ``sam_bot``'s parts, and the ``odom`` frame without errors. Gazebo should show ``sam_bot`` with a sphere and a cube detectable by ``sambot``'s lidar sensor."


#: ../../setup_guides/footprint/setup_footprint.rst:65
msgid "Next, we will publish the ``map`` => ``odom`` transform using the ``static_transform_publisher``. We publish the ``map`` => ``odom`` transform as static in this guide as a simple way to publish the transform and visualize the footprint. Open a new terminal and execute the lines below."
msgstr "Next, we will publish the ``map`` => ``odom`` transform using the ``static_transform_publisher``. We publish the ``map`` => ``odom`` transform as static in this guide as a simple way to publish the transform and visualize the footprint. Open a new terminal and execute the lines below."


#: ../../setup_guides/footprint/setup_footprint.rst:71
msgid "The ``map`` => ``odom`` transform should now be being published and the ``map`` frame should be added in RViz without errors."
msgstr "The ``map`` => ``odom`` transform should now be being published and the ``map`` frame should be added in RViz without errors."


#: ../../setup_guides/footprint/setup_footprint.rst:73
msgid "Lastly, we will launch Nav2 using the ``nav2_params.yaml`` configuration file we just made and ``navigation_launch.py``, the built-in launch file of ``nav2_bringup``. Open a new terminal and execute the following:"
msgstr "Lastly, we will launch Nav2 using the ``nav2_params.yaml`` configuration file we just made and ``navigation_launch.py``, the built-in launch file of ``nav2_bringup``. Open a new terminal and execute the following:"


#: ../../setup_guides/footprint/setup_footprint.rst:79
msgid "We should now be able to visualize the footprints in RViz, which will be discussed in the next section."
msgstr "We should now be able to visualize the footprints in RViz, which will be discussed in the next section."


#: ../../setup_guides/footprint/setup_footprint.rst:82
msgid "Visualizing Footprint in RViz"
msgstr "Visualizing Footprint in RViz"


#: ../../setup_guides/footprint/setup_footprint.rst:83
msgid "To visualize the footprint of the local costmap, click the add button at the bottom-left part of the RViz window. Under the ``By topic`` tab, select the ``Polygon`` under the ``/local_costmap/published_footprint`` topic, as shown below."
msgstr "To visualize the footprint of the local costmap, click the add button at the bottom-left part of the RViz window. Under the ``By topic`` tab, select the ``Polygon`` under the ``/local_costmap/published_footprint`` topic, as shown below."


#: ../../setup_guides/footprint/setup_footprint.rst:89
msgid "Set the fixed frame in RViz to ``odom`` and you should see the rectangular-shaped footprint of ``sam_bot``:"
msgstr "Set the fixed frame in RViz to ``odom`` and you should see the rectangular-shaped footprint of ``sam_bot``:"


#: ../../setup_guides/footprint/setup_footprint.rst:94
msgid "On the other hand, for the global costmap, click the add button at the bottom-left part of the RViz window. Go to ``By topic`` tab then select the ``Polygon`` under the ``/global_costmap/published_footprint`` topic, as shown below."
msgstr "On the other hand, for the global costmap, click the add button at the bottom-left part of the RViz window. Go to ``By topic`` tab then select the ``Polygon`` under the ``/global_costmap/published_footprint`` topic, as shown below."


#: ../../setup_guides/footprint/setup_footprint.rst:100
msgid "Set the fixed frame in RViz to ``map`` and you should see the circular footprint of ``sam_bot``:"
msgstr "Set the fixed frame in RViz to ``map`` and you should see the circular footprint of ``sam_bot``:"


#: ../../setup_guides/footprint/setup_footprint.rst:107
msgid "In this guide, we have shown how to configure a circular and polygon-shaped footprint for your robot. This footprint is important since it plays a major role in Nav2's pathfinding algorithms function."
msgstr "In this guide, we have shown how to configure a circular and polygon-shaped footprint for your robot. This footprint is important since it plays a major role in Nav2's pathfinding algorithms function."


#: ../../setup_guides/footprint/setup_footprint.rst:109
msgid "As a demo, we have configured the costmap footprint parameters of  ``sam_bot``. We set the local costmap to use a polygon-shaped footprint following ``sam_bot``'s shape while we set the the global costmap to use a circular footprint. Lastly, we visualized and confirmed the footprints of the local and global costmaps in RViz."
msgstr "As a demo, we have configured the costmap footprint parameters of  ``sam_bot``. We set the local costmap to use a polygon-shaped footprint following ``sam_bot``'s shape while we set the the global costmap to use a circular footprint. Lastly, we visualized and confirmed the footprints of the local and global costmaps in RViz."


#: ../../setup_guides/index.rst:4
msgid "First-Time Robot Setup Guide"
msgstr "First-Time Robot Setup Guide"


#: ../../setup_guides/index.rst:6
msgid "This section is a collection of guides that aims to provide readers a good resource for setting up Nav2. The objectives for this section are as follows:"
msgstr "This section is a collection of guides that aims to provide readers a good resource for setting up Nav2. The objectives for this section are as follows:"


#: ../../setup_guides/index.rst:8
msgid "Help new users with setting up Navigation2 with a new robot"
msgstr "Help new users with setting up Navigation2 with a new robot"


#: ../../setup_guides/index.rst:9
msgid "Help people with custom built robots to properly set up their robots to be used in ROS/Navigation2"
msgstr "Help people with custom built robots to properly set up their robots to be used in ROS/Navigation2"


#: ../../setup_guides/index.rst:10
msgid "Act as a checklist, template or boilerplate reference for more experienced readers"
msgstr "Act as a checklist, template or boilerplate reference for more experienced readers"


#: ../../setup_guides/index.rst:11
msgid "Provide examples which can be run on simulators/tools like Gazebo or RViz to guide readers on the Nav2 setup process even without a physical robot."
msgstr "Provide examples which can be run on simulators/tools like Gazebo or RViz to guide readers on the Nav2 setup process even without a physical robot."


#: ../../setup_guides/index.rst:12
msgid "Broad strokes, tips, and tricks for configuring certain packages and integrating different components of the robot platform (sensors, odometry, etc.)"
msgstr "Broad strokes, tips, and tricks for configuring certain packages and integrating different components of the robot platform (sensors, odometry, etc.)"


#: ../../setup_guides/index.rst:14
msgid "To guide you through the first-time setup of your robot, we will be tackling the following topics:"
msgstr "To guide you through the first-time setup of your robot, we will be tackling the following topics:"


#: ../../setup_guides/index.rst:16
msgid "Introduce TF2 and setup your robot URDF"
msgstr "Introduce TF2 and setup your robot URDF"


#: ../../setup_guides/index.rst:17
msgid "Setup sensor sources for robot odometry"
msgstr "Setup sensor sources for robot odometry"


#: ../../setup_guides/index.rst:18
msgid "Setup sensor sources for perception"
msgstr "Setup sensor sources for perception"


#: ../../setup_guides/index.rst:19
msgid "Configure round or arbitrary shaped footprints for your robot"
msgstr "Configure round or arbitrary shaped footprints for your robot"


#: ../../setup_guides/index.rst:20
msgid "Select and set up planner and controller navigation plugins for your robot's navigation tasks"
msgstr "Select and set up planner and controller navigation plugins for your robot's navigation tasks"


#: ../../setup_guides/index.rst:21
msgid "Lifecycle node management for easy bringup of other related sensors or nodes"
msgstr "Lifecycle node management for easy bringup of other related sensors or nodes"


#: ../../setup_guides/index.rst:23
msgid "These tutorials are not meant to be full tuning and configuration guides since they only aim to help you get your robot up and running with a basic configuration. For more detailed discussions and guides on how to customize and tune Nav2 for your robot, head on to the :ref:`configuration` section."
msgstr "These tutorials are not meant to be full tuning and configuration guides since they only aim to help you get your robot up and running with a basic configuration. For more detailed discussions and guides on how to customize and tune Nav2 for your robot, head on to the :ref:`configuration` section."


#: ../../setup_guides/index.rst:25
msgid "**Table of Contents:**"
msgstr "**Table of Contents:**"


#: ../../setup_guides/odom/setup_odom.rst:2
msgid "Setting Up Odometry"
msgstr "Setting Up Odometry"


#: ../../setup_guides/odom/setup_odom.rst:4
msgid "In this guide, we will be looking at how to integrate our robot's odometry system with Nav2. First we will provide a brief introduction on odometry, plus the necessary messages and transforms that need to be published for Nav2 to function correctly. Next, we will show how to setup odometry with two different cases. In the first case, we will show how to setup an odometry system for a robot with already available wheel encoders. In the second case, we will build a demo that simulates a functioning odometry system on ``sam_bot`` (the robot that we built in the previous section) using Gazebo. Afterwards, we will discuss how various sources of odometry can be fused to provide a smoothed odometry using the ``robot_localization`` package. Lastly, we will also show how to publish the ``odom`` => ``base_link`` transform using ``robot_localization``."
msgstr "In this guide, we will be looking at how to integrate our robot's odometry system with Nav2. First we will provide a brief introduction on odometry, plus the necessary messages and transforms that need to be published for Nav2 to function correctly. Next, we will show how to setup odometry with two different cases. In the first case, we will show how to setup an odometry system for a robot with already available wheel encoders. In the second case, we will build a demo that simulates a functioning odometry system on ``sam_bot`` (the robot that we built in the previous section) using Gazebo. Afterwards, we will discuss how various sources of odometry can be fused to provide a smoothed odometry using the ``robot_localization`` package. Lastly, we will also show how to publish the ``odom`` => ``base_link`` transform using ``robot_localization``."


#: ../../setup_guides/odom/setup_odom.rst:7 ../../setup_guides/urdf/setup_urdf.rst:9
msgid "The complete source code in this tutorial can be found in `navigation2_tutorials <https://github.com/ros-planning/navigation2_tutorials/tree/master/sam_bot_description>`_ repository under the ``sam_bot_description`` package. Note that the repository contains the full code after accomplishing all the tutorials in this guide."
msgstr "The complete source code in this tutorial can be found in `navigation2_tutorials <https://github.com/ros-planning/navigation2_tutorials/tree/master/sam_bot_description>`_ repository under the ``sam_bot_description`` package. Note that the repository contains the full code after accomplishing all the tutorials in this guide."


#: ../../setup_guides/odom/setup_odom.rst:10
msgid "Odometry Introduction"
msgstr "Odometry Introduction"


#: ../../setup_guides/odom/setup_odom.rst:12
msgid "The odometry system provides a locally accurate estimate of a robot's pose and velocity based on its motion. The odometry information can be obtained from various sources such as IMU, LIDAR, RADAR, VIO, and wheel encoders. One thing to note is that IMUs drift over time while wheel encoders drift over distance traveled, thus they are often used together to counter each other's negative characteristics."
msgstr "The odometry system provides a locally accurate estimate of a robot's pose and velocity based on its motion. The odometry information can be obtained from various sources such as IMU, LIDAR, RADAR, VIO, and wheel encoders. One thing to note is that IMUs drift over time while wheel encoders drift over distance traveled, thus they are often used together to counter each other's negative characteristics."


#: ../../setup_guides/odom/setup_odom.rst:14
msgid "The ``odom`` frame and the transformation associated with it use a robot's odometry system to publish localization information that is continuous but becomes less accurate over time or distance (depending on the sensor modalities and drift). In spite of this, the information can still be used by the robot to navigate its immediate vicinity (e.g collision avoidance). To obtain consistently accurate odometry information over time, the ``map`` frame provides globally accurate information that is used to correct the ``odom`` frame."
msgstr "The ``odom`` frame and the transformation associated with it use a robot's odometry system to publish localization information that is continuous but becomes less accurate over time or distance (depending on the sensor modalities and drift). In spite of this, the information can still be used by the robot to navigate its immediate vicinity (e.g collision avoidance). To obtain consistently accurate odometry information over time, the ``map`` frame provides globally accurate information that is used to correct the ``odom`` frame."


#: ../../setup_guides/odom/setup_odom.rst:16
msgid "As discussed in the previous guides and in `REP 105 <https://www.ros.org/reps/rep-0105.html>`_, the ``odom`` frame is connected to the rest of the system and Nav2 through the ``odom`` => ``base_link`` transform. This transform is published by a tf2 broadcaster or by frameworks such as ``robot_localization``, which also provide additional functionalities. We will be talking more about ``robot_localization`` in a following section."
msgstr "As discussed in the previous guides and in `REP 105 <https://www.ros.org/reps/rep-0105.html>`_, the ``odom`` frame is connected to the rest of the system and Nav2 through the ``odom`` => ``base_link`` transform. This transform is published by a tf2 broadcaster or by frameworks such as ``robot_localization``, which also provide additional functionalities. We will be talking more about ``robot_localization`` in a following section."


#: ../../setup_guides/odom/setup_odom.rst:18
msgid "In addition to the required ``odom`` => ``base_link`` transform, Nav2 also requires the publishing of ``nav_msgs/Odometry`` message because this message provides the velocity information of the robot. In detail, the ``nav_msgs/Odometry`` message contains the following information:"
msgstr "In addition to the required ``odom`` => ``base_link`` transform, Nav2 also requires the publishing of ``nav_msgs/Odometry`` message because this message provides the velocity information of the robot. In detail, the ``nav_msgs/Odometry`` message contains the following information:"


#: ../../setup_guides/odom/setup_odom.rst:38
msgid "This message tells us the estimates for the pose and velocity of the robot. The ``header`` message provides the timestamped data in a given coordinate frame. The ``pose`` message provides the position and orientation of the robot relative to the frame specified in ``header.frame_id``. The ``twist`` message gives the linear and angular velocity relative to the frame defined in ``child_frame_id``."
msgstr "This message tells us the estimates for the pose and velocity of the robot. The ``header`` message provides the timestamped data in a given coordinate frame. The ``pose`` message provides the position and orientation of the robot relative to the frame specified in ``header.frame_id``. The ``twist`` message gives the linear and angular velocity relative to the frame defined in ``child_frame_id``."


#: ../../setup_guides/odom/setup_odom.rst:42
msgid "Setting Up Odometry on your Robot"
msgstr "Setting Up Odometry on your Robot"


#: ../../setup_guides/odom/setup_odom.rst:44
msgid "Setting up the odometry system for Nav2 for your physical robot depends a lot on which odometry sensors are available with your robot. Due to the large number of configurations your robot may have, specific setup instructions will not be within the scope of this tutorial. Instead, we will provide some basic examples and useful resources to help you configure your robot for Nav2."
msgstr "Setting up the odometry system for Nav2 for your physical robot depends a lot on which odometry sensors are available with your robot. Due to the large number of configurations your robot may have, specific setup instructions will not be within the scope of this tutorial. Instead, we will provide some basic examples and useful resources to help you configure your robot for Nav2."


#: ../../setup_guides/odom/setup_odom.rst:46
msgid "To start, we will use an example of a robot with wheel encoders as its odometry source. Note that wheel encoders are not required for Nav2 but it is common in most setups. The goal in setting up the odometry is to compute the odometry information and publish the ``nav_msgs/Odometry`` message and ``odom`` => ``base_link`` transform over ROS 2. To calculate this information, you will need to setup some code that will translate wheel encoder information into odometry information, similar to the snippet below:"
msgstr "To start, we will use an example of a robot with wheel encoders as its odometry source. Note that wheel encoders are not required for Nav2 but it is common in most setups. The goal in setting up the odometry is to compute the odometry information and publish the ``nav_msgs/Odometry`` message and ``odom`` => ``base_link`` transform over ROS 2. To calculate this information, you will need to setup some code that will translate wheel encoder information into odometry information, similar to the snippet below:"


#: ../../setup_guides/odom/setup_odom.rst:53
msgid "The ``right_wheel_est_vel`` and ``left_wheel_est_vel`` are the estimated velocities of the right and left wheels respectively, and the ``wheel separation`` is the distance between the wheels. The values of ``right_wheel_est_vel`` and ``left_wheel_est_vel`` can be obtained by simply getting the changes in the positions of the wheel joints over time. This information can then be used to publish the Nav2 requirements. A basic example on how to do this can be found in the Navigation documentation on odometry `located here <http://wiki.ros.org/navigation/Tutorials/RobotSetup/Odom/>`_"
msgstr "The ``right_wheel_est_vel`` and ``left_wheel_est_vel`` are the estimated velocities of the right and left wheels respectively, and the ``wheel separation`` is the distance between the wheels. The values of ``right_wheel_est_vel`` and ``left_wheel_est_vel`` can be obtained by simply getting the changes in the positions of the wheel joints over time. This information can then be used to publish the Nav2 requirements. A basic example on how to do this can be found in the Navigation documentation on odometry `located here <http://wiki.ros.org/navigation/Tutorials/RobotSetup/Odom/>`_"


#: ../../setup_guides/odom/setup_odom.rst:55
msgid "An alternative to manually publishing this information that we recommend is through the ``ros2_control`` framework. The ``ros2_control`` framework contains various packages for real-time control of robots in ROS 2. For wheel encoders, ``ros2_control`` has a ``diff_drive_controller`` (differential drive controller) under the ``ros2_controller`` package. The ``diff_drive_controller`` takes in the ``geometry_msgs/Twist`` messages published on ``cmd_vel`` topic, computes odometry information, and publishes ``nav_msgs/Odometry`` messages on ``odom`` topic. Other packages that deal with different kind of sensors are also available in ``ros2_control``."
msgstr "An alternative to manually publishing this information that we recommend is through the ``ros2_control`` framework. The ``ros2_control`` framework contains various packages for real-time control of robots in ROS 2. For wheel encoders, ``ros2_control`` has a ``diff_drive_controller`` (differential drive controller) under the ``ros2_controller`` package. The ``diff_drive_controller`` takes in the ``geometry_msgs/Twist`` messages published on ``cmd_vel`` topic, computes odometry information, and publishes ``nav_msgs/Odometry`` messages on ``odom`` topic. Other packages that deal with different kind of sensors are also available in ``ros2_control``."


#: ../../setup_guides/odom/setup_odom.rst:58
msgid "For more information, see the `ros2_control documentation <https://ros-controls.github.io/control.ros.org/>`_ and the `Github repository of diff_drive_controller <https://github.com/ros-controls/ros2_controllers/tree/master/diff_drive_controller/>`_."
msgstr "For more information, see the `ros2_control documentation <https://ros-controls.github.io/control.ros.org/>`_ and the `Github repository of diff_drive_controller <https://github.com/ros-controls/ros2_controllers/tree/master/diff_drive_controller/>`_."


#: ../../setup_guides/odom/setup_odom.rst:60
msgid "For other types of sensors such as IMU, VIO, etc, their respective ROS drivers should have documentation on how publish the odometry information. Keep in mind that Nav2 requires the ``nav_msgs/Odometry`` message and ``odom`` => ``base_link`` transforms to be published and this should be your goal when setting up your odometry system."
msgstr "For other types of sensors such as IMU, VIO, etc, their respective ROS drivers should have documentation on how publish the odometry information. Keep in mind that Nav2 requires the ``nav_msgs/Odometry`` message and ``odom`` => ``base_link`` transforms to be published and this should be your goal when setting up your odometry system."


#: ../../setup_guides/odom/setup_odom.rst:63
msgid "Simulating an Odometry System using Gazebo"
msgstr "Simulating an Odometry System using Gazebo"


#: ../../setup_guides/odom/setup_odom.rst:65
msgid "In this section, we will be using Gazebo to simulate the odometry system of ``sam_bot``, the robot that we built in the previous section of this tutorial series. You may go through that guide first or grab the `complete source here  <https://github.com/ros-planning/navigation2_tutorials/tree/master/sam_bot_description/>`_."
msgstr "In this section, we will be using Gazebo to simulate the odometry system of ``sam_bot``, the robot that we built in the previous section of this tutorial series. You may go through that guide first or grab the `complete source here  <https://github.com/ros-planning/navigation2_tutorials/tree/master/sam_bot_description/>`_."


#: ../../setup_guides/odom/setup_odom.rst:67
msgid "If you are working on your own physical robot and have already set up your odometry sensors, you may opt to skip this section and head onto the next one where we fuse IMU and odometry messages to provide a smooth ``odom`` => ``base_link`` transformation."
msgstr "If you are working on your own physical robot and have already set up your odometry sensors, you may opt to skip this section and head onto the next one where we fuse IMU and odometry messages to provide a smooth ``odom`` => ``base_link`` transformation."


#: ../../setup_guides/odom/setup_odom.rst:69
msgid "As an overview for this section, we will first setup Gazebo and the necessary packages required to make it work with ROS 2. Next, we will be adding Gazebo plugins, which simulate an IMU sensor and a differential drive odometry system, in order to publish ``sensor_msgs/Imu`` and ``nav_msgs/Odometry`` messages respectively. Lastly, we will spawn ``sam_bot`` in a Gazebo environment and verify the published ``sensor_msgs/Imu`` and ``nav_msgs/Odometry`` messages over ROS 2."
msgstr "As an overview for this section, we will first setup Gazebo and the necessary packages required to make it work with ROS 2. Next, we will be adding Gazebo plugins, which simulate an IMU sensor and a differential drive odometry system, in order to publish ``sensor_msgs/Imu`` and ``nav_msgs/Odometry`` messages respectively. Lastly, we will spawn ``sam_bot`` in a Gazebo environment and verify the published ``sensor_msgs/Imu`` and ``nav_msgs/Odometry`` messages over ROS 2."


#: ../../setup_guides/odom/setup_odom.rst:72
msgid "Setup and Prerequisites"
msgstr "Setup and Prerequisites"


#: ../../setup_guides/odom/setup_odom.rst:74
msgid "`Gazebo <http://gazebosim.org/>`_ is a 3D simulator that allows us to observe how our virtual robot will function in a simulated environment. To start using Gazebo with ROS 2, follow the installation instructions in the `Gazebo Installation Documentation <http://gazebosim.org/tutorials?cat=install>`_."
msgstr "`Gazebo <http://gazebosim.org/>`_ is a 3D simulator that allows us to observe how our virtual robot will function in a simulated environment. To start using Gazebo with ROS 2, follow the installation instructions in the `Gazebo Installation Documentation <http://gazebosim.org/tutorials?cat=install>`_."


#: ../../setup_guides/odom/setup_odom.rst:76
msgid "We also need to install the ``gazebo_ros_pkgs`` package to simulate odometry and control the robot with ROS 2 in Gazebo:"
msgstr "We also need to install the ``gazebo_ros_pkgs`` package to simulate odometry and control the robot with ROS 2 in Gazebo:"


#: ../../setup_guides/odom/setup_odom.rst:82
msgid "You can test if you have successfully set up your ROS 2 and Gazebo environments by following the instructions `given here <http://gazebosim.org/tutorials?tut=ros2_installing&cat=connect_ros#TestingGazeboandROS2integration>`_."
msgstr "You can test if you have successfully set up your ROS 2 and Gazebo environments by following the instructions `given here <http://gazebosim.org/tutorials?tut=ros2_installing&cat=connect_ros#TestingGazeboandROS2integration>`_."


#: ../../setup_guides/odom/setup_odom.rst:84
msgid "Note that we described ``sam_bot`` using URDF. However, Gazebo uses `Simulation Description Format (SDF) <http://sdformat.org/>`_ to describe a robot in its simulated environment. Fortunately, Gazebo automatically translates compatible URDF files into SDF. The main requirement for the URDF to be compatible with Gazebo is to have an ``<inertia>`` element within each ``<link>`` element. This requirement is already satisfied in the URDF file of ``sam_bot``, so it can already be used in Gazebo."
msgstr "Note that we described ``sam_bot`` using URDF. However, Gazebo uses `Simulation Description Format (SDF) <http://sdformat.org/>`_ to describe a robot in its simulated environment. Fortunately, Gazebo automatically translates compatible URDF files into SDF. The main requirement for the URDF to be compatible with Gazebo is to have an ``<inertia>`` element within each ``<link>`` element. This requirement is already satisfied in the URDF file of ``sam_bot``, so it can already be used in Gazebo."


#: ../../setup_guides/odom/setup_odom.rst:87
msgid "For more information on how to use URDF in Gazebo, see `Tutorial: Using a URDF in Gazebo <http://gazebosim.org/tutorials/?tut=ros_urdf>`_."
msgstr "For more information on how to use URDF in Gazebo, see `Tutorial: Using a URDF in Gazebo <http://gazebosim.org/tutorials/?tut=ros_urdf>`_."


#: ../../setup_guides/odom/setup_odom.rst:90 ../../setup_guides/sensors/setup_sensors.rst:66
msgid "Adding Gazebo Plugins to a URDF"
msgstr "Adding Gazebo Plugins to a URDF"


#: ../../setup_guides/odom/setup_odom.rst:92
msgid "We will now add the IMU sensor and the differential drive plugins of Gazebo to our URDF. For an overview of the different plugins available in Gazebo, have a look at `Tutorial: Using Gazebo plugins with ROS <http://gazebosim.org/tutorials?tut=ros_gzplugins>`_."
msgstr "We will now add the IMU sensor and the differential drive plugins of Gazebo to our URDF. For an overview of the different plugins available in Gazebo, have a look at `Tutorial: Using Gazebo plugins with ROS <http://gazebosim.org/tutorials?tut=ros_gzplugins>`_."


#: ../../setup_guides/odom/setup_odom.rst:94
msgid "For our robot, we will be using the `GazeboRosImuSensor <http://gazebosim.org/tutorials?tut=ros_gzplugins#IMUsensor(GazeboRosImuSensor)>`_ which is a SensorPlugin. A SensorPlugin must be attached to a link, thus we will create an ``imu_link`` to which the IMU sensor will be attached. This link will be referenced under the ``<gazebo>`` element. Next, we will set ``/demo/imu`` as the topic to which the IMU will be publishing its information, and we will comply with `REP145 <https://www.ros.org/reps/rep-0145.html>`_ by setting ``initalOrientationAsReference`` to ``false``. We will also add some noise to the sensor configuration using Gazebo's `sensor noise model <http://gazebosim.org/tutorials?tut=sensor_noise>`_."
msgstr "For our robot, we will be using the `GazeboRosImuSensor <http://gazebosim.org/tutorials?tut=ros_gzplugins#IMUsensor(GazeboRosImuSensor)>`_ which is a SensorPlugin. A SensorPlugin must be attached to a link, thus we will create an ``imu_link`` to which the IMU sensor will be attached. This link will be referenced under the ``<gazebo>`` element. Next, we will set ``/demo/imu`` as the topic to which the IMU will be publishing its information, and we will comply with `REP145 <https://www.ros.org/reps/rep-0145.html>`_ by setting ``initalOrientationAsReference`` to ``false``. We will also add some noise to the sensor configuration using Gazebo's `sensor noise model <http://gazebosim.org/tutorials?tut=sensor_noise>`_."


#: ../../setup_guides/odom/setup_odom.rst:96
msgid "Now, we will set up our IMU sensor plugin according to the description above by adding the following lines before the ``</robot>`` line in our URDF:"
msgstr "Now, we will set up our IMU sensor plugin according to the description above by adding the following lines before the ``</robot>`` line in our URDF:"


#: ../../setup_guides/odom/setup_odom.rst:192
msgid "Now, let us add the differential drive ModelPlugin. We will configure the plugin such that ``nav_msgs/Odometry`` messages are published on the ``/demo/odom`` topic. The joints of the left and right wheels will be set to the wheel joints of ``sam_bot``. The wheel separation and wheel diameter are set according to the values of the defined values of ``wheel_ygap`` and ``wheel_radius`` respectively."
msgstr "Now, let us add the differential drive ModelPlugin. We will configure the plugin such that ``nav_msgs/Odometry`` messages are published on the ``/demo/odom`` topic. The joints of the left and right wheels will be set to the wheel joints of ``sam_bot``. The wheel separation and wheel diameter are set according to the values of the defined values of ``wheel_ygap`` and ``wheel_radius`` respectively."


#: ../../setup_guides/odom/setup_odom.rst:194
msgid "To include this plugin in our URDF, add the following lines after the ``</gazebo>`` tag of the IMU plugin:"
msgstr "To include this plugin in our URDF, add the following lines after the ``</gazebo>`` tag of the IMU plugin:"


#: ../../setup_guides/odom/setup_odom.rst:229 ../../setup_guides/odom/setup_odom.rst:438 ../../setup_guides/sensors/setup_sensors.rst:219
msgid "Launch and Build Files"
msgstr "Launch and Build Files"


#: ../../setup_guides/odom/setup_odom.rst:231
msgid "We will now edit our launch file, `launch/display.launch.py <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/launch/display.launch.py>`_, to spawn ``sam_bot`` in Gazebo. Since we will be simulating our robot, we can remove the GUI for the joint state publisher by deleting the following lines inside the ``generate_launch_description()``:"
msgstr "We will now edit our launch file, `launch/display.launch.py <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/launch/display.launch.py>`_, to spawn ``sam_bot`` in Gazebo. Since we will be simulating our robot, we can remove the GUI for the joint state publisher by deleting the following lines inside the ``generate_launch_description()``:"


#: ../../setup_guides/odom/setup_odom.rst:242
msgid "Remove the following `gui` param:"
msgstr "Remove the following `gui` param:"


#: ../../setup_guides/odom/setup_odom.rst:249
msgid "Remove the condition from the `joint_state_publisher_node`:"
msgstr "Remove the condition from the `joint_state_publisher_node`:"


#: ../../setup_guides/odom/setup_odom.rst:260
msgid "Next, open `package.xml <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/package.xml>`_ and delete the line:"
msgstr "Next, open `package.xml <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/package.xml>`_ and delete the line:"


#: ../../setup_guides/odom/setup_odom.rst:266
msgid "To launch Gazebo, add the following before the ``joint_state_publisher_node,`` line"
msgstr "To launch Gazebo, add the following before the ``joint_state_publisher_node,`` line"


#: ../../setup_guides/odom/setup_odom.rst:272
msgid "We will now add a node that spawns ``sam_bot`` in Gazebo. Open `launch/display.launch.py <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/launch/display.launch.py>`_ again and paste the following lines before the ``return launch.LaunchDescription([`` line."
msgstr "We will now add a node that spawns ``sam_bot`` in Gazebo. Open `launch/display.launch.py <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/launch/display.launch.py>`_ again and paste the following lines before the ``return launch.LaunchDescription([`` line."


#: ../../setup_guides/odom/setup_odom.rst:283
msgid "Then add the line ``spawn_entity,`` before the ``rviz_node`` line, as shown below."
msgstr "Then add the line ``spawn_entity,`` before the ``rviz_node`` line, as shown below."


#: ../../setup_guides/odom/setup_odom.rst:296
msgid "Let us run our package to check if the ``/demo/imu`` and ``/demo/odom`` topics are active in the system."
msgstr "Let us run our package to check if the ``/demo/imu`` and ``/demo/odom`` topics are active in the system."


#: ../../setup_guides/odom/setup_odom.rst:298
msgid "Navigate to the root of the project and execute the following lines:"
msgstr "Navigate to the root of the project and execute the following lines:"


#: ../../setup_guides/odom/setup_odom.rst:306
msgid "Gazebo should launch and you should see a 3D model of ``sam_bot``:"
msgstr "Gazebo should launch and you should see a 3D model of ``sam_bot``:"


#: ../../setup_guides/odom/setup_odom.rst:312
msgid "To see the active topics in the system, open a new terminal and execute:"
msgstr "To see the active topics in the system, open a new terminal and execute:"


#: ../../setup_guides/odom/setup_odom.rst:318
msgid "You should see ``/demo/imu`` and ``/demo/odom`` in the list of topics."
msgstr "You should see ``/demo/imu`` and ``/demo/odom`` in the list of topics."


#: ../../setup_guides/odom/setup_odom.rst:320
msgid "To see more information about the topics, execute:"
msgstr "To see more information about the topics, execute:"


#: ../../setup_guides/odom/setup_odom.rst:327
msgid "You should see an output similar to below:"
msgstr "You should see an output similar to below:"


#: ../../setup_guides/odom/setup_odom.rst:341
msgid "Observe that the ``/demo/imu`` topic publishes ``sensor_msgs/Imu`` type messages while the ``/demo/odom`` topic publishes ``nav_msgs/Odometry`` type messages. The information being published on these topics come from the gazebo simulation of the IMU sensor and the differential drive respectively. Also note that both topics currently have no subscribers. In the next section, we will create a ``robot_localization`` node that will subscribe to these two topics. It will then use the messages published on both topics to provide a fused, locally accurate and smooth odometry information for Nav2."
msgstr "Observe that the ``/demo/imu`` topic publishes ``sensor_msgs/Imu`` type messages while the ``/demo/odom`` topic publishes ``nav_msgs/Odometry`` type messages. The information being published on these topics come from the gazebo simulation of the IMU sensor and the differential drive respectively. Also note that both topics currently have no subscribers. In the next section, we will create a ``robot_localization`` node that will subscribe to these two topics. It will then use the messages published on both topics to provide a fused, locally accurate and smooth odometry information for Nav2."


#: ../../setup_guides/odom/setup_odom.rst:344
msgid "Robot Localization Demo"
msgstr "Robot Localization Demo"


#: ../../setup_guides/odom/setup_odom.rst:346
msgid "The ``robot_localization`` package is used to provide a fused and locally accurate smooth odometry information from the data provided by ``N`` odometry sensor inputs. These information can be provided to the package through ``nav_msgs/Odometry``, ``sensor_msgs/Imu``, ``geometry_msgs/PoseWithCovarianceStamped``, and ``geometry_msgs/TwistWithCovarianceStamped`` messages."
msgstr "The ``robot_localization`` package is used to provide a fused and locally accurate smooth odometry information from the data provided by ``N`` odometry sensor inputs. These information can be provided to the package through ``nav_msgs/Odometry``, ``sensor_msgs/Imu``, ``geometry_msgs/PoseWithCovarianceStamped``, and ``geometry_msgs/TwistWithCovarianceStamped`` messages."


#: ../../setup_guides/odom/setup_odom.rst:348
msgid "A usual robot setup consists of at least the wheel encoders and IMU as its odometry sensor sources. When multiple sources are provided to ``robot_localization``, it is able to fuse the odometry information given by the sensors through the use of state estimation nodes. These nodes make use of either an Extended Kalman filter (``ekf_node``) or an Unscented Kalman Filter (``ukf_node``) to implement this fusion. In addition, the package also implements a ``navsat_transform_node`` which transforms geographic coordinates into the robot’s world frame when working with GPS."
msgstr "A usual robot setup consists of at least the wheel encoders and IMU as its odometry sensor sources. When multiple sources are provided to ``robot_localization``, it is able to fuse the odometry information given by the sensors through the use of state estimation nodes. These nodes make use of either an Extended Kalman filter (``ekf_node``) or an Unscented Kalman Filter (``ukf_node``) to implement this fusion. In addition, the package also implements a ``navsat_transform_node`` which transforms geographic coordinates into the robot’s world frame when working with GPS."


#: ../../setup_guides/odom/setup_odom.rst:350
msgid "Fused sensor data is published by the ``robot_localization`` package through the ``odometry/filtered`` and the ``accel/filtered`` topics, if enabled in its configuration. In addition, it can also publish the ``odom`` => ``base_link`` transform on the ``/tf`` topic."
msgstr "Fused sensor data is published by the ``robot_localization`` package through the ``odometry/filtered`` and the ``accel/filtered`` topics, if enabled in its configuration. In addition, it can also publish the ``odom`` => ``base_link`` transform on the ``/tf`` topic."


#: ../../setup_guides/odom/setup_odom.rst:353
msgid "More details on ``robot_localization`` can be found in the official `Robot Localization Documentation <http://docs.ros.org/en/noetic/api/robot_localization/html/index.html>`_."
msgstr "More details on ``robot_localization`` can be found in the official `Robot Localization Documentation <http://docs.ros.org/en/noetic/api/robot_localization/html/index.html>`_."


#: ../../setup_guides/odom/setup_odom.rst:355
msgid "If your robot is only able to provide one odometry source, the use of ``robot_localization`` would have minimal effects aside from smoothing. In this case, an alternative approach is to publish transforms through a tf2 broadcaster in your single source of odometry node. Nevertheless, you can still opt to use ``robot_localization`` to publish the transforms and some smoothing properties may still be observed in the output."
msgstr "If your robot is only able to provide one odometry source, the use of ``robot_localization`` would have minimal effects aside from smoothing. In this case, an alternative approach is to publish transforms through a tf2 broadcaster in your single source of odometry node. Nevertheless, you can still opt to use ``robot_localization`` to publish the transforms and some smoothing properties may still be observed in the output."


#: ../../setup_guides/odom/setup_odom.rst:358
msgid "For more information on how to write a tf2 broadcaster, you can check Writing a tf2 broadcaster `(C++)  <https://docs.ros.org/en/rolling/Tutorials/Tf2/Writing-A-Tf2-Broadcaster-Cpp.html>`_  `(Python)  <https://docs.ros.org/en/rolling/Tutorials/Tf2/Writing-A-Tf2-Broadcaster-Py.html>`_."
msgstr "For more information on how to write a tf2 broadcaster, you can check Writing a tf2 broadcaster `(C++)  <https://docs.ros.org/en/rolling/Tutorials/Tf2/Writing-A-Tf2-Broadcaster-Cpp.html>`_  `(Python)  <https://docs.ros.org/en/rolling/Tutorials/Tf2/Writing-A-Tf2-Broadcaster-Py.html>`_."


#: ../../setup_guides/odom/setup_odom.rst:360
msgid "For the rest of this section, we will show how to use ``robot_localization`` to fuse the sensors of ``sam_bot``. It will use the ``sensor_msgs/Imu`` messages published on ``/demo/Imu`` and the ``nav_msgs/Odometry`` message published on ``/demo/odom`` and then it will publish data on ``odometry/filtered``,  ``accel/filtered``, and ``/tf`` topics."
msgstr "For the rest of this section, we will show how to use ``robot_localization`` to fuse the sensors of ``sam_bot``. It will use the ``sensor_msgs/Imu`` messages published on ``/demo/Imu`` and the ``nav_msgs/Odometry`` message published on ``/demo/odom`` and then it will publish data on ``odometry/filtered``,  ``accel/filtered``, and ``/tf`` topics."


#: ../../setup_guides/odom/setup_odom.rst:363
msgid "Configuring Robot Localization"
msgstr "Configuring Robot Localization"


#: ../../setup_guides/odom/setup_odom.rst:365
msgid "Let us now configure the ``robot_localization`` package to use an Extended Kalman Filter (``ekf_node``) to fuse odometry information and publish the ``odom`` => ``base_link`` transform."
msgstr "Let us now configure the ``robot_localization`` package to use an Extended Kalman Filter (``ekf_node``) to fuse odometry information and publish the ``odom`` => ``base_link`` transform."


#: ../../setup_guides/odom/setup_odom.rst:367
msgid "First, install the ``robot_localization`` package using your machines package manager or by executing the following command:"
msgstr "First, install the ``robot_localization`` package using your machines package manager or by executing the following command:"


#: ../../setup_guides/odom/setup_odom.rst:373
msgid "Next, we specify the parameters of the ``ekf_node`` using a YAML file. Create a directory named ``config`` at the root of your project and create a file named ``ekf.yaml``. Copy the following lines of code into your ``ekf.yaml`` file."
msgstr "Next, we specify the parameters of the ``ekf_node`` using a YAML file. Create a directory named ``config`` at the root of your project and create a file named ``ekf.yaml``. Copy the following lines of code into your ``ekf.yaml`` file."


#: ../../setup_guides/odom/setup_odom.rst:425
msgid "In this configuration, we defined the parameter values of ``frequency``, ``two_d_mode``, ``publish_acceleration``, ``publish_tf``, ``map_frame``, ``odom_frame``, ``base_link_frame``, and ``world_frame``. For more information on the other parameters you can modify, see `Parameters of state estimation nodes <http://docs.ros.org/en/melodic/api/robot_localization/html/state_estimation_nodes.html#parameters>`_, and a sample ``efk.yaml`` can be found `here <https://github.com/cra-ros-pkg/robot_localization/blob/foxy-devel/params/ekf.yaml>`_."
msgstr "In this configuration, we defined the parameter values of ``frequency``, ``two_d_mode``, ``publish_acceleration``, ``publish_tf``, ``map_frame``, ``odom_frame``, ``base_link_frame``, and ``world_frame``. For more information on the other parameters you can modify, see `Parameters of state estimation nodes <http://docs.ros.org/en/melodic/api/robot_localization/html/state_estimation_nodes.html#parameters>`_, and a sample ``efk.yaml`` can be found `here <https://github.com/cra-ros-pkg/robot_localization/blob/foxy-devel/params/ekf.yaml>`_."


#: ../../setup_guides/odom/setup_odom.rst:427
msgid "To add a sensor input to the ``ekf_filter_node``, add the next number in the sequence to its base name (odom, imu, pose, twist). In our case, we have one ``nav_msgs/Odometry`` and one ``sensor_msgs/Imu`` as inputs to the filter, thus we use ``odom0`` and ``imu0``. We set the value of ``odom0`` to ``demo/odom``, which is the topic that publishes the ``nav_msgs/Odometry``. Similarly, we set the value of ``imu0`` to the topic that publishes ``sensor_msgs/Imu``, which is ``demo/imu``."
msgstr "To add a sensor input to the ``ekf_filter_node``, add the next number in the sequence to its base name (odom, imu, pose, twist). In our case, we have one ``nav_msgs/Odometry`` and one ``sensor_msgs/Imu`` as inputs to the filter, thus we use ``odom0`` and ``imu0``. We set the value of ``odom0`` to ``demo/odom``, which is the topic that publishes the ``nav_msgs/Odometry``. Similarly, we set the value of ``imu0`` to the topic that publishes ``sensor_msgs/Imu``, which is ``demo/imu``."


#: ../../setup_guides/odom/setup_odom.rst:429
msgid "You can specify which values from a sensor are to be used by the filter using the ``_config`` parameter. The order of the values of this parameter is x, y, z, roll, pitch, yaw, vx, vy, vz, vroll, vpitch, vyaw, ax, ay, az. In our example, we set everything in ``odom0_config`` to ``false`` except the 1st, 2nd, 3rd, and 12th entries, which means the filter will only use the x, y, z, and the vyaw values of ``odom0``."
msgstr "You can specify which values from a sensor are to be used by the filter using the ``_config`` parameter. The order of the values of this parameter is x, y, z, roll, pitch, yaw, vx, vy, vz, vroll, vpitch, vyaw, ax, ay, az. In our example, we set everything in ``odom0_config`` to ``false`` except the 1st, 2nd, 3rd, and 12th entries, which means the filter will only use the x, y, z, and the vyaw values of ``odom0``."


#: ../../setup_guides/odom/setup_odom.rst:431
msgid "In the ``imu0_config`` matrix, you'll notice that only roll, pitch, and yaw are used. Typical mobile robot-grade IMUs will also provide angular velocities and linear accelerations. For ``robot_localization`` to work properly, you should not fuse in multiple fields that are derivative of each other. Since angular velocity is fused internally to the IMU to provide the roll, pitch and yaw estimates, we should not fuse in the angular velocities used to derive that information. We also do not fuse in angular velocity due to the noisy characteristics it has when not using exceptionally high quality (and expensive) IMUs."
msgstr "In the ``imu0_config`` matrix, you'll notice that only roll, pitch, and yaw are used. Typical mobile robot-grade IMUs will also provide angular velocities and linear accelerations. For ``robot_localization`` to work properly, you should not fuse in multiple fields that are derivative of each other. Since angular velocity is fused internally to the IMU to provide the roll, pitch and yaw estimates, we should not fuse in the angular velocities used to derive that information. We also do not fuse in angular velocity due to the noisy characteristics it has when not using exceptionally high quality (and expensive) IMUs."


#: ../../setup_guides/odom/setup_odom.rst:434
msgid "For more advise on configuration of input data to ``robot_localization``, see `Preparing Your Data for Use with robot_localization <http://docs.ros.org/en/melodic/api/robot_localization/html/preparing_sensor_data.html#odometry>`_, and `Configuring robot_localization <http://docs.ros.org/en/melodic/api/robot_localization/html/configuring_robot_localization.html>`_."
msgstr "For more advise on configuration of input data to ``robot_localization``, see `Preparing Your Data for Use with robot_localization <http://docs.ros.org/en/melodic/api/robot_localization/html/preparing_sensor_data.html#odometry>`_, and `Configuring robot_localization <http://docs.ros.org/en/melodic/api/robot_localization/html/configuring_robot_localization.html>`_."


#: ../../setup_guides/odom/setup_odom.rst:440
msgid "Now, let us add the ``ekf_node`` into the launch file. Open ``launch/display.launch.py`` and paste the following lines before the ``return launch.LaunchDescription([`` line."
msgstr "Now, let us add the ``ekf_node`` into the launch file. Open ``launch/display.launch.py`` and paste the following lines before the ``return launch.LaunchDescription([`` line."


#: ../../setup_guides/odom/setup_odom.rst:452
msgid "Next, add the following launch arguments within the ``return launch.LaunchDescription([`` block."
msgstr "Next, add the following launch arguments within the ``return launch.LaunchDescription([`` block."


#: ../../setup_guides/odom/setup_odom.rst:459
msgid "Lastly, add ``robot_localization_node,`` above the ``rviz_node`` line to launch the robot localization node."
msgstr "Lastly, add ``robot_localization_node,`` above the ``rviz_node`` line to launch the robot localization node."


#: ../../setup_guides/odom/setup_odom.rst:469
msgid "Next, we need to add the ``robot_localization`` dependency to our package definition. Open ``package.xml`` and add the following line below the last ``<exec_depend>`` tag."
msgstr "Next, we need to add the ``robot_localization`` dependency to our package definition. Open ``package.xml`` and add the following line below the last ``<exec_depend>`` tag."


#: ../../setup_guides/odom/setup_odom.rst:475
msgid "Lastly, open ``CMakeLists.txt`` and append the ``config`` directory inside the ``install(DIRECTORY...)``, as shown in the snippet below."
msgstr "Lastly, open ``CMakeLists.txt`` and append the ``config`` directory inside the ``install(DIRECTORY...)``, as shown in the snippet below."


#: ../../setup_guides/odom/setup_odom.rst:488
msgid "Let us now build and run our package. Navigate to the root of the project and execute the following lines:"
msgstr "Let us now build and run our package. Navigate to the root of the project and execute the following lines:"


#: ../../setup_guides/odom/setup_odom.rst:496
msgid "Gazebo and RVIZ should launch. In the RVIZ window, you should see the model and TF frames of ``sam_bot``:"
msgstr "Gazebo and RVIZ should launch. In the RVIZ window, you should see the model and TF frames of ``sam_bot``:"


#: ../../setup_guides/odom/setup_odom.rst:502
msgid "Next, let us verify that the ``odometry/filtered``,  ``accel/filtered``, and ``/tf`` topics are active in the system. Open a new terminal and execute:"
msgstr "Next, let us verify that the ``odometry/filtered``,  ``accel/filtered``, and ``/tf`` topics are active in the system. Open a new terminal and execute:"


#: ../../setup_guides/odom/setup_odom.rst:508
msgid "You should see ``odometry/filtered``, ``accel/filtered``, and ``/tf`` in the list of the topics."
msgstr "You should see ``odometry/filtered``, ``accel/filtered``, and ``/tf`` in the list of the topics."


#: ../../setup_guides/odom/setup_odom.rst:510
msgid "You can also check the subscriber count of these topics again by executing:"
msgstr "You can also check the subscriber count of these topics again by executing:"


#: ../../setup_guides/odom/setup_odom.rst:517
msgid "You should see that ``/demo/imu`` and ``/demo/odom`` now both have 1 subscriber each."
msgstr "You should see that ``/demo/imu`` and ``/demo/odom`` now both have 1 subscriber each."


#: ../../setup_guides/odom/setup_odom.rst:519
msgid "To verify that the ``ekf_filter_node`` are the subscribers of these topics, execute:"
msgstr "To verify that the ``ekf_filter_node`` are the subscribers of these topics, execute:"


#: ../../setup_guides/odom/setup_odom.rst:525
msgid "You should see an output as shown below."
msgstr "You should see an output as shown below."


#: ../../setup_guides/odom/setup_odom.rst:545
msgid "From the output above, we can see that the ``ekf_filter_node`` is subscribed to ``/demo/imu`` and ``/demo/odom``. We can also see that the ``ekf_filter_node`` publishes on the ``odometry/filtered``, ``accel/filtered``, and ``/tf`` topics."
msgstr "From the output above, we can see that the ``ekf_filter_node`` is subscribed to ``/demo/imu`` and ``/demo/odom``. We can also see that the ``ekf_filter_node`` publishes on the ``odometry/filtered``, ``accel/filtered``, and ``/tf`` topics."


#: ../../setup_guides/odom/setup_odom.rst:547
msgid "You may also verify that ``robot_localization`` is publishing the ``odom`` => ``base_link`` transform by using the tf2_echo utility. Run the folllowing command in a separate command line terminal:"
msgstr "You may also verify that ``robot_localization`` is publishing the ``odom`` => ``base_link`` transform by using the tf2_echo utility. Run the folllowing command in a separate command line terminal:"


#: ../../setup_guides/odom/setup_odom.rst:553
msgid "You should see a continuous output similar to what is shown below."
msgstr "You should see a continuous output similar to what is shown below."


#: ../../setup_guides/odom/setup_odom.rst:567
msgid "In this guide, we have discussed the messages and transforms that are expected by Nav2 from the odometry system. We have seen how to set up an odometry system and how to verify the published messages. We also have discussed how multiple odometry sensors can be used to provide a filtered and smoothed odometry using ``robot_localization``. We have also checked if the ``odom`` => ``base_link`` transform is being published correctly by ``robot_localization``."
msgstr "In this guide, we have discussed the messages and transforms that are expected by Nav2 from the odometry system. We have seen how to set up an odometry system and how to verify the published messages. We also have discussed how multiple odometry sensors can be used to provide a filtered and smoothed odometry using ``robot_localization``. We have also checked if the ``odom`` => ``base_link`` transform is being published correctly by ``robot_localization``."


#: ../../setup_guides/sensors/setup_sensors.rst:4
msgid "Setting Up Sensors"
msgstr "Setting Up Sensors"


#: ../../setup_guides/sensors/setup_sensors.rst:6
msgid "In this guide, we will discuss the importance of the sensors in navigating a robot safely and how to set up the sensors with Nav2. In the first half of this tutorial, we will take a brief look at commonly used sensors and common sensor messages in Nav2. Next, we will add a basic sensor setup on our previously built simulated robot, ``sam_bot``. Lastly, we will then verify the simulated sensor messages of ``sam_bot`` by visualizing them in RViz."
msgstr "In this guide, we will discuss the importance of the sensors in navigating a robot safely and how to set up the sensors with Nav2. In the first half of this tutorial, we will take a brief look at commonly used sensors and common sensor messages in Nav2. Next, we will add a basic sensor setup on our previously built simulated robot, ``sam_bot``. Lastly, we will then verify the simulated sensor messages of ``sam_bot`` by visualizing them in RViz."


#: ../../setup_guides/sensors/setup_sensors.rst:8
msgid "Once sensors have been set up on a robot, their readings can be used in mapping, localization, and perception tasks. In the second half of this guide, we will first discuss how mapping and localization use the sensor data. Then, we will also take a look at one of Nav2's packages, ``nav2_costmap_2d``, which generates costmaps that will eventually be used in Nav2 path planning. We will set up basic configuration parameters for this package so it properly takes in sensor information from ``sam_bot``. Lastly, we visualize a generated costmaps in RViz to verify its received data."
msgstr "Once sensors have been set up on a robot, their readings can be used in mapping, localization, and perception tasks. In the second half of this guide, we will first discuss how mapping and localization use the sensor data. Then, we will also take a look at one of Nav2's packages, ``nav2_costmap_2d``, which generates costmaps that will eventually be used in Nav2 path planning. We will set up basic configuration parameters for this package so it properly takes in sensor information from ``sam_bot``. Lastly, we visualize a generated costmaps in RViz to verify its received data."


#: ../../setup_guides/sensors/setup_sensors.rst:11
msgid "Sensor Introduction"
msgstr "Sensor Introduction"


#: ../../setup_guides/sensors/setup_sensors.rst:12
msgid "Mobile robots are equipped with a multitude of sensors that allow them to see and perceive their environment. These sensors obtain information which can be used to build and maintain the map of the environment, to localize the robot on the map, and to see the obstacles in the environment. These tasks are essential to be able to safely and efficiently navigate a robot through a dynamic environment."
msgstr "Mobile robots are equipped with a multitude of sensors that allow them to see and perceive their environment. These sensors obtain information which can be used to build and maintain the map of the environment, to localize the robot on the map, and to see the obstacles in the environment. These tasks are essential to be able to safely and efficiently navigate a robot through a dynamic environment."


#: ../../setup_guides/sensors/setup_sensors.rst:14
msgid "Examples of commonly used sensors are lidar, radar, RGB camera, depth camera, IMU, and GPS. To standardize the message formats of these sensors and allow for easier interoperation between vendors, ROS provides the ``sensor_msgs`` package that defines the common sensor interfaces. This also allows users to use any sensor vendor as long as it follows the standard format in ``sensor_msgs``. In the next subsection, we introduce some of commonly used messages in navigation, namely the ``sensor_msgs/LaserScan``, ``sensor_msgs/PointCloud2``, ``sensor_msgs/Range``, and ``sensor_msgs/Image``."
msgstr "Examples of commonly used sensors are lidar, radar, RGB camera, depth camera, IMU, and GPS. To standardize the message formats of these sensors and allow for easier interoperation between vendors, ROS provides the ``sensor_msgs`` package that defines the common sensor interfaces. This also allows users to use any sensor vendor as long as it follows the standard format in ``sensor_msgs``. In the next subsection, we introduce some of commonly used messages in navigation, namely the ``sensor_msgs/LaserScan``, ``sensor_msgs/PointCloud2``, ``sensor_msgs/Range``, and ``sensor_msgs/Image``."


#: ../../setup_guides/sensors/setup_sensors.rst:16
msgid "Aside from the ``sensor_msgs`` package, there are also the ``radar_msgs`` and ``vision_msgs`` standard interfaces you should be aware of.  The ``radar_msgs`` defines the messages for radar-specific sensors while the ``vision_msgs`` package defines the messages used in computer vision such as object detection, segmentation, and other machine learning models. Messages supported by this package are ``vision_msgs/Classification2D``, ``vision_msgs/Classification3D``, ``vision_msgs/Detection2D``, and ``vision_msgs/Detection3D``, to name a few."
msgstr "Aside from the ``sensor_msgs`` package, there are also the ``radar_msgs`` and ``vision_msgs`` standard interfaces you should be aware of.  The ``radar_msgs`` defines the messages for radar-specific sensors while the ``vision_msgs`` package defines the messages used in computer vision such as object detection, segmentation, and other machine learning models. Messages supported by this package are ``vision_msgs/Classification2D``, ``vision_msgs/Classification3D``, ``vision_msgs/Detection2D``, and ``vision_msgs/Detection3D``, to name a few."


#: ../../setup_guides/sensors/setup_sensors.rst:19
msgid "For more information, see the API documentation of `sensor_msgs <http://wiki.ros.org/sensor_msgs>`_, `radar_msgs <http://wiki.ros.org/radar_msgs>`_, and `vision_msgs <http://wiki.ros.org/vision_msgs>`_."
msgstr "For more information, see the API documentation of `sensor_msgs <http://wiki.ros.org/sensor_msgs>`_, `radar_msgs <http://wiki.ros.org/radar_msgs>`_, and `vision_msgs <http://wiki.ros.org/vision_msgs>`_."


#: ../../setup_guides/sensors/setup_sensors.rst:21
msgid "Your physical robot's sensors probably have ROS drivers written for them (e.g. a ROS node that connects to the sensors, populates data into messages, and publishes them for your robot to use) that follow the standard interface in the ``sensor_msgs`` package. The ``sensor_msgs`` package makes it easy for you to use many different sensors from different manufacturers. General software packages like Nav2 can then can read these standardized messages and perform tasks independent of the sensor hardware. On simulated robots such as ``sam_bot``, Gazebo has sensor plugins which also publish their information following the ``sensor_msgs`` package."
msgstr "Your physical robot's sensors probably have ROS drivers written for them (e.g. a ROS node that connects to the sensors, populates data into messages, and publishes them for your robot to use) that follow the standard interface in the ``sensor_msgs`` package. The ``sensor_msgs`` package makes it easy for you to use many different sensors from different manufacturers. General software packages like Nav2 can then can read these standardized messages and perform tasks independent of the sensor hardware. On simulated robots such as ``sam_bot``, Gazebo has sensor plugins which also publish their information following the ``sensor_msgs`` package."


#: ../../setup_guides/sensors/setup_sensors.rst:24
msgid "Common Sensor Messages"
msgstr "Common Sensor Messages"


#: ../../setup_guides/sensors/setup_sensors.rst:26
msgid "In this subsection, we discuss some of the common types of ``sensor_msgs`` you might encounter when setting up Nav2. We will provide a brief description for each sensor, an image of it being simulated in Gazebo and the corresponding visualization of the sensor readings in RViz."
msgstr "In this subsection, we discuss some of the common types of ``sensor_msgs`` you might encounter when setting up Nav2. We will provide a brief description for each sensor, an image of it being simulated in Gazebo and the corresponding visualization of the sensor readings in RViz."


#: ../../setup_guides/sensors/setup_sensors.rst:28
msgid "There are other types of ``sensor_msgs`` aside from the ones listed below.  The complete list of messages and their definitions can be found in the `sensor_msgs documentation <http://wiki.ros.org/sensor_msgs>`_."
msgstr "There are other types of ``sensor_msgs`` aside from the ones listed below.  The complete list of messages and their definitions can be found in the `sensor_msgs documentation <http://wiki.ros.org/sensor_msgs>`_."


#: ../../setup_guides/sensors/setup_sensors.rst:31
msgid "sensor_msgs/LaserScan"
msgstr "sensor_msgs/LaserScan"


#: ../../setup_guides/sensors/setup_sensors.rst:33
msgid "This message represents a single scan from a planar laser range-finder. This message is used in ``slam_toolbox`` and ``nav2_amcl`` for localization and mapping, or in ``nav2_costmap_2d`` for perception."
msgstr "This message represents a single scan from a planar laser range-finder. This message is used in ``slam_toolbox`` and ``nav2_amcl`` for localization and mapping, or in ``nav2_costmap_2d`` for perception."


#: ../../setup_guides/sensors/setup_sensors.rst:38
msgid "sensor_msgs/PointCloud2"
msgstr "sensor_msgs/PointCloud2"


#: ../../setup_guides/sensors/setup_sensors.rst:40
msgid "This message holds a collection of 3D points, plus optional additional information about each point. This can be from a 3D lidar, a 2D lidar, a depth camera or more."
msgstr "This message holds a collection of 3D points, plus optional additional information about each point. This can be from a 3D lidar, a 2D lidar, a depth camera or more."


#: ../../setup_guides/sensors/setup_sensors.rst:45
msgid "sensor_msgs/Range"
msgstr "sensor_msgs/Range"


#: ../../setup_guides/sensors/setup_sensors.rst:47
msgid "This is a single range reading from an active ranger that emits energy and reports one range reading that is valid along an arc at the distance measured. A sonar, IR sensor, or 1D range finder are examples of sensors that use this message."
msgstr "This is a single range reading from an active ranger that emits energy and reports one range reading that is valid along an arc at the distance measured. A sonar, IR sensor, or 1D range finder are examples of sensors that use this message."


#: ../../setup_guides/sensors/setup_sensors.rst:52
msgid "sensor_msgs/Image"
msgstr "sensor_msgs/Image"


#: ../../setup_guides/sensors/setup_sensors.rst:54
msgid "This represents the sensor readings from RGB or depth camera, corresponding to RGB or range values."
msgstr "This represents the sensor readings from RGB or depth camera, corresponding to RGB or range values."


#: ../../setup_guides/sensors/setup_sensors.rst:59
msgid "Simulating Sensors using Gazebo"
msgstr "Simulating Sensors using Gazebo"


#: ../../setup_guides/sensors/setup_sensors.rst:60
msgid "To give you a better grasp of how to set up sensors on a simulated robot, we will build up on our previous tutorials and attach sensors to our simulated robot ``sam_bot``. Similar to the previous tutorial where we used Gazebo plugins to add odometry sensors to ``sam_bot``, we will be using the Gazebo plugins to simulate a lidar sensor and a depth camera on ``sam_bot``. If you are working with a real robot, most of these steps are still required for setting up your URDF frames and it will not hurt to also add in the gazebo plugins for later use."
msgstr "To give you a better grasp of how to set up sensors on a simulated robot, we will build up on our previous tutorials and attach sensors to our simulated robot ``sam_bot``. Similar to the previous tutorial where we used Gazebo plugins to add odometry sensors to ``sam_bot``, we will be using the Gazebo plugins to simulate a lidar sensor and a depth camera on ``sam_bot``. If you are working with a real robot, most of these steps are still required for setting up your URDF frames and it will not hurt to also add in the gazebo plugins for later use."


#: ../../setup_guides/sensors/setup_sensors.rst:62
msgid "To be able to follow the rest of this section, make sure that you have properly installed Gazebo. You can follow the instructions at the `Setup and Prerequisites <https://navigation.ros.org/setup_guides/odom/setup_odom.html#setup-and-prerequisites>`_ of the previous tutorial to setup Gazebo."
msgstr "To be able to follow the rest of this section, make sure that you have properly installed Gazebo. You can follow the instructions at the `Setup and Prerequisites <https://navigation.ros.org/setup_guides/odom/setup_odom.html#setup-and-prerequisites>`_ of the previous tutorial to setup Gazebo."


#: ../../setup_guides/sensors/setup_sensors.rst:68
msgid "Let us first add a lidar sensor to ``sam_bot``. Open the URDF file, `src/description/sam_bot_description.urdf <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/src/description/sam_bot_description.urdf>`_ and paste the following lines before the ``</robot>`` tag."
msgstr "Let us first add a lidar sensor to ``sam_bot``. Open the URDF file, `src/description/sam_bot_description.urdf <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/src/description/sam_bot_description.urdf>`_ and paste the following lines before the ``</robot>`` tag."


#: ../../setup_guides/sensors/setup_sensors.rst:136
msgid "In the code snippet above, we create a ``lidar_link`` which will be referenced by the ``gazebo_ros_ray_sensor`` plugin as the location to attach our sensor. We also set values to the simulated lidar's scan and range properties. Lastly, we set the ``/scan`` as the topic to which it will publish the ``sensor_msgs/LaserScan`` messages."
msgstr "In the code snippet above, we create a ``lidar_link`` which will be referenced by the ``gazebo_ros_ray_sensor`` plugin as the location to attach our sensor. We also set values to the simulated lidar's scan and range properties. Lastly, we set the ``/scan`` as the topic to which it will publish the ``sensor_msgs/LaserScan`` messages."


#: ../../setup_guides/sensors/setup_sensors.rst:138
msgid "Next, let us add a depth camera to ``sam_bot``. Paste the following lines after the ``</gazebo>`` tag of the lidar sensor."
msgstr "Next, let us add a depth camera to ``sam_bot``. Paste the following lines after the ``</gazebo>`` tag of the lidar sensor."


#: ../../setup_guides/sensors/setup_sensors.rst:216
msgid "Similar to the lidar sensor, we create ``camera_link`` which will be referenced by the ``gazebo_ros_camera`` plugin as the sensor attachment location. We also create a ``camera_depth_frame`` that is attached to the ``camera_link`` and will be set as the ``<frame_name>`` of the depth camera plugin.  We also configure the plugin such that it will publish ``sensor_msgs/Image`` and ``sensor_msgs/PointCloud2`` messages to ``/depth_camera/image_raw`` and  ``/depth_camera/points`` topics respectively. Lastly, we also set up other basic configuration properties for our depth camera."
msgstr "Similar to the lidar sensor, we create ``camera_link`` which will be referenced by the ``gazebo_ros_camera`` plugin as the sensor attachment location. We also create a ``camera_depth_frame`` that is attached to the ``camera_link`` and will be set as the ``<frame_name>`` of the depth camera plugin.  We also configure the plugin such that it will publish ``sensor_msgs/Image`` and ``sensor_msgs/PointCloud2`` messages to ``/depth_camera/image_raw`` and  ``/depth_camera/points`` topics respectively. Lastly, we also set up other basic configuration properties for our depth camera."


#: ../../setup_guides/sensors/setup_sensors.rst:221
msgid "To verify that the sensors are set up properly and that they can see objects in our environemnt, let us launch ``sam_bot`` in a Gazebo world with objects. Let us create a Gazebo world with a single cube and a single sphere that are within the range of ``sam_bot``'s sensors so we can verify if it can see the objects correctly."
msgstr "To verify that the sensors are set up properly and that they can see objects in our environemnt, let us launch ``sam_bot`` in a Gazebo world with objects. Let us create a Gazebo world with a single cube and a single sphere that are within the range of ``sam_bot``'s sensors so we can verify if it can see the objects correctly."


#: ../../setup_guides/sensors/setup_sensors.rst:224
msgid "To create the world, create a directory named ``world`` at the root of your project and create a file named ``my_world.sdf`` inside the ``world`` folder . Then copy the contents of `world/my_world.sdf <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/world/my_world.sdf>`_ and paste them inside ``my_world.sdf``."
msgstr "To create the world, create a directory named ``world`` at the root of your project and create a file named ``my_world.sdf`` inside the ``world`` folder . Then copy the contents of `world/my_world.sdf <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/world/my_world.sdf>`_ and paste them inside ``my_world.sdf``."


#: ../../setup_guides/sensors/setup_sensors.rst:226
msgid "Now, let us edit our launch file, `launch/display.launch.py <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/launch/display.launch.py>`_, to launch Gazebo with the world we just created. First, add the path of ``my_world.sdf`` by adding the following lines inside the ``generate_launch_description()``:"
msgstr "Now, let us edit our launch file, `launch/display.launch.py <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/launch/display.launch.py>`_, to launch Gazebo with the world we just created. First, add the path of ``my_world.sdf`` by adding the following lines inside the ``generate_launch_description()``:"


#: ../../setup_guides/sensors/setup_sensors.rst:232
msgid "Lastly, add the world path in the ``launch.actions.ExecuteProcess(cmd=['gazebo',...`` line, as shown below."
msgstr "Lastly, add the world path in the ``launch.actions.ExecuteProcess(cmd=['gazebo',...`` line, as shown below."


#: ../../setup_guides/sensors/setup_sensors.rst:238
msgid "We also have to add the ``world`` directory to our ``CMakeLists.txt`` file. Open `CmakeLists.txt <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/CMakeLists.txt>`_ and append the ``world`` directory inside the install(DIRECTORY...), as shown in the snippet below."
msgstr "We also have to add the ``world`` directory to our ``CMakeLists.txt`` file. Open `CmakeLists.txt <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/CMakeLists.txt>`_ and append the ``world`` directory inside the install(DIRECTORY...), as shown in the snippet below."


#: ../../setup_guides/sensors/setup_sensors.rst:250
msgid "We can now build and run our project. Navigate to the root of the project and execute the following lines:"
msgstr "We can now build and run our project. Navigate to the root of the project and execute the following lines:"


#: ../../setup_guides/sensors/setup_sensors.rst:258
msgid "RViz and the Gazebo will then be launched with ``sam_bot`` present in both. In the Gazebo window, the world that we created should be launched and ``sam_bot`` should be spawned in that world. You should now be able to observe ``sam_bot`` with the 360 lidar sensor and the depth camera, as shown in the image below."
msgstr "RViz and the Gazebo will then be launched with ``sam_bot`` present in both. In the Gazebo window, the world that we created should be launched and ``sam_bot`` should be spawned in that world. You should now be able to observe ``sam_bot`` with the 360 lidar sensor and the depth camera, as shown in the image below."


#: ../../setup_guides/sensors/setup_sensors.rst:263
msgid "In the RViz window, we can verify if we have properly modeled our sensors and if the transforms of our newly added sensors are correct:"
msgstr "In the RViz window, we can verify if we have properly modeled our sensors and if the transforms of our newly added sensors are correct:"


#: ../../setup_guides/sensors/setup_sensors.rst:268
msgid "Lastly, we can also visualize the sensor readings in RViz.  To visualize the ``sensor_msgs/LaserScan`` message published on ``/scan`` topic, click the add button at the bottom part of the RViz window. Then go to the ``By topic`` tab and select the ``LaserScan`` option under ``/scan``, as shown below."
msgstr "Lastly, we can also visualize the sensor readings in RViz.  To visualize the ``sensor_msgs/LaserScan`` message published on ``/scan`` topic, click the add button at the bottom part of the RViz window. Then go to the ``By topic`` tab and select the ``LaserScan`` option under ``/scan``, as shown below."


#: ../../setup_guides/sensors/setup_sensors.rst:274
msgid "Next, set the ``Reliability Policy`` in RViz to ``Best Effort`` and set the ``size`` to 0.1 to see the points clearer. You should see the visualized ``LaserScan`` detection as shown below. This corresponds to the detected cube and sphere that we added to the Gazebo world."
msgstr "Next, set the ``Reliability Policy`` in RViz to ``Best Effort`` and set the ``size`` to 0.1 to see the points clearer. You should see the visualized ``LaserScan`` detection as shown below. This corresponds to the detected cube and sphere that we added to the Gazebo world."


#: ../../setup_guides/sensors/setup_sensors.rst:279
msgid "To visualize ``sensor_msgs/Image`` and ``sensor_msgs/PointCloud2``, do the same for topics ``/depth_camera/image_raw`` and ``/depth_camera/points`` respectively:"
msgstr "To visualize ``sensor_msgs/Image`` and ``sensor_msgs/PointCloud2``, do the same for topics ``/depth_camera/image_raw`` and ``/depth_camera/points`` respectively:"


#: ../../setup_guides/sensors/setup_sensors.rst:283
msgid "After adding the ``/depth_camera/image_raw`` topic in RViz, set the ``Reliability Policy`` in RViz to ``Best Effort``. Then you should see the cube in the image window at the lower-left side of the RViz window, as shown below."
msgstr "After adding the ``/depth_camera/image_raw`` topic in RViz, set the ``Reliability Policy`` in RViz to ``Best Effort``. Then you should see the cube in the image window at the lower-left side of the RViz window, as shown below."


#: ../../setup_guides/sensors/setup_sensors.rst:288
msgid "You should also see the ``sensor_msgs/PointCloud2``, as shown below."
msgstr "You should also see the ``sensor_msgs/PointCloud2``, as shown below."


#: ../../setup_guides/sensors/setup_sensors.rst:295
msgid "Mapping and Localization"
msgstr "Mapping and Localization"


#: ../../setup_guides/sensors/setup_sensors.rst:296
msgid "Now that we have a robot with its sensors set up, we can use the obtained sensor information to build a map of the environment and to localize the robot on the map. The ``slam_toolbox`` package is a set of tools and capabilities for 2D Simultaneous Localization and Mapping (SLAM) in potentially massive maps with ROS2. It is also one of the officially supported SLAM libraries in Nav2, and we recommend to use this package in situations you need to use SLAM on your robot setup. Aside from the ``slam_toolbox``, localization can also be implemented through the ``nav2_amcl`` package. This package implements Adaptive Monte Carlo Localization (AMCL) which estimates the position and orientation of the robot in a map. Other techniques may also be available, please check Nav2 documentation for more information."
msgstr "Now that we have a robot with its sensors set up, we can use the obtained sensor information to build a map of the environment and to localize the robot on the map. The ``slam_toolbox`` package is a set of tools and capabilities for 2D Simultaneous Localization and Mapping (SLAM) in potentially massive maps with ROS2. It is also one of the officially supported SLAM libraries in Nav2, and we recommend to use this package in situations you need to use SLAM on your robot setup. Aside from the ``slam_toolbox``, localization can also be implemented through the ``nav2_amcl`` package. This package implements Adaptive Monte Carlo Localization (AMCL) which estimates the position and orientation of the robot in a map. Other techniques may also be available, please check Nav2 documentation for more information."


#: ../../setup_guides/sensors/setup_sensors.rst:298
msgid "Both the ``slam_toolbox`` and ``nav2_amcl`` use information from the laser scan sensor to be able to perceive the robot's environment. Hence, to verify that they can access the laser scan sensor readings, we must make sure that they are subscribed to the correct topic that publishes the ``sensor_msgs/LaserScan`` message. This can be configured by setting their ``scan_topic`` parameters to the topic that publishes that message. It is a convention to publish the ``sensor_msgs/LaserScan`` messages to  ``/scan`` topic. Thus, by default, the ``scan_topic`` parameter is set to ``/scan``. Recall that when we added the lidar sensor to ``sam_bot`` in the previous section, we set the topic to which the lidar sensor will publish the ``sensor_msgs/LaserScan`` messages as ``/scan``."
msgstr "Both the ``slam_toolbox`` and ``nav2_amcl`` use information from the laser scan sensor to be able to perceive the robot's environment. Hence, to verify that they can access the laser scan sensor readings, we must make sure that they are subscribed to the correct topic that publishes the ``sensor_msgs/LaserScan`` message. This can be configured by setting their ``scan_topic`` parameters to the topic that publishes that message. It is a convention to publish the ``sensor_msgs/LaserScan`` messages to  ``/scan`` topic. Thus, by default, the ``scan_topic`` parameter is set to ``/scan``. Recall that when we added the lidar sensor to ``sam_bot`` in the previous section, we set the topic to which the lidar sensor will publish the ``sensor_msgs/LaserScan`` messages as ``/scan``."


#: ../../setup_guides/sensors/setup_sensors.rst:300
msgid "In-depth discussions on the complete configuration parameters will not be a scope of our tutorials since they can be pretty complex. Instead, we recommend you to have a look at their official documentation in the links below."
msgstr "In-depth discussions on the complete configuration parameters will not be a scope of our tutorials since they can be pretty complex. Instead, we recommend you to have a look at their official documentation in the links below."


#: ../../setup_guides/sensors/setup_sensors.rst
msgid "For the complete list of configuration parameters of ``slam_toolbox``, see the `Github repository of slam_toolbox <https://github.com/SteveMacenski/slam_toolbox#readme>`_."
msgstr "For the complete list of configuration parameters of ``slam_toolbox``, see the `Github repository of slam_toolbox <https://github.com/SteveMacenski/slam_toolbox#readme>`_."


#: ../../setup_guides/sensors/setup_sensors.rst
msgid "For the complete list of configuration parameters and example configuration of ``nav2_amcl``, see the `AMCL Configuration Guide <https://navigation.ros.org/configuration/packages/configuring-amcl.html>`_."
msgstr "For the complete list of configuration parameters and example configuration of ``nav2_amcl``, see the `AMCL Configuration Guide <https://navigation.ros.org/configuration/packages/configuring-amcl.html>`_."


#: ../../setup_guides/sensors/setup_sensors.rst:307
msgid "You can also refer to the `(SLAM) Navigating While Mapping guide <https://navigation.ros.org/tutorials/docs/navigation2_with_slam.html>`_ for the tutorial on how to use Nav2 with SLAM. You can verify that ``slam_toolbox`` and ``nav2_amcl`` have been correctly setup by visualizing the map and the robot's pose in RViz, similar to what was shown in the previous section."
msgstr "You can also refer to the `(SLAM) Navigating While Mapping guide <https://navigation.ros.org/tutorials/docs/navigation2_with_slam.html>`_ for the tutorial on how to use Nav2 with SLAM. You can verify that ``slam_toolbox`` and ``nav2_amcl`` have been correctly setup by visualizing the map and the robot's pose in RViz, similar to what was shown in the previous section."


#: ../../setup_guides/sensors/setup_sensors.rst:311
msgid "Costmap 2D"
msgstr "二维代价地图"


#: ../../setup_guides/sensors/setup_sensors.rst:312
msgid "The costmap 2D package makes use of the sensor information to provide a representation of the robot's environment in the form of an occupancy grid. The cells in the occupancy grid store cost values between 0-254 which denote a cost to travel through these zones. A cost of 0 means the cell is free while a cost of 254 means that the cell is lethally occupied. Values in between these extremes are used by navigation algorithms to steer your robot away from obstacles as a potential field. Costmaps in Nav2 are implemented through the ``nav2_costmap_2d`` package."
msgstr "The costmap 2D package makes use of the sensor information to provide a representation of the robot's environment in the form of an occupancy grid. The cells in the occupancy grid store cost values between 0-254 which denote a cost to travel through these zones. A cost of 0 means the cell is free while a cost of 254 means that the cell is lethally occupied. Values in between these extremes are used by navigation algorithms to steer your robot away from obstacles as a potential field. Costmaps in Nav2 are implemented through the ``nav2_costmap_2d`` package."


#: ../../setup_guides/sensors/setup_sensors.rst:314
msgid "The costmap implementation consists of multiple layers, each of which has a certain function that contributes to a cell's overall cost. The package consists of the following layers, but are plugin-based to allow customization and new layers to be used as well: static layer, inflation layer, range layer, obstacle layer, and voxel layer. The static layer represents the map section of the costmap, obtained from the messages published to the ``/map`` topic like those produced by SLAM.  The obstacle layer includes the objects detected by sensors that publish either or both the ``LaserScan`` and ``PointCloud2`` messages. The voxel layer is similar to the obstacle layer such that it can use either or both the ``LaserScan`` and ``PointCloud2`` sensor information but handles 3D data instead. The range layer allows for the inclusion of information provided by sonar and infrared sensors. Lastly, the inflation layer represents the added cost values around lethal obstacles such that our robot avoids navigating into obstacles due to the robot's geometry. In the next subsection of this tutorial, we will have some discussion about the basic configuration of the different layers in ``nav2_costmap_2d``."
msgstr "The costmap implementation consists of multiple layers, each of which has a certain function that contributes to a cell's overall cost. The package consists of the following layers, but are plugin-based to allow customization and new layers to be used as well: static layer, inflation layer, range layer, obstacle layer, and voxel layer. The static layer represents the map section of the costmap, obtained from the messages published to the ``/map`` topic like those produced by SLAM.  The obstacle layer includes the objects detected by sensors that publish either or both the ``LaserScan`` and ``PointCloud2`` messages. The voxel layer is similar to the obstacle layer such that it can use either or both the ``LaserScan`` and ``PointCloud2`` sensor information but handles 3D data instead. The range layer allows for the inclusion of information provided by sonar and infrared sensors. Lastly, the inflation layer represents the added cost values around lethal obstacles such that our robot avoids navigating into obstacles due to the robot's geometry. In the next subsection of this tutorial, we will have some discussion about the basic configuration of the different layers in ``nav2_costmap_2d``."


#: ../../setup_guides/sensors/setup_sensors.rst:316
msgid "The layers are integrated into the costmap through a plugin interface and then inflated using a user-specified `inflation radius <http://wiki.ros.org/costmap_2d/hydro/inflation>`_, if the inflation layer is enabled. For a deeper discussion on costmap concepts, you can have a look at the `ROS1 costmap_2D documentation <http://wiki.ros.org/costmap_2d>`_. Note that the ``nav2_costmap_2d`` package is mostly a straightforward ROS2 port of the ROS1 navigation stack version with minor changes required for ROS2 support and some new layer plugins."
msgstr "The layers are integrated into the costmap through a plugin interface and then inflated using a user-specified `inflation radius <http://wiki.ros.org/costmap_2d/hydro/inflation>`_, if the inflation layer is enabled. For a deeper discussion on costmap concepts, you can have a look at the `ROS1 costmap_2D documentation <http://wiki.ros.org/costmap_2d>`_. Note that the ``nav2_costmap_2d`` package is mostly a straightforward ROS2 port of the ROS1 navigation stack version with minor changes required for ROS2 support and some new layer plugins."


#: ../../setup_guides/sensors/setup_sensors.rst:321
msgid "Configuring nav2_costmap_2d"
msgstr "Configuring nav2_costmap_2d"


#: ../../setup_guides/sensors/setup_sensors.rst:322
msgid "In this subsection, we will show an example configuration of ``nav2_costmap_2d`` such that it uses the information provided by the lidar sensor of ``sam_bot``. We will show an example configuration that uses static layer, obstacle layer, voxel layer, and inflation layer. We set both the obstacle and voxel layer to use the ``LaserScan`` messages published  to the ``/scan`` topic by the lidar sensor. We also set some of the basic parameters to define how the detected obstacles are reflected in the costmap. Note that this configuration is to be included in the configuration file of Nav2."
msgstr "In this subsection, we will show an example configuration of ``nav2_costmap_2d`` such that it uses the information provided by the lidar sensor of ``sam_bot``. We will show an example configuration that uses static layer, obstacle layer, voxel layer, and inflation layer. We set both the obstacle and voxel layer to use the ``LaserScan`` messages published  to the ``/scan`` topic by the lidar sensor. We also set some of the basic parameters to define how the detected obstacles are reflected in the costmap. Note that this configuration is to be included in the configuration file of Nav2."


#: ../../setup_guides/sensors/setup_sensors.rst:399
msgid "In the configuration above, notice that we set the parameters for two different costmaps: ``global_costmap`` and ``local_costmap``. We set up two costmaps since the ``global_costmap`` is mainly used for long-term planning over the whole map while ``local_costmap`` is for short-term planning and collision avoidance."
msgstr "In the configuration above, notice that we set the parameters for two different costmaps: ``global_costmap`` and ``local_costmap``. We set up two costmaps since the ``global_costmap`` is mainly used for long-term planning over the whole map while ``local_costmap`` is for short-term planning and collision avoidance."


#: ../../setup_guides/sensors/setup_sensors.rst:401
msgid "The layers that we use for our configuration are defined in the ``plugins`` parameter, as shown in line 13 for the ``global_costmap`` and line 50 for the ``local_costmap``. These values are set as a list of mapped layer names that also serve as namespaces for the layer parameters we set up starting at lines 14 and line 51. Note that each layer/namespace in this list must have a ``plugin`` parameter (as indicated in lines 15, 18, 32, 52, and 68) defining the type of plugin to be loaded for that specific layer."
msgstr "The layers that we use for our configuration are defined in the ``plugins`` parameter, as shown in line 13 for the ``global_costmap`` and line 50 for the ``local_costmap``. These values are set as a list of mapped layer names that also serve as namespaces for the layer parameters we set up starting at lines 14 and line 51. Note that each layer/namespace in this list must have a ``plugin`` parameter (as indicated in lines 15, 18, 32, 52, and 68) defining the type of plugin to be loaded for that specific layer."


#: ../../setup_guides/sensors/setup_sensors.rst:403
msgid "For the static layer (lines 14-16), we set the ``map_subscribe_transient_local`` parameter to ``True``. This sets the QoS settings for the map topic. Another important parameter for the static layer is the ``map_topic`` which defines the map topic to subscribe to. This defaults to ``/map`` topic when not defined."
msgstr "For the static layer (lines 14-16), we set the ``map_subscribe_transient_local`` parameter to ``True``. This sets the QoS settings for the map topic. Another important parameter for the static layer is the ``map_topic`` which defines the map topic to subscribe to. This defaults to ``/map`` topic when not defined."


#: ../../setup_guides/sensors/setup_sensors.rst:405
msgid "For the obstacle layer (lines 17-30), we define its sensor source under the ``observation_sources`` parameter (line 20) as ``scan`` whose parameters are set up in lines 22-30. We set its ``topic`` parameter as the topic that publishes the defined sensor source and we set the ``data_type`` according to the sensor source it will use. In our configuration, the obstacle layer will use the ``LaserScan`` published by the lidar sensor to ``/scan``."
msgstr "For the obstacle layer (lines 17-30), we define its sensor source under the ``observation_sources`` parameter (line 20) as ``scan`` whose parameters are set up in lines 22-30. We set its ``topic`` parameter as the topic that publishes the defined sensor source and we set the ``data_type`` according to the sensor source it will use. In our configuration, the obstacle layer will use the ``LaserScan`` published by the lidar sensor to ``/scan``."


#: ../../setup_guides/sensors/setup_sensors.rst:407
msgid "Note that the obstacle layer and voxel layer can use either or both ``LaserScan`` and ``PointCloud2`` as their ``data_type`` but it is set to ``LaserScan`` by default. The code snippet below shows an example of using both the ``LaserScan`` and ``PointCloud2`` as the sensor sources. This may be particularly useful when setting up your own physical robot."
msgstr "Note that the obstacle layer and voxel layer can use either or both ``LaserScan`` and ``PointCloud2`` as their ``data_type`` but it is set to ``LaserScan`` by default. The code snippet below shows an example of using both the ``LaserScan`` and ``PointCloud2`` as the sensor sources. This may be particularly useful when setting up your own physical robot."


#: ../../setup_guides/sensors/setup_sensors.rst:422
msgid "For the other parameters of the obstacle layer, the ``max_obstacle_height`` parameter sets the maximum height of the sensor reading to return to the occupancy grid. The minimum height of the sensor reading can also be set using the ``min_obstacle_height`` parameter, which defaults to 0 since we did not set it in the configation. The ``clearing`` parameter is used to set whether the obstacle is to be removed from the costmap or not. The clearing operation is done by raytracing through the grid. The maximum and minimum range to raytrace clear objects from the costmap is set using the ``raytrace_max_range`` and ``raytrace_min_range`` respectively. The ``marking`` parameter is used to set whether the inserted obstacle is marked into the costmap or not. We also set the maximum and minimum range to mark obstacles in the costmap through the ``obstacle_max_range`` and ``obstacle_min_range`` respectively."
msgstr "For the other parameters of the obstacle layer, the ``max_obstacle_height`` parameter sets the maximum height of the sensor reading to return to the occupancy grid. The minimum height of the sensor reading can also be set using the ``min_obstacle_height`` parameter, which defaults to 0 since we did not set it in the configation. The ``clearing`` parameter is used to set whether the obstacle is to be removed from the costmap or not. The clearing operation is done by raytracing through the grid. The maximum and minimum range to raytrace clear objects from the costmap is set using the ``raytrace_max_range`` and ``raytrace_min_range`` respectively. The ``marking`` parameter is used to set whether the inserted obstacle is marked into the costmap or not. We also set the maximum and minimum range to mark obstacles in the costmap through the ``obstacle_max_range`` and ``obstacle_min_range`` respectively."


#: ../../setup_guides/sensors/setup_sensors.rst:424
msgid "For the inflation layer (lines 31-34 and 67-70), we set the exponential decay factor across the inflation radius using the ``cost_scaling_factor`` parameter. The value of the radius to inflate around lethal obstacles is defined using the ``inflation_radius``."
msgstr "For the inflation layer (lines 31-34 and 67-70), we set the exponential decay factor across the inflation radius using the ``cost_scaling_factor`` parameter. The value of the radius to inflate around lethal obstacles is defined using the ``inflation_radius``."


#: ../../setup_guides/sensors/setup_sensors.rst:426
msgid "For the voxel layer (lines 51-66), we set the ``publish_voxel_map`` parameter to ``True`` to enable the publishing of the 3D voxel grid. The resolution of the voxels in height is defined using the ``z_resolution`` parameter, while the number of voxels in each column is defined using the ``z_voxels`` parameter. The ``mark_threshold`` parameter sets the minimum number of voxels in a column to mark as occupied in the occupancy grid. We set the ``observation_sources`` parameter of the voxel layer to ``scan``, and we set the scan parameters (in lines 61-66) similar to the parameters that we have discussed for the obstacle layer. As defined in its ``topic`` and ``data_type`` parameters, the voxel layer will use the ``LaserScan`` published on the ``/scan`` topic by the lidar scanner."
msgstr "For the voxel layer (lines 51-66), we set the ``publish_voxel_map`` parameter to ``True`` to enable the publishing of the 3D voxel grid. The resolution of the voxels in height is defined using the ``z_resolution`` parameter, while the number of voxels in each column is defined using the ``z_voxels`` parameter. The ``mark_threshold`` parameter sets the minimum number of voxels in a column to mark as occupied in the occupancy grid. We set the ``observation_sources`` parameter of the voxel layer to ``scan``, and we set the scan parameters (in lines 61-66) similar to the parameters that we have discussed for the obstacle layer. As defined in its ``topic`` and ``data_type`` parameters, the voxel layer will use the ``LaserScan`` published on the ``/scan`` topic by the lidar scanner."


#: ../../setup_guides/sensors/setup_sensors.rst:428
msgid "Note that the we are not using a range layer for our configuration but it may be useful for your own robot setup. For the range layer, its basic parameters are the ``topics``, ``input_sensor_type``, and ``clear_on_max_reading`` parameters. The range topics to subscribe to are defined in the ``topics`` parameter. The ``input_sensor_type`` is set to either ``ALL``, ``VARIABLE``, or ``FIXED``. The ``clear_on_max_reading`` is a boolean parameter that sets whether to clear the sensor readings on max range.  Have a look at the configuration guide in the link below in case you need to set it up."
msgstr "Note that the we are not using a range layer for our configuration but it may be useful for your own robot setup. For the range layer, its basic parameters are the ``topics``, ``input_sensor_type``, and ``clear_on_max_reading`` parameters. The range topics to subscribe to are defined in the ``topics`` parameter. The ``input_sensor_type`` is set to either ``ALL``, ``VARIABLE``, or ``FIXED``. The ``clear_on_max_reading`` is a boolean parameter that sets whether to clear the sensor readings on max range.  Have a look at the configuration guide in the link below in case you need to set it up."


#: ../../setup_guides/sensors/setup_sensors.rst:431
msgid "For more information on ``nav2_costmap_2d`` and the complete list of layer plugin parameters, see the `Costmap 2D Configuration Guide <https://navigation.ros.org/configuration/packages/configuring-costmaps.html>`_."
msgstr "For more information on ``nav2_costmap_2d`` and the complete list of layer plugin parameters, see the `Costmap 2D Configuration Guide <https://navigation.ros.org/configuration/packages/configuring-costmaps.html>`_."


#: ../../setup_guides/sensors/setup_sensors.rst:436
msgid "We will first launch ``display.launch.py`` which launches the robot state publisher that provides the ``base_link`` => ``sensors`` transformations in our URDF. It also launches Gazebo that acts as our physics simulator and also provides the ``odom`` => ``base_link`` from the differential drive plugin, which we added to ``sam_bot`` in the previous guide, `Simulating an Odometry System Using Gazebo <https://navigation.ros.org/setup_guides/odom/setup_odom.html#simulating-an-odometry-system-using-gazebo>`_. It also launches RViz which we can use to visualize the robot and sensor information."
msgstr "We will first launch ``display.launch.py`` which launches the robot state publisher that provides the ``base_link`` => ``sensors`` transformations in our URDF. It also launches Gazebo that acts as our physics simulator and also provides the ``odom`` => ``base_link`` from the differential drive plugin, which we added to ``sam_bot`` in the previous guide, `Simulating an Odometry System Using Gazebo <https://navigation.ros.org/setup_guides/odom/setup_odom.html#simulating-an-odometry-system-using-gazebo>`_. It also launches RViz which we can use to visualize the robot and sensor information."


#: ../../setup_guides/sensors/setup_sensors.rst:438
msgid "Then we will launch ``slam_toolbox`` to publish to ``/map`` topic and provide the ``map`` => ``odom`` transform. Recall that the ``map`` => ``odom`` transform is one of the primary requirements of the Nav2 system. The messages published on the ``/map`` topic will then be used by the static layer of the ``global_costmap``."
msgstr "Then we will launch ``slam_toolbox`` to publish to ``/map`` topic and provide the ``map`` => ``odom`` transform. Recall that the ``map`` => ``odom`` transform is one of the primary requirements of the Nav2 system. The messages published on the ``/map`` topic will then be used by the static layer of the ``global_costmap``."


#: ../../setup_guides/sensors/setup_sensors.rst:440
msgid "After we have properly setup our robot description, odometry sensors, and necessary transforms, we will finally launch the Nav2 system itself. For now, we will only be exploring the costmap generation system of Nav2. After launching Nav2, we will visualize the costmaps in RViz to confirm our output."
msgstr "After we have properly setup our robot description, odometry sensors, and necessary transforms, we will finally launch the Nav2 system itself. For now, we will only be exploring the costmap generation system of Nav2. After launching Nav2, we will visualize the costmaps in RViz to confirm our output."


#: ../../setup_guides/sensors/setup_sensors.rst:443
msgid "Launching Description Nodes, RViz and Gazebo"
msgstr "Launching Description Nodes, RViz and Gazebo"


#: ../../setup_guides/sensors/setup_sensors.rst:445
msgid "Let us now launch our Robot Description Nodes, RViz and Gazebo through the launch file ``display.launch.py``. Open a new terminal and execute the lines below."
msgstr "Let us now launch our Robot Description Nodes, RViz and Gazebo through the launch file ``display.launch.py``. Open a new terminal and execute the lines below."


#: ../../setup_guides/sensors/setup_sensors.rst:453
msgid "RViz and the Gazebo should now be launched with ``sam_bot`` present in both. Recall that the ``base_link`` => ``sensors`` transform is now being published by ``robot_state_publisher`` and the ``odom`` => ``base_link`` transform by our Gazebo plugins. Both transforms should now be dislpayed show without errors in RViz."
msgstr "RViz and the Gazebo should now be launched with ``sam_bot`` present in both. Recall that the ``base_link`` => ``sensors`` transform is now being published by ``robot_state_publisher`` and the ``odom`` => ``base_link`` transform by our Gazebo plugins. Both transforms should now be dislpayed show without errors in RViz."


#: ../../setup_guides/sensors/setup_sensors.rst:456
msgid "Launching slam_toolbox"
msgstr "Launching slam_toolbox"


#: ../../setup_guides/sensors/setup_sensors.rst:458
msgid "To be able to launch ``slam_toolbox``, make sure that you have installed the ``slam_toolbox`` package by executing the following command:"
msgstr "To be able to launch ``slam_toolbox``, make sure that you have installed the ``slam_toolbox`` package by executing the following command:"


#: ../../setup_guides/sensors/setup_sensors.rst:464
msgid "We will launch the ``async_slam_toolbox_node`` of ``slam_toolbox`` using the package's built-in launch files. Open a new terminal and then execute the following lines:"
msgstr "We will launch the ``async_slam_toolbox_node`` of ``slam_toolbox`` using the package's built-in launch files. Open a new terminal and then execute the following lines:"


#: ../../setup_guides/sensors/setup_sensors.rst:470
msgid "The ``slam_toolbox`` should now be publishing to the ``/map`` topic and providing the ``map`` => ``odom`` transform."
msgstr "The ``slam_toolbox`` should now be publishing to the ``/map`` topic and providing the ``map`` => ``odom`` transform."


#: ../../setup_guides/sensors/setup_sensors.rst:472
msgid "We can verify in RViz that the ``/map`` topic is being published. In the RViz window, click the add button at the bottom-left part then go to ``By topic`` tab then select the ``Map`` under the ``/map`` topic. You should be able to visualize the message received in the ``/map`` as shown in the image below."
msgstr "We can verify in RViz that the ``/map`` topic is being published. In the RViz window, click the add button at the bottom-left part then go to ``By topic`` tab then select the ``Map`` under the ``/map`` topic. You should be able to visualize the message received in the ``/map`` as shown in the image below."


#: ../../setup_guides/sensors/setup_sensors.rst:477
msgid "We can also check that the transforms are correct by executing the following lines in a new terminal:"
msgstr "We can also check that the transforms are correct by executing the following lines in a new terminal:"


#: ../../setup_guides/sensors/setup_sensors.rst:483
msgid "Note: For Galactic and newer, it should be ``view_frames`` and not ``view_frames.py`` The line above will create a ``frames.pdf`` file that shows the current transform tree. Your tranform tree should be similar to the one shown below:"
msgstr "Note: For Galactic and newer, it should be ``view_frames`` and not ``view_frames.py`` The line above will create a ``frames.pdf`` file that shows the current transform tree. Your tranform tree should be similar to the one shown below:"


#: ../../setup_guides/sensors/setup_sensors.rst:490
msgid "Launching Nav2"
msgstr "Launching Nav2"


#: ../../setup_guides/sensors/setup_sensors.rst:491
msgid "First, Make sure you have installed the Nav2 packages by executing the following:"
msgstr "First, Make sure you have installed the Nav2 packages by executing the following:"


#: ../../setup_guides/sensors/setup_sensors.rst:498
msgid "We will now launch Nav2 using the ``nav2_bringup``'s built-in launch file, ``navigation_launch.py`` . Open a new terminal and execute the following:"
msgstr "We will now launch Nav2 using the ``nav2_bringup``'s built-in launch file, ``navigation_launch.py`` . Open a new terminal and execute the following:"


#: ../../setup_guides/sensors/setup_sensors.rst:504
msgid "Note that the parameters of the ``nav2_costmap_2d`` that we discussed in the previous subsection are included in the default parameters of ``navigation_launch.py``. Aside from the ``nav2_costmap_2d`` parameters, it also contains parameters for the other nodes that are included in Nav2 implementation."
msgstr "Note that the parameters of the ``nav2_costmap_2d`` that we discussed in the previous subsection are included in the default parameters of ``navigation_launch.py``. Aside from the ``nav2_costmap_2d`` parameters, it also contains parameters for the other nodes that are included in Nav2 implementation."


#: ../../setup_guides/sensors/setup_sensors.rst:506
msgid "After we have properly set up and launched Nav2, the ``/global_costmap`` and ``/local_costmap`` topics should now be active."
msgstr "After we have properly set up and launched Nav2, the ``/global_costmap`` and ``/local_costmap`` topics should now be active."


#: ../../setup_guides/sensors/setup_sensors.rst:509
msgid "To make the costmaps show up, run the 3 commands in this order"
msgstr "To make the costmaps show up, run the 3 commands in this order"


#: ../../setup_guides/sensors/setup_sensors.rst:511
msgid "Launching Description Nodes, RViz and Gazebo - in logs wait for \"Connected to gazebo master\""
msgstr "Launching Description Nodes, RViz and Gazebo - in logs wait for \"Connected to gazebo master\""


#: ../../setup_guides/sensors/setup_sensors.rst:512
msgid "Launching slam_toolbox - in logs wait for \"Registering sensor\""
msgstr "Launching slam_toolbox - in logs wait for \"Registering sensor\""


#: ../../setup_guides/sensors/setup_sensors.rst:513
msgid "Launching Nav2 - in logs wait for \"Creating bond timer\""
msgstr "Launching Nav2 - in logs wait for \"Creating bond timer\""


#: ../../setup_guides/sensors/setup_sensors.rst:516
msgid "Visualizing Costmaps in RViz"
msgstr "Visualizing Costmaps in RViz"


#: ../../setup_guides/sensors/setup_sensors.rst:518
msgid "The ``global_costmap``, ``local_costmap`` and the voxel representation of the detected obstacles can be visualized in RViz."
msgstr "The ``global_costmap``, ``local_costmap`` and the voxel representation of the detected obstacles can be visualized in RViz."


#: ../../setup_guides/sensors/setup_sensors.rst:520
msgid "To visualize the ``global_costmap`` in RViz, click the add button at the bottom-left part of the RViz window. Go to ``By topic`` tab then select the ``Map`` under the ``/global_costmap/costmap`` topic. The ``global_costmap`` should show in the RViz window, as shown below. The ``global_costmap`` shows areas which should be avoided (black) by our robot when it navigates our simulated world in Gazebo."
msgstr "To visualize the ``global_costmap`` in RViz, click the add button at the bottom-left part of the RViz window. Go to ``By topic`` tab then select the ``Map`` under the ``/global_costmap/costmap`` topic. The ``global_costmap`` should show in the RViz window, as shown below. The ``global_costmap`` shows areas which should be avoided (black) by our robot when it navigates our simulated world in Gazebo."


#: ../../setup_guides/sensors/setup_sensors.rst:525
msgid "To visualize the ``local_costmap`` in RViz, select the ``Map`` under the ``/local_costmap/costmap`` topic. Set the ``color scheme`` in RViz to ``costmap`` to make it appear similar to the image below."
msgstr "To visualize the ``local_costmap`` in RViz, select the ``Map`` under the ``/local_costmap/costmap`` topic. Set the ``color scheme`` in RViz to ``costmap`` to make it appear similar to the image below."


#: ../../setup_guides/sensors/setup_sensors.rst:530
msgid "To visualize the voxel representation of the detected object, open a new terminal and execute the following lines:"
msgstr "To visualize the voxel representation of the detected object, open a new terminal and execute the following lines:"


#: ../../setup_guides/sensors/setup_sensors.rst:536
msgid "The line above sets the topic where the the markers will be published to ``/my_marker``. To see the markers in RViz, select ``Marker`` under the ``/my_marker`` topic, as shown below."
msgstr "The line above sets the topic where the the markers will be published to ``/my_marker``. To see the markers in RViz, select ``Marker`` under the ``/my_marker`` topic, as shown below."


#: ../../setup_guides/sensors/setup_sensors.rst:542
msgid "Then set the ``fixed frame`` in RViz to ``odom`` and you should now see the voxels in RViz, which represent the cube and the sphere that we have in the Gazebo world:"
msgstr "Then set the ``fixed frame`` in RViz to ``odom`` and you should now see the voxels in RViz, which represent the cube and the sphere that we have in the Gazebo world:"


#: ../../setup_guides/sensors/setup_sensors.rst:550
msgid "In this section of our robot setup guide, we have discussed the importance of sensor information for different tasks associated with Nav2. More specifically, tasks such as mapping (SLAM), localization (AMCL), and perception (costmap) tasks."
msgstr "In this section of our robot setup guide, we have discussed the importance of sensor information for different tasks associated with Nav2. More specifically, tasks such as mapping (SLAM), localization (AMCL), and perception (costmap) tasks."


#: ../../setup_guides/sensors/setup_sensors.rst:552
msgid "We also had a discussion on the common types of sensor messages in Nav2 which standardize the message formats for different sensor vendors. We also discussed how to add sensors to a simulated robot using Gazebo and how to verify that the sensors are working correctly through RViz."
msgstr "We also had a discussion on the common types of sensor messages in Nav2 which standardize the message formats for different sensor vendors. We also discussed how to add sensors to a simulated robot using Gazebo and how to verify that the sensors are working correctly through RViz."


#: ../../setup_guides/sensors/setup_sensors.rst:554
msgid "Lastly, we set up a basic configuration for the ``nav2_costmap_2d`` package using different layers to produce a global and local costmap. We then verify our work by visualizing these costmaps in RViz."
msgstr "Lastly, we set up a basic configuration for the ``nav2_costmap_2d`` package using different layers to produce a global and local costmap. We then verify our work by visualizing these costmaps in RViz."


#: ../../setup_guides/transformation/setup_transforms.rst:4
msgid "Setting Up Transformations"
msgstr "Setting Up Transformations"


#: ../../setup_guides/transformation/setup_transforms.rst:6
msgid "In this guide, we will be looking at the necessary transforms required by Nav2. These transforms allow Nav2 to interpret information coming in from various sources, such as sensors and odometry, by transforming them to the coordinate frames for use. Below is what a full transform tree for a robot looks like but we'll start with something much more simpler."
msgstr "In this guide, we will be looking at the necessary transforms required by Nav2. These transforms allow Nav2 to interpret information coming in from various sources, such as sensors and odometry, by transforming them to the coordinate frames for use. Below is what a full transform tree for a robot looks like but we'll start with something much more simpler."


#: ../../setup_guides/transformation/setup_transforms.rst:11
msgid "For this tutorial, we will first provide a brief introduction to transforms in ROS. Second, we will be working on a simple command-line demo of a TF2 static publisher to see it in action. Lastly, we will outline the necessary transforms that need to be published for Nav2 to function."
msgstr "For this tutorial, we will first provide a brief introduction to transforms in ROS. Second, we will be working on a simple command-line demo of a TF2 static publisher to see it in action. Lastly, we will outline the necessary transforms that need to be published for Nav2 to function."


#: ../../setup_guides/transformation/setup_transforms.rst:14
msgid "Transforms Introduction"
msgstr "Transforms Introduction"


#: ../../setup_guides/transformation/setup_transforms.rst:17
msgid "This section of this guide has been adapted from the `Setting Up You Robot using tf <http://wiki.ros.org/navigation/Tutorials/RobotSetup/TF>`__ tutorial in the ROS (1) Navigation documentation."
msgstr "This section of this guide has been adapted from the `Setting Up You Robot using tf <http://wiki.ros.org/navigation/Tutorials/RobotSetup/TF>`__ tutorial in the ROS (1) Navigation documentation."


#: ../../setup_guides/transformation/setup_transforms.rst:19
msgid "Many ROS packages require the transform tree of a robot to be published using the TF2 ROS package. A transformation tree defines the relations between different coordinate systems, in terms of translation, rotation, and relative motion. To make this more concrete, let us apply an example of a simple robot that has a mobile base with a single laser sensor mounted on top of it."
msgstr "Many ROS packages require the transform tree of a robot to be published using the TF2 ROS package. A transformation tree defines the relations between different coordinate systems, in terms of translation, rotation, and relative motion. To make this more concrete, let us apply an example of a simple robot that has a mobile base with a single laser sensor mounted on top of it."


#: ../../setup_guides/transformation/setup_transforms.rst:21
msgid "This robot has two defined coordinate frames: one corresponding to the center point of the mobile base of the robot, and one for the center point of the laser that is mounted on top of the base. We'll call the coordinate frame attached to the mobile base  ``base_link`` and we'll call the coordinate frame attached to the laser ``base_laser``. Note that will be talking more about the naming and conventions of these coordinate frames in the next section."
msgstr "This robot has two defined coordinate frames: one corresponding to the center point of the mobile base of the robot, and one for the center point of the laser that is mounted on top of the base. We'll call the coordinate frame attached to the mobile base  ``base_link`` and we'll call the coordinate frame attached to the laser ``base_laser``. Note that will be talking more about the naming and conventions of these coordinate frames in the next section."


#: ../../setup_guides/transformation/setup_transforms.rst:23
msgid "At this point, let's assume that we have some data from the laser in the form of distance measurements from the laser's center point. In other words, we have some data in the ``base_laser`` coordinate frame."
msgstr "At this point, let's assume that we have some data from the laser in the form of distance measurements from the laser's center point. In other words, we have some data in the ``base_laser`` coordinate frame."


#: ../../setup_guides/transformation/setup_transforms.rst:25
msgid "Now, suppose we want to take this data and use it to help the mobile base avoid obstacles in the world. To do this successfully, we need a way to transform the laser scan we've received from the ``base_laser`` frame to the  ``base_link`` frame. In essence, we need to define a relationship between the ``base_laser`` and  ``base_link`` coordinate frames."
msgstr "Now, suppose we want to take this data and use it to help the mobile base avoid obstacles in the world. To do this successfully, we need a way to transform the laser scan we've received from the ``base_laser`` frame to the  ``base_link`` frame. In essence, we need to define a relationship between the ``base_laser`` and  ``base_link`` coordinate frames."


#: ../../setup_guides/transformation/setup_transforms.rst:30
msgid "In defining this relationship, let us assume that the only data we have is that the laser is mounted 10cm forward and 20cm above the center point of the mobile base. This gives us a translational offset that relates the  ``base_link`` frame to the ``base_laser`` frame. Specifically, we know that to get data from the  ``base_link`` frame to the ``base_laser`` frame, we must apply a translation of (x: 0.1m, y: 0.0m, z: 0.2m), and transversely, to get data from the ``base_laser`` frame to the  ``base_link`` frame, we must apply the opposite translation (x: -0.1m, y: 0.0m, z: -0.20m)."
msgstr "In defining this relationship, let us assume that the only data we have is that the laser is mounted 10cm forward and 20cm above the center point of the mobile base. This gives us a translational offset that relates the  ``base_link`` frame to the ``base_laser`` frame. Specifically, we know that to get data from the  ``base_link`` frame to the ``base_laser`` frame, we must apply a translation of (x: 0.1m, y: 0.0m, z: 0.2m), and transversely, to get data from the ``base_laser`` frame to the  ``base_link`` frame, we must apply the opposite translation (x: -0.1m, y: 0.0m, z: -0.20m)."


#: ../../setup_guides/transformation/setup_transforms.rst:32
msgid "We could choose to manage this relationship ourselves, meaning to store and apply the appropriate translations between the frames when necessary, but this becomes a real pain as the number of coordinate frames increases. Luckily, we don't have to do this work ourselves. Instead, we'll define the relationship between  ``base_link`` and ``base_laser`` once using TF2 and let it manage the transformation between the two coordinate frames for us. This is especially useful when working with non-static transformations, such as a set of frames that are moving relative to each other, like a robot base frame in a map frame."
msgstr "We could choose to manage this relationship ourselves, meaning to store and apply the appropriate translations between the frames when necessary, but this becomes a real pain as the number of coordinate frames increases. Luckily, we don't have to do this work ourselves. Instead, we'll define the relationship between  ``base_link`` and ``base_laser`` once using TF2 and let it manage the transformation between the two coordinate frames for us. This is especially useful when working with non-static transformations, such as a set of frames that are moving relative to each other, like a robot base frame in a map frame."


#: ../../setup_guides/transformation/setup_transforms.rst:34
msgid "To define and store the relationship between the  ``base_link`` and ``base_laser`` frames using TF2, we need to add them to a transform tree. Conceptually, each node in the transform tree corresponds to a coordinate frame, and each edge corresponds to the transform that needs to be applied to move from the current node to its child. TF2 uses a tree structure to guarantee that there is only a single traversal that links any two coordinate frames together, and assumes that all edges in the tree are directed from parent to child nodes."
msgstr "To define and store the relationship between the  ``base_link`` and ``base_laser`` frames using TF2, we need to add them to a transform tree. Conceptually, each node in the transform tree corresponds to a coordinate frame, and each edge corresponds to the transform that needs to be applied to move from the current node to its child. TF2 uses a tree structure to guarantee that there is only a single traversal that links any two coordinate frames together, and assumes that all edges in the tree are directed from parent to child nodes."


#: ../../setup_guides/transformation/setup_transforms.rst:39
msgid "To create a transform tree for our simple example, we'll create two nodes: one for the  ``base_link`` coordinate frame and one for the ``base_laser`` coordinate frame. To create the edge between them, we first need to decide which node will be the parent and which will be the child. Remember — this distinction is important because TF2 assumes that all transforms move from parent to child."
msgstr "To create a transform tree for our simple example, we'll create two nodes: one for the  ``base_link`` coordinate frame and one for the ``base_laser`` coordinate frame. To create the edge between them, we first need to decide which node will be the parent and which will be the child. Remember — this distinction is important because TF2 assumes that all transforms move from parent to child."


#: ../../setup_guides/transformation/setup_transforms.rst:41
msgid "Let's choose the  ``base_link`` coordinate frame as the parent because when other pieces/sensors are added to the robot, it will make the most sense for them to relate to the ``base_laser`` frame by traversing through the  ``base_link`` frame. This means that the transform associated with the edge connecting  ``base_link`` and ``base_laser`` should be (x: 0.1m, y: 0.0m, z: 0.2m)."
msgstr "Let's choose the  ``base_link`` coordinate frame as the parent because when other pieces/sensors are added to the robot, it will make the most sense for them to relate to the ``base_laser`` frame by traversing through the  ``base_link`` frame. This means that the transform associated with the edge connecting  ``base_link`` and ``base_laser`` should be (x: 0.1m, y: 0.0m, z: 0.2m)."


#: ../../setup_guides/transformation/setup_transforms.rst:43
msgid "With this transform tree set up, converting the laser scan received in the ``base_laser`` frame to the  ``base_link`` frame is as simple as making a call to the TF2 library. Our robot can now use this information to reason about laser scans in the  ``base_link`` frame and safely plan around obstacles in its environment."
msgstr "With this transform tree set up, converting the laser scan received in the ``base_laser`` frame to the  ``base_link`` frame is as simple as making a call to the TF2 library. Our robot can now use this information to reason about laser scans in the  ``base_link`` frame and safely plan around obstacles in its environment."


#: ../../setup_guides/transformation/setup_transforms.rst:46
msgid "Static Transform Publisher Demo"
msgstr "Static Transform Publisher Demo"


#: ../../setup_guides/transformation/setup_transforms.rst:48
msgid "If you are new to ROS 2 or do not have a working environment yet, then please take some time to properly setup your machine using the resources in the official `ROS 2 Installation Documentation <https://docs.ros.org/en/rolling/Installation.html>`__"
msgstr "If you are new to ROS 2 or do not have a working environment yet, then please take some time to properly setup your machine using the resources in the official `ROS 2 Installation Documentation <https://docs.ros.org/en/rolling/Installation.html>`__"


#: ../../setup_guides/transformation/setup_transforms.rst:50
msgid "Now let's try publishing a very simple transform using the static_transform_publisher tool provided by TF2. We will be publishing a transformation from the link ``base_link`` to the link ``base_laser`` with a translation of (x: 0.1m, y: 0.0m, z: 0.2m). Note that we will be building the transform from the diagram earlier in this tutorial."
msgstr "Now let's try publishing a very simple transform using the static_transform_publisher tool provided by TF2. We will be publishing a transformation from the link ``base_link`` to the link ``base_laser`` with a translation of (x: 0.1m, y: 0.0m, z: 0.2m). Note that we will be building the transform from the diagram earlier in this tutorial."


#: ../../setup_guides/transformation/setup_transforms.rst:52
msgid "Open up your command line and execute the following command:"
msgstr "Open up your command line and execute the following command:"


#: ../../setup_guides/transformation/setup_transforms.rst:58
msgid "With this, we are now sucessfully publishing our ``base_link`` to ``base_laser`` transform in TF2. Let us now check if it is working properly through ``tf2_echo``. Open up a separate command line window and execute the following:"
msgstr "With this, we are now sucessfully publishing our ``base_link`` to ``base_laser`` transform in TF2. Let us now check if it is working properly through ``tf2_echo``. Open up a separate command line window and execute the following:"


#: ../../setup_guides/transformation/setup_transforms.rst:64
msgid "You should be able to observe a repeated output simiar to the one below."
msgstr "You should be able to observe a repeated output simiar to the one below."


#: ../../setup_guides/transformation/setup_transforms.rst:72
msgid "And that's it for this short demo - we were able to successfully publish a transform from ``base_link`` to ``base_laser`` using the TF2 library. Note that we do not recommend using the above demo in publishing transforms for your actual robotics projects, it is just a quick demo to see TF2 in action. For a real robot system, we would create a URDF file which embeds this information and more about your robot for use of the robot_state_publisher rather than the static_transform_publisher. There are more suitable and practical ways to go about this which will be discussed in the :ref:`urdf_handson` tutorial."
msgstr "And that's it for this short demo - we were able to successfully publish a transform from ``base_link`` to ``base_laser`` using the TF2 library. Note that we do not recommend using the above demo in publishing transforms for your actual robotics projects, it is just a quick demo to see TF2 in action. For a real robot system, we would create a URDF file which embeds this information and more about your robot for use of the robot_state_publisher rather than the static_transform_publisher. There are more suitable and practical ways to go about this which will be discussed in the :ref:`urdf_handson` tutorial."


#: ../../setup_guides/transformation/setup_transforms.rst:75
msgid "If you would like to learn more about TF2 and how to create your own transform publishers, head onto the official `TF2 Documentation <https://wiki.ros.org/tf2/Tutorials>`__"
msgstr "If you would like to learn more about TF2 and how to create your own transform publishers, head onto the official `TF2 Documentation <https://wiki.ros.org/tf2/Tutorials>`__"


#: ../../setup_guides/transformation/setup_transforms.rst:79
msgid "Transforms in Navigation2"
msgstr "Transforms in Navigation2"


#: ../../setup_guides/transformation/setup_transforms.rst:81
msgid "There are two important ROS REPs which we highly suggest for you to check out. These documents detail some standards set about by the ROS community to ensure proper operation across different packages. Nav2 also adheres to these standards and conventions."
msgstr "There are two important ROS REPs which we highly suggest for you to check out. These documents detail some standards set about by the ROS community to ensure proper operation across different packages. Nav2 also adheres to these standards and conventions."


#: ../../setup_guides/transformation/setup_transforms.rst:83
msgid "`REP 105 - Coordinate Frames for Mobile Platforms <https://www.ros.org/reps/rep-0105.html>`__"
msgstr "`REP 105 - Coordinate Frames for Mobile Platforms <https://www.ros.org/reps/rep-0105.html>`__"


#: ../../setup_guides/transformation/setup_transforms.rst:84
msgid "`REP 103 - Standard Units of Measure and Coordinate Conventions <https://www.ros.org/reps/rep-0103.html>`__"
msgstr "`REP 103 - Standard Units of Measure and Coordinate Conventions <https://www.ros.org/reps/rep-0103.html>`__"


#: ../../setup_guides/transformation/setup_transforms.rst:86
msgid "To quickly summarize REP 105, this document specifies the naming conventions and semantic meanings of the different coordinate frames used in ROS. Of interest to this tutorial are the ``base_link``, ``odom`` and ``map`` coordinate frames. The ``base_link`` is a coordinate frame that is attached to a fixed position on the robot, typically at its main chassis and its rotational center. The ``odom`` coordinate frame is a fixed frame relative to the robot's starting position and is mainly used for locally-consistent representations of distances. Lastly, the ``map`` coordinate frame is a world fixed frame that is used for globally-consistent representations of distances."
msgstr "To quickly summarize REP 105, this document specifies the naming conventions and semantic meanings of the different coordinate frames used in ROS. Of interest to this tutorial are the ``base_link``, ``odom`` and ``map`` coordinate frames. The ``base_link`` is a coordinate frame that is attached to a fixed position on the robot, typically at its main chassis and its rotational center. The ``odom`` coordinate frame is a fixed frame relative to the robot's starting position and is mainly used for locally-consistent representations of distances. Lastly, the ``map`` coordinate frame is a world fixed frame that is used for globally-consistent representations of distances."


#: ../../setup_guides/transformation/setup_transforms.rst:88
msgid "REP 103, on the other hand, discusses some standard units of measure and other related conventions to keep integration issues between different ROS packages to a minimum. The basic overview is that frames are defined using the right hand rule, with Z up and X forward, and units should be standard SI units."
msgstr "REP 103, on the other hand, discusses some standard units of measure and other related conventions to keep integration issues between different ROS packages to a minimum. The basic overview is that frames are defined using the right hand rule, with Z up and X forward, and units should be standard SI units."


#: ../../setup_guides/transformation/setup_transforms.rst:90
msgid "Now let's move on to some specifics for the Navigation2 package to function correctly. Nav2 requires the following transformations to be published in ROS:"
msgstr "Now let's move on to some specifics for the Navigation2 package to function correctly. Nav2 requires the following transformations to be published in ROS:"


#: ../../setup_guides/transformation/setup_transforms.rst:92
msgid "``map`` => ``odom``"
msgstr "``map`` => ``odom``"


#: ../../setup_guides/transformation/setup_transforms.rst:93
msgid "``odom`` => ``base_link``"
msgstr "``odom`` => ``base_link``"


#: ../../setup_guides/transformation/setup_transforms.rst:94
msgid "``base_link`` => ``base_laser`` (sensor base frames)"
msgstr "``base_link`` => ``base_laser`` (sensor base frames)"


#: ../../setup_guides/transformation/setup_transforms.rst:97
msgid "The ``base_laser`` coordinate frame is not included in the REP 105 standard. For this guide, we will be using this name to refer to the coordinate frame for a laser sensor on our robot platform.  If there are multiple sensor base frames (e.g. camera_link, base_laser2, lidar_link etc.), then a transformation back to ``base_link`` for each one is required."
msgstr "The ``base_laser`` coordinate frame is not included in the REP 105 standard. For this guide, we will be using this name to refer to the coordinate frame for a laser sensor on our robot platform.  If there are multiple sensor base frames (e.g. camera_link, base_laser2, lidar_link etc.), then a transformation back to ``base_link`` for each one is required."


#: ../../setup_guides/transformation/setup_transforms.rst:99
msgid "The first transform ``map`` => ``odom`` is usually provided by a different ROS package dealing with localization and mapping such as AMCL. This transform updates live in use so we don't set static values for this in our robot's TF tree. Further detail about how to set this up may be pretty complex, so we highly suggest to have a look at the documentation of the mapping or localization package you are using for your platform. All ROS compliant SLAM and localization packages will provide you with this transformation automatically on launch."
msgstr "The first transform ``map`` => ``odom`` is usually provided by a different ROS package dealing with localization and mapping such as AMCL. This transform updates live in use so we don't set static values for this in our robot's TF tree. Further detail about how to set this up may be pretty complex, so we highly suggest to have a look at the documentation of the mapping or localization package you are using for your platform. All ROS compliant SLAM and localization packages will provide you with this transformation automatically on launch."


#: ../../setup_guides/transformation/setup_transforms.rst:101
msgid "The ``odom`` => ``base_link`` is usually published by our odometry system using sensors such as wheel encoders. This is typically computed via sensor fusion of odometry sensors (IMU, wheel encoders, VIO, etc) using the ``robot_localization`` package."
msgstr "The ``odom`` => ``base_link`` is usually published by our odometry system using sensors such as wheel encoders. This is typically computed via sensor fusion of odometry sensors (IMU, wheel encoders, VIO, etc) using the ``robot_localization`` package."


#: ../../setup_guides/transformation/setup_transforms.rst:103
msgid "All other statically defined transforms (e.g. ``base_link`` => ``base_laser``, ``base_link`` => ``wheels``, ``wheels`` => ``IMU``, etc) is what we will be talking about for the rest of this guide. This transformation tree is used by Nav2 to properly relate the information from sensors or other frame of interest to the rest of the robot. The transformation between these two coordinate frames is usually provided to Nav2 through the Robot State Publisher and the Universal Robot Descriptor File (URDF). In cases where there are more sensor coordinate frames on your platform, then a transform tree from ``base_link`` to each sensor coordinate frame needs to be published."
msgstr "All other statically defined transforms (e.g. ``base_link`` => ``base_laser``, ``base_link`` => ``wheels``, ``wheels`` => ``IMU``, etc) is what we will be talking about for the rest of this guide. This transformation tree is used by Nav2 to properly relate the information from sensors or other frame of interest to the rest of the robot. The transformation between these two coordinate frames is usually provided to Nav2 through the Robot State Publisher and the Universal Robot Descriptor File (URDF). In cases where there are more sensor coordinate frames on your platform, then a transform tree from ``base_link`` to each sensor coordinate frame needs to be published."


#: ../../setup_guides/transformation/setup_transforms.rst:106
msgid "For a more in-depth discussion on the usage of transforms and how these are used to estimate the current state of your robot, we highly recommend having a look at the State Estimation topic in :ref:`concepts`."
msgstr "For a more in-depth discussion on the usage of transforms and how these are used to estimate the current state of your robot, we highly recommend having a look at the State Estimation topic in :ref:`concepts`."


#: ../../setup_guides/transformation/setup_transforms.rst:111
msgid "In this tutorial, we have discussed about the concept of transforms and how they are used in Nav2."
msgstr "In this tutorial, we have discussed about the concept of transforms and how they are used in Nav2."


#: ../../setup_guides/transformation/setup_transforms.rst:113
msgid "In the last section, we have also explored using the static_transform_publisher of TF2 to publish our transforms. You may use this to set up your transforms for Nav2, but this is generally not the best way to do it. In most robotics projects, we make use of the Robot State Publisher since it is much easier to use and scales well as our robot gets more complex. We will be talking about the Robot State Publisher, URDF, and how to set it up in the next tutorial on :ref:`urdf_handson`."
msgstr "In the last section, we have also explored using the static_transform_publisher of TF2 to publish our transforms. You may use this to set up your transforms for Nav2, but this is generally not the best way to do it. In most robotics projects, we make use of the Robot State Publisher since it is much easier to use and scales well as our robot gets more complex. We will be talking about the Robot State Publisher, URDF, and how to set it up in the next tutorial on :ref:`urdf_handson`."


#: ../../setup_guides/transformation/setup_transforms.rst:115
msgid "Lastly, we also discussed the three published transform requirements of Nav2 and the neccessary REPs to keep in mind when setting them up."
msgstr "Lastly, we also discussed the three published transform requirements of Nav2 and the neccessary REPs to keep in mind when setting them up."


#: ../../setup_guides/urdf/setup_urdf.rst:4
msgid "Setting Up The URDF"
msgstr "Setting Up The URDF"


#: ../../setup_guides/urdf/setup_urdf.rst:6
msgid "For this guide, we will be creating the Unified Robot Description Format (URDF) file for a simple differential drive robot to give you hands-on experience on working with URDF. We will also setup the robot state publisher and visualize our model in RVIZ. Lastly, we will be adding some kinematic properties to our robot URDF to prepare it for simulation purposes. These steps are necessary to represent all the sensor, hardware, and robot transforms of your robot for use in navigation."
msgstr "For this guide, we will be creating the Unified Robot Description Format (URDF) file for a simple differential drive robot to give you hands-on experience on working with URDF. We will also setup the robot state publisher and visualize our model in RVIZ. Lastly, we will be adding some kinematic properties to our robot URDF to prepare it for simulation purposes. These steps are necessary to represent all the sensor, hardware, and robot transforms of your robot for use in navigation."


#: ../../setup_guides/urdf/setup_urdf.rst:12
msgid "URDF and the Robot State Publisher"
msgstr "URDF and the Robot State Publisher"


#: ../../setup_guides/urdf/setup_urdf.rst:14
msgid "As discussed in the previous tutorial, one of the requirements for Navigation2 is the transformation from  ``base_link`` to the various sensors and reference frames. This transformation tree can range from a simple tree with only one link from the  ``base_link`` to ``laser_link`` or a tree comprised of multiple sensors located in different locations, each having their own coordinate frame. Creating multiple publishers to handle all of these coordinate frame transformations may become tedious. Therefore, we will be making use of the Robot State Publisher package to publish our transforms."
msgstr "As discussed in the previous tutorial, one of the requirements for Navigation2 is the transformation from  ``base_link`` to the various sensors and reference frames. This transformation tree can range from a simple tree with only one link from the  ``base_link`` to ``laser_link`` or a tree comprised of multiple sensors located in different locations, each having their own coordinate frame. Creating multiple publishers to handle all of these coordinate frame transformations may become tedious. Therefore, we will be making use of the Robot State Publisher package to publish our transforms."


#: ../../setup_guides/urdf/setup_urdf.rst:16
msgid "The Robot State Publisher is a package of ROS 2 that interacts with the tf2 package to publish all of the necessary transforms that can be directly inferred from the geometry and structure of the robot. We need to provide it with the correct URDF and it will automatically handle publishing the transforms. This is very useful for complex transformations but it is still recommended for simpler transform trees."
msgstr "The Robot State Publisher is a package of ROS 2 that interacts with the tf2 package to publish all of the necessary transforms that can be directly inferred from the geometry and structure of the robot. We need to provide it with the correct URDF and it will automatically handle publishing the transforms. This is very useful for complex transformations but it is still recommended for simpler transform trees."


#: ../../setup_guides/urdf/setup_urdf.rst:18
msgid "The Unified Robot Description Format (URDF) is an XML file that represents a robot model. In this tutorial, it will mainly be used to build transformations trees related with the robot geometry, but it also has other uses. One example is how it can be used in visualizing your robot model in RVIZ, a 3D Visualization tool for ROS, by defining visual components such as materials and meshes. Another example is how the URDF can be used to define the physical properties of the robot. These properties are then used in physics simulators such as Gazebo to simulate how your robot will interact in an environment."
msgstr "The Unified Robot Description Format (URDF) is an XML file that represents a robot model. In this tutorial, it will mainly be used to build transformations trees related with the robot geometry, but it also has other uses. One example is how it can be used in visualizing your robot model in RVIZ, a 3D Visualization tool for ROS, by defining visual components such as materials and meshes. Another example is how the URDF can be used to define the physical properties of the robot. These properties are then used in physics simulators such as Gazebo to simulate how your robot will interact in an environment."


#: ../../setup_guides/urdf/setup_urdf.rst:20
msgid "Another major feature of URDF is that it also supports Xacro (XML Macros) to help you create a shorter and readable XML to help in defining complex robots. We can use these macros to eliminate the need for repeating blocks of XML in our URDF. Xacro is also useful in defining configuration constants which can be reused throughout the URDF."
msgstr "Another major feature of URDF is that it also supports Xacro (XML Macros) to help you create a shorter and readable XML to help in defining complex robots. We can use these macros to eliminate the need for repeating blocks of XML in our URDF. Xacro is also useful in defining configuration constants which can be reused throughout the URDF."


#: ../../setup_guides/urdf/setup_urdf.rst:23
msgid "If you want to learn more about the URDF and the Robot State Publisher, we encourage you to have a look at the official `URDF Documentation <http://wiki.ros.org/urdf>`__ and `Robot State Publisher Documentation <http://wiki.ros.org/robot_state_publisher>`__"
msgstr "If you want to learn more about the URDF and the Robot State Publisher, we encourage you to have a look at the official `URDF Documentation <http://wiki.ros.org/urdf>`__ and `Robot State Publisher Documentation <http://wiki.ros.org/robot_state_publisher>`__"


#: ../../setup_guides/urdf/setup_urdf.rst:26
msgid "Setting Up the Environment"
msgstr "Setting Up the Environment"


#: ../../setup_guides/urdf/setup_urdf.rst:28
msgid "In this guide, we are assuming that you are already familiar with ROS 2 and how to setup your development environment, so we'll breeze through the steps in this section."
msgstr "In this guide, we are assuming that you are already familiar with ROS 2 and how to setup your development environment, so we'll breeze through the steps in this section."


#: ../../setup_guides/urdf/setup_urdf.rst:30
msgid "Let's begin by installing some additional ROS 2 packages that we will be using during this tutorial."
msgstr "Let's begin by installing some additional ROS 2 packages that we will be using during this tutorial."


#: ../../setup_guides/urdf/setup_urdf.rst:37
msgid "Next, create a directory for your project, initialize a ROS 2 workspace and give your robot a name. For ours, we'll be calling it ``sam_bot``."
msgstr "Next, create a directory for your project, initialize a ROS 2 workspace and give your robot a name. For ours, we'll be calling it ``sam_bot``."


#: ../../setup_guides/urdf/setup_urdf.rst:44
msgid "Writing the URDF"
msgstr "Writing the URDF"


#: ../../setup_guides/urdf/setup_urdf.rst:46
msgid "This section aims to provide you with a beginner-friendly introduction to building URDFs for your robot. If you would like to learn more about URDF and XAcro, we suggest for you to have a look at the official `URDF Documentation <http://wiki.ros.org/urdf>`__"
msgstr "This section aims to provide you with a beginner-friendly introduction to building URDFs for your robot. If you would like to learn more about URDF and XAcro, we suggest for you to have a look at the official `URDF Documentation <http://wiki.ros.org/urdf>`__"


#: ../../setup_guides/urdf/setup_urdf.rst:48
msgid "Now that we have our project workspace set up, let's dive straight into writing the URDF. Below is an image of the robot we will be trying to build."
msgstr "Now that we have our project workspace set up, let's dive straight into writing the URDF. Below is an image of the robot we will be trying to build."


#: ../../setup_guides/urdf/setup_urdf.rst:57
msgid "To get started, create a file named ``sam_bot_description.urdf`` under ``src/description`` and input the following as the initial contents of the file."
msgstr "To get started, create a file named ``sam_bot_description.urdf`` under ``src/description`` and input the following as the initial contents of the file."


#: ../../setup_guides/urdf/setup_urdf.rst:69
msgid "The following code snippets should be placed within the ``<robot>`` tags. We suggest to add them in the same order as introduced in this tutorial. We have also included some line numbers to give you a rough idea on where to input the code. This may differ from the actual file you are writing depending on your usage of whitespaces. Also note that the line numbers assume that you are putting in code as they appear in this guide."
msgstr "The following code snippets should be placed within the ``<robot>`` tags. We suggest to add them in the same order as introduced in this tutorial. We have also included some line numbers to give you a rough idea on where to input the code. This may differ from the actual file you are writing depending on your usage of whitespaces. Also note that the line numbers assume that you are putting in code as they appear in this guide."


#: ../../setup_guides/urdf/setup_urdf.rst:71
msgid "Next, let us define some constants using XAcro properties that will be reused throughout the URDF."
msgstr "Next, let us define some constants using XAcro properties that will be reused throughout the URDF."


#: ../../setup_guides/urdf/setup_urdf.rst:89
msgid "Here is a brief discussion on what these properties will represent in our urdf. The ``base_*`` properties all define the size of the robot's main chassis. The ``wheel_radius`` and ``wheel_width`` define the shape of the robot's two back wheels. The ``wheel_ygap`` adjusts the gap between the wheel and the chassis along the y-axis whilst ``wheel_zoff`` and ``wheel_xoff`` position the back wheels along the z-axis and x-axis appropriately. Lastly, the ``caster_xoff`` positions the front caster wheel along the x-axis."
msgstr "Here is a brief discussion on what these properties will represent in our urdf. The ``base_*`` properties all define the size of the robot's main chassis. The ``wheel_radius`` and ``wheel_width`` define the shape of the robot's two back wheels. The ``wheel_ygap`` adjusts the gap between the wheel and the chassis along the y-axis whilst ``wheel_zoff`` and ``wheel_xoff`` position the back wheels along the z-axis and x-axis appropriately. Lastly, the ``caster_xoff`` positions the front caster wheel along the x-axis."


#: ../../setup_guides/urdf/setup_urdf.rst:91
msgid "Let us then define our ``base_link`` - this link will be a large box and will act as the main chassis of our robot. In URDF, a ``link`` element describes a rigid part or component of our robot. The robot state publisher then utilizes these definitions to determine coordinate frames for each link and publish the transformations between them."
msgstr "Let us then define our ``base_link`` - this link will be a large box and will act as the main chassis of our robot. In URDF, a ``link`` element describes a rigid part or component of our robot. The robot state publisher then utilizes these definitions to determine coordinate frames for each link and publish the transformations between them."


#: ../../setup_guides/urdf/setup_urdf.rst:93
msgid "We will also be defining some of the link's visual properties which can be used by tools such as Gazebo and Rviz to show us a 3D model of our robot. Amongst these properties are ``<geometry>`` which describes the link's shape and ``<material>`` which describes it's color."
msgstr "We will also be defining some of the link's visual properties which can be used by tools such as Gazebo and Rviz to show us a 3D model of our robot. Amongst these properties are ``<geometry>`` which describes the link's shape and ``<material>`` which describes it's color."


#: ../../setup_guides/urdf/setup_urdf.rst:95
msgid "For the code block block below, we access the ``base`` properties from the robot constants sections we defined before using the ``${property}`` syntax. In addition, we also set the material color of the main chassis to ``Cyan``. Note that we set these parameters under the ``<visual>`` tag so they will only be applied as visual parameters which dont affect any collision or physical properties."
msgstr "For the code block block below, we access the ``base`` properties from the robot constants sections we defined before using the ``${property}`` syntax. In addition, we also set the material color of the main chassis to ``Cyan``. Note that we set these parameters under the ``<visual>`` tag so they will only be applied as visual parameters which dont affect any collision or physical properties."


#: ../../setup_guides/urdf/setup_urdf.rst:112
msgid "Next, let us define a ``base_footprint`` link. The ``base_footprint`` link is a virtual (non-physical) link which has no dimensions or collision areas. Its primary purpose is to enable various packages determine the center of a robot projected to the ground. For example, Navigation2 uses this link to determine the center of a circular footprint used in its obstacle avoidance algorithms. Again, we set this link with no dimensions and to which position the robot's center is in when it is projected to the ground plane."
msgstr "Next, let us define a ``base_footprint`` link. The ``base_footprint`` link is a virtual (non-physical) link which has no dimensions or collision areas. Its primary purpose is to enable various packages determine the center of a robot projected to the ground. For example, Navigation2 uses this link to determine the center of a circular footprint used in its obstacle avoidance algorithms. Again, we set this link with no dimensions and to which position the robot's center is in when it is projected to the ground plane."


#: ../../setup_guides/urdf/setup_urdf.rst:114
msgid "After defining our base_link, we then add a joint to connect it to ``base_link``. In URDF, a ``joint`` element describes the kinematic and dynamic properties between coordinate frames. For this case, we will be defining a ``fixed`` joint with the appropriate offsets to place our ``base_footprint`` link in the proper location based on the description above. Remember that we want to set our base_footprint to be at the ground plane when projected from the center of the main chassis, hence we get the sum of the ``wheel_radius`` and the ``wheel_zoff`` to get the appropriate location along the z-axis."
msgstr "After defining our base_link, we then add a joint to connect it to ``base_link``. In URDF, a ``joint`` element describes the kinematic and dynamic properties between coordinate frames. For this case, we will be defining a ``fixed`` joint with the appropriate offsets to place our ``base_footprint`` link in the proper location based on the description above. Remember that we want to set our base_footprint to be at the ground plane when projected from the center of the main chassis, hence we get the sum of the ``wheel_radius`` and the ``wheel_zoff`` to get the appropriate location along the z-axis."


#: ../../setup_guides/urdf/setup_urdf.rst:128
msgid "Now, we will be adding two large drive wheels to our robot. To make our code cleaner and avoid repetition, we will make use of macros to define a block of code that will be repeated with differing parameters. Our macro will have 3 params: ``prefix`` which simply adds a prefix to our link and joint names, and ``x_reflect`` and ``y_reflect`` which allows us to flip the positions of our wheels with respect to the x and y axis respectively. Within this macro, we can also define the visual properties of a single wheel. Lastly, we will also define a ``continuous`` joint to allow our wheels to freely rotate about an axis. This joint also connects our wheel to the ``base_link`` at the appropriate location."
msgstr "Now, we will be adding two large drive wheels to our robot. To make our code cleaner and avoid repetition, we will make use of macros to define a block of code that will be repeated with differing parameters. Our macro will have 3 params: ``prefix`` which simply adds a prefix to our link and joint names, and ``x_reflect`` and ``y_reflect`` which allows us to flip the positions of our wheels with respect to the x and y axis respectively. Within this macro, we can also define the visual properties of a single wheel. Lastly, we will also define a ``continuous`` joint to allow our wheels to freely rotate about an axis. This joint also connects our wheel to the ``base_link`` at the appropriate location."


#: ../../setup_guides/urdf/setup_urdf.rst:130
msgid "At the end of this code block, we will be instantiating two wheels using the macro we just made through the ``xacro:wheel`` tags. Note that we also define the parameters to have one wheel on both sides at the back of our robot."
msgstr "At the end of this code block, we will be instantiating two wheels using the macro we just made through the ``xacro:wheel`` tags. Note that we also define the parameters to have one wheel on both sides at the back of our robot."


#: ../../setup_guides/urdf/setup_urdf.rst:160
msgid "Next, we will be adding a caster wheel at the front of our robot. We will be modelling this wheel as a sphere to keep things simple. Again, we define the wheel's geometry, material and the joint to connect it to ``base_link`` at the appropriate location."
msgstr "Next, we will be adding a caster wheel at the front of our robot. We will be modelling this wheel as a sphere to keep things simple. Again, we define the wheel's geometry, material and the joint to connect it to ``base_link`` at the appropriate location."


#: ../../setup_guides/urdf/setup_urdf.rst:183
msgid "And that's it! We have built a URDF for a simple differential drive robot. In the next section, we will focus on building the ROS Package containing our URDF, launching the robot state publisher, and visualizing the robot in RVIz."
msgstr "And that's it! We have built a URDF for a simple differential drive robot. In the next section, we will focus on building the ROS Package containing our URDF, launching the robot state publisher, and visualizing the robot in RVIz."


#: ../../setup_guides/urdf/setup_urdf.rst:186
msgid "Build and Launch"
msgstr "Build and Launch"


#: ../../setup_guides/urdf/setup_urdf.rst:188
msgid "The launch files from this tutorial were adapted from the official `URDF Tutorials for ROS 2 <https://github.com/ros/urdf_tutorial/tree/ros2>`__"
msgstr "The launch files from this tutorial were adapted from the official `URDF Tutorials for ROS 2 <https://github.com/ros/urdf_tutorial/tree/ros2>`__"


#: ../../setup_guides/urdf/setup_urdf.rst:190
msgid "Let's start this section by adding some dependencies that will be required once we build this project. Open up the root of your project directory and add the following lines to your ``package.xml`` (preferably after the ``<buildtool_depend>`` tag)"
msgstr "Let's start this section by adding some dependencies that will be required once we build this project. Open up the root of your project directory and add the following lines to your ``package.xml`` (preferably after the ``<buildtool_depend>`` tag)"


#: ../../setup_guides/urdf/setup_urdf.rst:200
msgid "Next, let us create our launch file. Launch files are used by ROS 2 to bring up the necessary nodes for our package. From the root of the project, create a directory named ``launch`` and a ``display.launch.py`` file within it. The launch file below launches a robot publisher node in ROS 2 that uses our URDF to publish the transforms for our robot. In addition, the launch file also automatically launches RVIZ so we can visualize our robot as defined by the URDF. Copy and paste the snippet below into your ``display.launch.py`` file."
msgstr "Next, let us create our launch file. Launch files are used by ROS 2 to bring up the necessary nodes for our package. From the root of the project, create a directory named ``launch`` and a ``display.launch.py`` file within it. The launch file below launches a robot publisher node in ROS 2 that uses our URDF to publish the transforms for our robot. In addition, the launch file also automatically launches RVIZ so we can visualize our robot as defined by the URDF. Copy and paste the snippet below into your ``display.launch.py`` file."


#: ../../setup_guides/urdf/setup_urdf.rst:252
msgid "For more information regarding the launch system in ROS 2, you can have a look at the official `ROS 2 Launch System Documentation <https://docs.ros.org/en/rolling/Tutorials/Launch-system.html>`__"
msgstr "For more information regarding the launch system in ROS 2, you can have a look at the official `ROS 2 Launch System Documentation <https://docs.ros.org/en/rolling/Tutorials/Launch-system.html>`__"


#: ../../setup_guides/urdf/setup_urdf.rst:254
msgid "To keep things simpler when we get to visualization, we have provided an RVIz config file that will be loaded when we launch our package. This configuration file initializes RVIz with the proper settings so you can view the robot immediately once it launches. Create a directory named ``rviz`` in the root of your project and a file named ``urdf_config.rviz`` under it. Place the following as the contents of ``urdf_config.rviz``"
msgstr "To keep things simpler when we get to visualization, we have provided an RVIz config file that will be loaded when we launch our package. This configuration file initializes RVIz with the proper settings so you can view the robot immediately once it launches. Create a directory named ``rviz`` in the root of your project and a file named ``urdf_config.rviz`` under it. Place the following as the contents of ``urdf_config.rviz``"


#: ../../setup_guides/urdf/setup_urdf.rst:323
msgid "Lastly, let us modify the ``CMakeLists.txt`` file in the project root directory to include the files we just created during the package installation process. Add the following snippet to ``CMakeLists.txt`` file preferrably above the ``if(BUILD_TESTING)`` line:"
msgstr "Lastly, let us modify the ``CMakeLists.txt`` file in the project root directory to include the files we just created during the package installation process. Add the following snippet to ``CMakeLists.txt`` file preferrably above the ``if(BUILD_TESTING)`` line:"


#: ../../setup_guides/urdf/setup_urdf.rst:332
msgid "We are now ready to build our project using colcon. Navigate to the project root and execute the following commands."
msgstr "We are now ready to build our project using colcon. Navigate to the project root and execute the following commands."


#: ../../setup_guides/urdf/setup_urdf.rst:339
msgid "After a successful build, execute the following commands to install the ROS 2 package and launch our project."
msgstr "After a successful build, execute the following commands to install the ROS 2 package and launch our project."


#: ../../setup_guides/urdf/setup_urdf.rst:345
msgid "ROS 2 should now launch a robot publisher node and start up RVIZ using our URDF. We'll be taking a look at our robot using RVIZ in the next section."
msgstr "ROS 2 should now launch a robot publisher node and start up RVIZ using our URDF. We'll be taking a look at our robot using RVIZ in the next section."


#: ../../setup_guides/urdf/setup_urdf.rst:348
msgid "Visualization using RVIZ"
msgstr "Visualization using RVIZ"


#: ../../setup_guides/urdf/setup_urdf.rst:350
msgid "RVIZ is a robot visualization tool that allows us to see a 3D model of our robot using its URDF. Upon a successful launch using the commands in the previous section, RVIZ should now be visible on your screen and should look like the image below. You may need to move around and manipulate the view to get a good look at your robot."
msgstr "RVIZ is a robot visualization tool that allows us to see a 3D model of our robot using its URDF. Upon a successful launch using the commands in the previous section, RVIZ should now be visible on your screen and should look like the image below. You may need to move around and manipulate the view to get a good look at your robot."


#: ../../setup_guides/urdf/setup_urdf.rst:354
msgid "As you can see, we have successfully created a simple differential drive robot and visualized it in RVIz. It is not necessary to visualize your robot in RVIz, but it's a good step in order to see if you have properly defined your URDF. This helps you ensure that the robot state publisher is publishing the correct transformations."
msgstr "As you can see, we have successfully created a simple differential drive robot and visualized it in RVIz. It is not necessary to visualize your robot in RVIz, but it's a good step in order to see if you have properly defined your URDF. This helps you ensure that the robot state publisher is publishing the correct transformations."


#: ../../setup_guides/urdf/setup_urdf.rst:356
msgid "You may have noticed that another window was launched - this is a GUI for the joint state publisher. The joint state publisher is another ROS 2 package which publishes the state for our non-fixed joints. You can manipulate this publisher through the small GUI and the new pose of the joints will be reflected in RVIz. Sliding the bars for any of the two wheels will rotate these joints. You can see this in action by viewing RVIZ as you sweep the sliders in the Joint State Publisher GUI."
msgstr "You may have noticed that another window was launched - this is a GUI for the joint state publisher. The joint state publisher is another ROS 2 package which publishes the state for our non-fixed joints. You can manipulate this publisher through the small GUI and the new pose of the joints will be reflected in RVIz. Sliding the bars for any of the two wheels will rotate these joints. You can see this in action by viewing RVIZ as you sweep the sliders in the Joint State Publisher GUI."


#: ../../setup_guides/urdf/setup_urdf.rst:360
msgid "We won't be interacting much with this package for Nav2, but if you would like to know more about the joint state publisher, feel free to have a look at the official `Joint State Publisher Documentation <http://wiki.ros.org/joint_state_publisher>`_."
msgstr "We won't be interacting much with this package for Nav2, but if you would like to know more about the joint state publisher, feel free to have a look at the official `Joint State Publisher Documentation <http://wiki.ros.org/joint_state_publisher>`_."


#: ../../setup_guides/urdf/setup_urdf.rst:362
msgid "At this point, you may already decide to stop with this tutorial since we have already achieved our objective of creating a URDF for a simple differential drive robot. The robot state publisher is now publishing the transforms derived from the URDF. These transforms can now be used by other packages (such as Nav2) to get information regarding the shape and structure of your robot. However, to properly use this URDF in a simulation, we need physical properties so that the robot reacts to physical environments like a real robot would. The visualization fields are only for visualization, not collision, so your robot will drive straight through obstacles. We'll get into adding these properties in our URDF in the next section."
msgstr "At this point, you may already decide to stop with this tutorial since we have already achieved our objective of creating a URDF for a simple differential drive robot. The robot state publisher is now publishing the transforms derived from the URDF. These transforms can now be used by other packages (such as Nav2) to get information regarding the shape and structure of your robot. However, to properly use this URDF in a simulation, we need physical properties so that the robot reacts to physical environments like a real robot would. The visualization fields are only for visualization, not collision, so your robot will drive straight through obstacles. We'll get into adding these properties in our URDF in the next section."


#: ../../setup_guides/urdf/setup_urdf.rst:365
msgid "Adding Physical Properties"
msgstr "Adding Physical Properties"


#: ../../setup_guides/urdf/setup_urdf.rst:367
msgid "As an additional section to this guide, we will be modifying our current URDF to include some of our robot's kinematic properties. This information may be used by physics simulators such as Gazebo to model and simulate how our robot will act in the virtual environment."
msgstr "As an additional section to this guide, we will be modifying our current URDF to include some of our robot's kinematic properties. This information may be used by physics simulators such as Gazebo to model and simulate how our robot will act in the virtual environment."


#: ../../setup_guides/urdf/setup_urdf.rst:369
msgid "Let us first define macros containing the inertial properties of the geometric primitives we used in our project. Place the snippet below after our constants section in the URDF:"
msgstr "Let us first define macros containing the inertial properties of the geometric primitives we used in our project. Place the snippet below after our constants section in the URDF:"


#: ../../setup_guides/urdf/setup_urdf.rst:398
msgid "Let us start by adding collision areas to our ``base_link`` using the ``<collision>`` tag. We will also be using the box_inertia macro we defined before to add some inertial properties to our ``base_link``. Include the following code snippet within ``<link name=\"base_link\">`` tag of base_link in our URDF."
msgstr "Let us start by adding collision areas to our ``base_link`` using the ``<collision>`` tag. We will also be using the box_inertia macro we defined before to add some inertial properties to our ``base_link``. Include the following code snippet within ``<link name=\"base_link\">`` tag of base_link in our URDF."


#: ../../setup_guides/urdf/setup_urdf.rst:411
msgid "Next, let us do the same for our wheel macros. Include the following code snippet within the ``<link name=\"${prefix}_link\">`` tag of our wheel macros in our URDF."
msgstr "Next, let us do the same for our wheel macros. Include the following code snippet within the ``<link name=\"${prefix}_link\">`` tag of our wheel macros in our URDF."


#: ../../setup_guides/urdf/setup_urdf.rst:425
msgid "Lastly, let us add the similar properties to our spherical caster wheels. Include the following in the ``<link name=\"front_caster\">`` tag of our caster wheel in the URDF."
msgstr "Lastly, let us add the similar properties to our spherical caster wheels. Include the following in the ``<link name=\"front_caster\">`` tag of our caster wheel in the URDF."


#: ../../setup_guides/urdf/setup_urdf.rst:439
msgid "We did not add any inertial or collision properties to our ``base_footprint`` link since this is a virtual and non-physical link."
msgstr "We did not add any inertial or collision properties to our ``base_footprint`` link since this is a virtual and non-physical link."


#: ../../setup_guides/urdf/setup_urdf.rst:441
msgid "Build your project and then launch RViz using the same commands in the previous section."
msgstr "Build your project and then launch RViz using the same commands in the previous section."


#: ../../setup_guides/urdf/setup_urdf.rst:449
msgid "You can verify whether you have properly set up the collision areas by enabling ``Collision Enabled`` under ``RobotModel`` on the left pane (it may be easier to see if you also turn off ``Visual Enabled``). For this tutorial we defined a collision area which is similar to our visual properties. Note that this may not always be the case since you may opt for simpler collision areas based on how your robot looks."
msgstr "You can verify whether you have properly set up the collision areas by enabling ``Collision Enabled`` under ``RobotModel`` on the left pane (it may be easier to see if you also turn off ``Visual Enabled``). For this tutorial we defined a collision area which is similar to our visual properties. Note that this may not always be the case since you may opt for simpler collision areas based on how your robot looks."


#: ../../setup_guides/urdf/setup_urdf.rst:453
msgid "For now, we will have to stop here since we will need to set up a lot more components to actually start simulating our robot in Gazebo. We will be coming back to this project during the course of these setup guides, and we will eventually see our robot move in a virtual environment once we get to the simulation sections. The major components that are missing from this work are the simulation plugins required to mimic your robot controllers. We will introduce those and add them to this URDF in the appropriate section."
msgstr "For now, we will have to stop here since we will need to set up a lot more components to actually start simulating our robot in Gazebo. We will be coming back to this project during the course of these setup guides, and we will eventually see our robot move in a virtual environment once we get to the simulation sections. The major components that are missing from this work are the simulation plugins required to mimic your robot controllers. We will introduce those and add them to this URDF in the appropriate section."


#: ../../setup_guides/urdf/setup_urdf.rst:458
msgid "And that's it. In this tutorial, you have successfully created a URDF for a simple differential drive robot. You have also set up a ROS 2 project that launches a robot publisher node, which then uses your URDF to publish the robot's transforms. We have also used RViz to visualize our robot to verify whether our URDF is correct. Lastly, we have added in some physical properties to our URDF in order to prepare it for simulation."
msgstr "And that's it. In this tutorial, you have successfully created a URDF for a simple differential drive robot. You have also set up a ROS 2 project that launches a robot publisher node, which then uses your URDF to publish the robot's transforms. We have also used RViz to visualize our robot to verify whether our URDF is correct. Lastly, we have added in some physical properties to our URDF in order to prepare it for simulation."


#: ../../setup_guides/urdf/setup_urdf.rst:460
msgid "Feel free to use this tutorial as a template for your own robot. Remember that your main goal is to publish the correct transforms from your base_link up to your sensor_frames. Once these have been setup, then you may proceed to our other setup guides."
msgstr "Feel free to use this tutorial as a template for your own robot. Remember that your main goal is to publish the correct transforms from your base_link up to your sensor_frames. Once these have been setup, then you may proceed to our other setup guides."

