# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2020
# This file is distributed under the same license as the Navigation 2 package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2023.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Navigation 2 latest\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2023-06-18 21:11+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language: zh\n"
"Language-Team: zh <LL@li.org>\n"
"Plural-Forms: nplurals=1; plural=0;\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.12.1\n"


#: ../../setup_guides/algorithm/select_algorithm.rst:4
msgid "Setting Up Navigation Plugins"
msgstr "设置导航插件"


#: ../../setup_guides/algorithm/select_algorithm.rst:6
msgid "In this part of the guide, we discuss how your robot can utilize different planner and controller algorithms to complete navigation tasks. We will discuss some of the available algorithm plugins you can use based on your robot type and environment."
msgstr "在本指南的这部分中，我们将讨论如何利用不同的规划器和控制器算法来完成导航任务。我们将根据机器人类型和环境讨论一些可用的算法插件。"


#: ../../setup_guides/algorithm/select_algorithm.rst:9
msgid "Planner and Controller Servers"
msgstr "规划器和控制器服务器"


#: ../../setup_guides/algorithm/select_algorithm.rst:10
msgid "Navigation algorithms are implemented in Nav2 through the use of plugins running on ROS action servers - the planner, controller and behavior servers (among others). For this section, we discuss the planner and controller servers, which are the heart of the navigation stack. These servers may implement one or more algorithm plugins each with its own configuration tailored for a specific action or robot state. This guide will highlight the different algorithms based on the type of robot and environment the robot is deployed in. This guide will not cover behaviors, smoothers, etc as those are dependent on application and not hardware/environment to offer generalized advice."
msgstr "导航算法通过在ROS动作服务器上运行的插件在Nav2中实现-规划器、控制器和行为服务器（等等）。在本节中，我们讨论规划器和控制器服务器，它们是导航堆栈的核心。这些服务器可以实现一个或多个算法插件，每个插件都有自己的配置，针对特定的动作或机器人状态进行调整。本指南将根据机器人的类型和部署环境突出显示不同的算法。本指南不涉及行为、平滑器等方面，因为这些取决于应用程序而不是硬件/环境，无法提供一般化的建议。"


#: ../../setup_guides/algorithm/select_algorithm.rst:12
msgid "The planner server is responsible for implementing algorithms that compute the robot's path. For example, one plugin can be configured to compute a simple shortest path between two relatively near locations while another plugin computes for a path to locations that cover the entire robot environment."
msgstr "规划器服务器负责实现计算机器人路径的算法。例如，一个插件可以配置为计算两个相对较近位置之间的简单最短路径，而另一个插件则可以计算覆盖整个机器人环境的路径。"


#: ../../setup_guides/algorithm/select_algorithm.rst:14
msgid "The controller server generates the appropriate control efforts needed for a robot to complete a task in its local environment. These tasks include but are not limited to: following a path generated by the planner server, avoiding dynamic obstacles along this path, and even charging at a docking station."
msgstr "控制器服务器生成机器人在其局部环境中完成任务所需的适当控制力。这些任务包括但不限于：按照规划器服务器生成的路径行驶，避开路径上的动态障碍物，甚至在充电站充电。"


#: ../../setup_guides/algorithm/select_algorithm.rst:16
msgid "As mentioned before, the planner and controller servers host a map of one or multiple plugins wherein a certain plugin will be used for a certain environment, scenario, or task. For instance, the controller server can have a plugin for following a path when in long corridors to stay in the middle of the aisle, and then another plugin for avoiding dynamic obstacles in a crowded place. Selecting which planning algorithm to execute based on the robot's task can be done through the behavior tree of your navigation system or application server."
msgstr "如前所述，规划器和控制器服务器托管了一个或多个插件的地图，在特定环境、场景或任务中将使用特定的插件。例如，控制器服务器可以有一个插件，用于在长走廊中遵循路径以保持在过道中间，然后另一个插件用于在拥挤的场所避免动态障碍物。根据机器人的任务选择要执行的规划算法可以通过导航系统或应用服务器的行为树来完成。"


#: ../../setup_guides/algorithm/select_algorithm.rst:19
msgid "For a more in-depth discussion on Navigation Servers, we suggest to have a look at the `Navigation Servers <https://navigation.ros.org/concepts/index.html#navigation-servers>`_ section under the Navigation Concepts category."
msgstr "如果想深入讨论导航服务器，我们建议查看导航概念类别下的“导航服务器 <https://navigation.ros.org/concepts/index.html#navigation-servers>`_”部分。"


#: ../../setup_guides/algorithm/select_algorithm.rst:22
msgid "Selecting the Algorithm Plugins"
msgstr "选择算法插件"


#: ../../setup_guides/algorithm/select_algorithm.rst:24
msgid "In this section, we discuss some of the available algorithm plugins for the planner and controller servers. We also discuss the purpose of each algorithm, and for which type of robot they are recommended to be used. Lastly, we show some sample yaml configuration that specifies the plugin to be used for each server."
msgstr "在本节中，我们将讨论规划器和控制器服务器的一些可用算法插件。我们还将讨论每个算法的目的，以及推荐为哪种类型的机器人使用。最后，我们展示一些示例的 YAML 配置，指定每个服务器要使用的插件。"


#: ../../setup_guides/algorithm/select_algorithm.rst:27
msgid "The algorithm plugins you can use are not limited to the ones mentioned in this section. You may create custom plugins as well and new plugins are added to Nav2 regularly. For tutorials on how to write your own plugins, please see `Writing a New Planner Plugin <https://navigation.ros.org/plugin_tutorials/docs/writing_new_nav2planner_plugin.html>`_  and `Writing a New Controller Plugin <https://navigation.ros.org/plugin_tutorials/docs/writing_new_nav2controller_plugin.html>`_. The list of all available Nav2 plugins and their descriptions can be found in `Navigation Plugins Section <https://navigation.ros.org/plugins/index.html>`_."
msgstr "你可以使用的算法插件不仅限于本节中提到的插件。你也可以创建自定义插件，并且Nav2会定期添加新的插件。关于如何编写自己的插件的教程，请参阅“编写新的规划器插件”和“编写新的控制器插件”。所有可用的Nav2插件及其描述列表可以在“导航插件部分”中找到。"


#: ../../setup_guides/algorithm/select_algorithm.rst:30
msgid "Planner Server"
msgstr "规划器服务器"


#: ../../setup_guides/algorithm/select_algorithm.rst:32
msgid "The algorithm plugins for the planner server find the robot's path using a representation of its environment captured by its different sensors. Some of these algorithms operate by searching through the environment's grid space while others expand the robot's possible states while accounting for path feasibility."
msgstr "规划器服务器的算法插件使用机器人不同传感器捕捉到的环境表示来找到机器人的路径。其中一些算法通过搜索环境的网格空间来运行，而其他算法则通过考虑路径的可行性来扩展机器人的可能状态。"


#: ../../setup_guides/algorithm/select_algorithm.rst:34
msgid "As mentioned, the planner server may utilize plugins that work on the grid space such as the ``NavFn Planner``, ``Smac Planner 2D``, and ``Theta Star Planner``. The `NavFn planner <https://navigation.ros.org/configuration/packages/configuring-navfn.html>`_ is a navigation function planner that uses either Dijkstra or A*.  Next, the `Smac 2D planner <https://navigation.ros.org/configuration/packages/configuring-smac-planner.html>`_ implements a 2D A* algorithm using 4 or 8 connected neighborhoods with a smoother and multi-resolution query. Lastly, the `Theta Star planner <https://navigation.ros.org/configuration/packages/configuring-thetastar.html#>`_ is an implementation of Theta* using either line of sight to create non-discretely oriented path segments."
msgstr "如前所述，规划器服务器可以使用在网格空间上工作的插件，例如“NavFn规划器”、“Smac 2D规划器”和“Theta Star规划器”。NavFn规划器是一个导航函数规划器，它可以使用Dijkstra或A*算法。接下来，Smac 2D规划器使用4或8个相邻点的A*算法，在查询过程中具有更平滑和多分辨率的特点。最后，Theta Star规划器是Theta*算法的一个实现，可以使用视线来创建非离散定向的路径段。"


#: ../../setup_guides/algorithm/select_algorithm.rst:36
msgid "One issue you may encounter when using algorithms that work on the grid space is that there is no guarantee that a drivable path can be generated for any type of robot. For example, it is not guaranteed that the ``NavFn Planner`` can plan a feasible path for a non-circular robot in a tight space since it uses the circular footprint of a robot (by approximating the robot's largest cross-sectional radius) and checks for collisions per costmap grid cell. In addition, these algorithms are also not suitable for ackermann and legged robots since they have turning constraints. That being said, these plugins are best used on robots that can drive in any direction or rotate safely in place, such as **circular differential and circular omnidirectional** robots."
msgstr "使用在网格空间上工作的算法时可能会遇到一个问题，即不能保证能够为任何类型的机器人生成可行的路径。例如，不能保证``NavFn Planner``能够为紧凑空间中的非圆形机器人规划出可行的路径，因为它使用机器人的圆形足迹（通过估计机器人的最大横截面半径）并检查每个代价地图网格单元的碰撞情况。此外，这些算法也不适用于阿克曼（ackermann）和腿式机器人，因为它们具有转向约束。也就是说，这些插件最适用于可以任意方向行"


#: ../../setup_guides/algorithm/select_algorithm.rst:38
msgid "Another planner plugin is the `Smac Hybrid-A* planner <https://navigation.ros.org/configuration/packages/configuring-smac-planner.html>`_ that supports **arbitrary shaped ackermann and legged** robots. It is a highly optimized and fully reconfigurable Hybrid-A* implementation supporting Dubin and Reeds-Shepp motion models. This algorithm expands the robot's candidate paths while considering the robot's minimum turning radius constraint and the robot's full footprint for collision avoidance. Thus, this plugin is suitable for arbitrary shaped robots that require full footprint collision checking. It may also be used for high-speed robots that must be navigated carefully to not flip over, skid, or dump load at high speeds."
msgstr "另一个规划器插件是Smac Hybrid-A*规划器，它支持任意形状的Ackermann和Legged机器人。它是一个高度优化且完全可配置的Hybrid-A*算法实现，支持Dubin和Reeds-Shepp运动模型。该算法在考虑机器人的最小转弯半径约束和机器人的完整足迹以避免碰撞的同时，扩展机器人的候选路径。因此，该插件适用于需要进行完整足迹碰撞检查的任意形状机器人。它还可用于需要小心导航以避免翻车、打滑或高速时倾倒的高速机器人。"


#: ../../setup_guides/algorithm/select_algorithm.rst:40
msgid "There is also the ``Smac Lattice planner`` plugin which is based on a State Lattice planner. This plugin functions by expanding the robot state space while ensuring the path complies with the robot's kinematic constraints. The algorithm provides minimum control sets which allows it to support **differential, omnidirectional, and ackermann** vehicles of any shape and size with minimal reconfiguration."
msgstr "还有基于状态格的``Smac Lattice planner``插件。该插件通过扩展机器人状态空间，确保路径符合机器人的运动约束。该算法提供了最小控制集，使其能够支持**微分、全向和阿克曼**型车辆的任何形状和尺寸，并且最小程度上需要重新配置。"


#: ../../setup_guides/algorithm/select_algorithm.rst:43 ../../setup_guides/algorithm/select_algorithm.rst:85
msgid "Summary"
msgstr "总结"


#: ../../setup_guides/algorithm/select_algorithm.rst:46 ../../setup_guides/algorithm/select_algorithm.rst:88
msgid "Plugin Name"
msgstr "插件名称"


#: ../../setup_guides/algorithm/select_algorithm.rst:46 ../../setup_guides/algorithm/select_algorithm.rst:88
msgid "Supported Robot Types"
msgstr "支持的机器人类型"


#: ../../setup_guides/algorithm/select_algorithm.rst:48
msgid "NavFn Planner"
msgstr "NavFn规划器"


#: ../../setup_guides/algorithm/select_algorithm.rst:48
msgid "Circular Differential, Circular Omnidirectional"
msgstr "圆形差分，圆形全向"


#: ../../setup_guides/algorithm/select_algorithm.rst:50
msgid "Smac Planner 2D"
msgstr "Smac 2D规划器"


#: ../../setup_guides/algorithm/select_algorithm.rst:52
msgid "Theta Star Planner"
msgstr "Theta Star Planner"


#: ../../setup_guides/algorithm/select_algorithm.rst:54
msgid "Smac Hybrid-A* Planner"
msgstr "Smac混合A*规划器"


#: ../../setup_guides/algorithm/select_algorithm.rst:54
msgid "Non-circular or Circular Ackermann, Non-circular or Circular Legged"
msgstr "非圆形或圆形阿克曼，非圆形或圆形腿式"


#: ../../setup_guides/algorithm/select_algorithm.rst:56
msgid "Smac Lattice Planner"
msgstr "Smac格栅规划器"


#: ../../setup_guides/algorithm/select_algorithm.rst:56
msgid "Non-circular Differential, Non-circular Omnidirectional"
msgstr "非圆形差动，非圆形全向"


#: ../../setup_guides/algorithm/select_algorithm.rst:61 ../../setup_guides/algorithm/select_algorithm.rst:100
msgid "Example Configuration"
msgstr "示例配置"


#: ../../setup_guides/algorithm/select_algorithm.rst:71
msgid "An example configuration of the planner server is shown above. The ``planner_plugins`` parameter accepts a list of mapped planner plugin names. For each plugin namespace defined in ``planner_plugins`` (``GridBased`` in our example), we specify the type of plugin to be loaded in the ``plugin`` parameter. Additional configurations must then be specified in this namespace based on the algorithm to be used. Please see the `Configuration Guide <https://navigation.ros.org/configuration/index.html>`_ for more details."
msgstr "上面显示了规划器服务器的一个示例配置。'planner_plugins'参数接受一个映射的规划器插件名称列表。对于在'planner_plugins'中定义的每个插件命名空间（例如我们的示例中的'GridBased'），我们在'plugin'参数中指定要加载的插件类型。然后，必须在此命名空间中根据要使用的算法指定其他配置。有关更多详细信息，请参阅“配置指南”"


#: ../../setup_guides/algorithm/select_algorithm.rst:74
msgid "Controller Server"
msgstr "控制器服务器"


#: ../../setup_guides/algorithm/select_algorithm.rst:76
msgid "The default controller plugin is the `DWB controller <https://navigation.ros.org/configuration/packages/configuring-dwb-controller.html>`_. It implements a modified Dynamic Window Approach (DWA) algorithm with configurable plugins to compute the control commands for the robot. This controller makes use of a ``Trajectory Generator plugin`` that generates the set of possible trajectories. These are then evaluated by one or more ``Critic plugins``, each of which may give a different score based on how they are configured. The sum of the scores from these ``Critic plugins`` determine the overall score of a trajectory. The best scoring trajectory then determines the output command velocity."
msgstr "默认的控制器插件是`DWB controller <https://navigation.ros.org/configuration/packages/configuring-dwb-controller.html>`_。它实现了一种改进的动态窗口方法（DWA）算法，通过可配置的插件计算机器人的控制命令。该控制器使用一个生成可能轨迹集的``Trajectory Generator插件``。然后，这些轨迹由一个或多个``Critic插件``进行评估，每个插件根据其配置给出不同的评分。这些``Critic插件``的评分之和确定了轨迹的整体评分。评分最高的轨迹确定了输出的命令速度。"


#: ../../setup_guides/algorithm/select_algorithm.rst:78
msgid "The ``DWB controller`` can be used on **circular or non-circular differential, and circular or non-circular omnidirectional** robots. It may also be configured for **ackerman and legged** robots if it is given a ``Trajectory Generation plugin`` that produces a set of possible trajectories that considers the robot's minimum curvature constraint."
msgstr "``DWB控制器``可以用于**圆形或非圆形差动和全向**机器人。如果给它一个产生考虑到机器人最小曲率约束的可能轨迹集的``轨迹生成插件``，它还可以配置为**阿克曼和腿式**机器人。"


#: ../../setup_guides/algorithm/select_algorithm.rst:80
msgid "Another example of a controller server plugin is the `TEB controller <https://github.com/rst-tu-dortmund/teb_local_planner>`_ which is an MPC time optimal controller. It implements the Timed Elastic Band (TEB) approach which optimizes the robot's trajectory based on its execution time, distance from obstacles, and feasibility with respect to the robot's kinematic constraints. This controller can be used on **differential, omnidirectional, ackermann, and legged** robots."
msgstr "另一个控制器服务器插件的例子是`TEB controller <https://github.com/rst-tu-dortmund/teb_local_planner>`_，它是一种MPC最优控制器。它实现了基于执行时间、障碍物距离和符合机器人运动约束的时间弹性带（TEB）方法来优化机器人的轨迹。该控制器可以用于**微分、全向、阿克曼和腿式**机器人。"


#: ../../setup_guides/algorithm/select_algorithm.rst:82
msgid "The last example for this section is the `Regulated Pure Pursuit controller (RPP) <https://navigation.ros.org/configuration/packages/configuring-regulated-pp.html>`_ . This controller implements a variant of the pure pursuit algorithm with added regulation heuristic functions to manage collision and velocity constraints. This variation is implemented to target the needs of service or industrial robots and is suitable for use with **differential, ackermann, and legged** robots."
msgstr "本节的最后一个示例是 `Regulated Pure Pursuit控制器（RPP）<https://navigation.ros.org/configuration/packages/configuring-regulated-pp.html>`_ 。该控制器实现了一种变体的纯追踪算法，并添加了调节启发式函数来管理碰撞和速度约束。此变体是为满足服务或工业机器人的需求而实现的，并适用于**差动、阿克曼和腿式**机器人。"


#: ../../setup_guides/algorithm/select_algorithm.rst:88
msgid "Task"
msgstr "任务"


#: ../../setup_guides/algorithm/select_algorithm.rst:90
msgid "DWB controller"
msgstr "DWB控制器"


#: ../../setup_guides/algorithm/select_algorithm.rst:90
msgid "Differential, Omnidirectional"
msgstr "差动、全向"


#: ../../setup_guides/algorithm/select_algorithm.rst:90
msgid "Dynamic obstacle avoidance"
msgstr "动态障碍物避免"


#: ../../setup_guides/algorithm/select_algorithm.rst:92
msgid "TEB Controller"
msgstr "TEB 控制器"


#: ../../setup_guides/algorithm/select_algorithm.rst:92
msgid "Differential, Omnidirectional, Ackermann, Legged"
msgstr "差动、全向、阿克曼、腿式"


#: ../../setup_guides/algorithm/select_algorithm.rst:94
msgid "RPP controller"
msgstr "RPP 控制器"


#: ../../setup_guides/algorithm/select_algorithm.rst:94
msgid "Differential, Ackermann, Legged"
msgstr "差动、阿克曼、腿式"


#: ../../setup_guides/algorithm/select_algorithm.rst:94
msgid "Exact path following"
msgstr "精确路径跟随"


#: ../../setup_guides/algorithm/select_algorithm.rst:97
msgid "All of these algorithms work for both circular and non-circular robots."
msgstr "所有这些算法都适用于圆形和非圆形机器人。"


#: ../../setup_guides/algorithm/select_algorithm.rst:110
msgid "Shown above is a sample basic configuration of the controller server. The list of mapped names for controller plugins are defined in the ``controller_plugins`` parameter. Similar to the planner server, each namespace defined in the ``controller_plugins`` (``FollowPath`` in our example) must define the type of plugin it will use in the ``plugin`` parameter. Additional configurations must also be made for the selected algorithm in the namespace. Please see the `Configuration Guide <https://navigation.ros.org/configuration/index.html>`_ for more details."
msgstr "上图显示了控制器服务器的一个示例基本配置。控制器插件的映射名称列表在``controller_plugins``参数中定义。与规划器服务器类似，``controller_plugins``中定义的每个命名空间（在我们的示例中为``FollowPath``）必须在``plugin``参数中定义它将使用的插件类型。还必须对命名空间中选择的算法进行其他配置。有关详细信息，请参阅`配置指南<https://navigation.ros.org/configuration/index.html>`_。"


#: ../../setup_guides/algorithm/select_algorithm.rst:113
msgid "The planner and controller servers, along with the other servers of Nav2, are launched in ROS 2 through lifecycle nodes. Lifecycle nodes allow for easier bringup and teardown of the servers. Lifecycle node management will be discussed in the next tutorial."
msgstr "规划器和控制器服务器以及Nav2的其他服务器通过生命周期节点在ROS 2中启动。生命周期节点可以更轻松地启动和关闭服务器。生命周期节点管理将在下一个教程中讨论。"


#: ../../setup_guides/algorithm/select_algorithm.rst:116 ../../setup_guides/footprint/setup_footprint.rst:106 ../../setup_guides/odom/setup_odom.rst:565 ../../setup_guides/sensors/setup_sensors.rst:548 ../../setup_guides/transformation/setup_transforms.rst:109 ../../setup_guides/urdf/setup_urdf.rst:456
msgid "Conclusion"
msgstr "结论"


#: ../../setup_guides/algorithm/select_algorithm.rst:117
msgid "In this tutorial, we have discussed the roles and configuration of Nav2's planner and controller servers. To summarize, these servers host a map of one or more algorithm plugins which are selected depending on your robot's structure and surroundings. We also described a few of the available plugins for the planner and controller servers to help you identify which plugins are suitable for your robot. Lastly, we also provided some simple configuration examples to show how these plugins are instantiated on the servers. You can refer to the configuration guide of the algorithm plugin you will select for more details on its configuration parameters."
msgstr "在本教程中，我们讨论了Nav2规划器和控制器服务器的角色和配置。总结一下，这些服务器托管一个或多个算法插件的地图，选择插件取决于您的机器人结构和周围环境。我们还描述了一些可用于规划器和控制器服务器的插件，以帮助您确定哪些插件适合您的机器人。最后，我们还提供了一些简单的配置示例，以展示这些插件如何在服务器上实例化。有关所选算法插件的配置参数的详细信息，请参阅其配置指南。"


#: ../../setup_guides/footprint/setup_footprint.rst:4
msgid "Setting Up the Robot's Footprint"
msgstr "设置机器人的轮廓"


#: ../../setup_guides/footprint/setup_footprint.rst:6
msgid "In this guide, we will discuss how to configure the footprint of your robot for the navigation algorithms used by Nav2. We will also show a sample footprint configuration on ``sam_bot``, the simulated robot that we have been building in this series of setup guides. Lastly, we will also show the visualization of ``sam_bot``'s footprint in RViz to ensure that we have set it up correctly."
msgstr "在本指南中，我们将讨论如何配置机器人的足迹，以便Nav2使用的导航算法能够正常运行。我们还将在这一系列设置指南中一直在构建的仿真机器人“sam_bot”上展示一个样本足迹配置。最后，我们还将在RViz中显示“sam_bot”的足迹可视化，以确保我们设置正确。"


#: ../../setup_guides/footprint/setup_footprint.rst:9
msgid "Footprint Introduction"
msgstr "轮廓介绍"


#: ../../setup_guides/footprint/setup_footprint.rst:11
msgid "The footprint outlines the robot's 2D shape when projected to the ground and is primarily used by Nav2 to avoid collisions during planning. The algorithms involved in this task makes sure that the robot does not collide with the obstacles in the costmap while it computes the robot's paths or plans."
msgstr "足迹描述了机器人在投射到地面时的二维形状，主要用于Nav2在规划过程中避免碰撞。参与此任务的算法确保机器人在计算路径或规划过程中不会与代价地图中的障碍物发生碰撞。"


#: ../../setup_guides/footprint/setup_footprint.rst:13
msgid "The footprint is set up using the ``footprint`` or ``robot_radius`` parameter of the global and local costmaps which we tackled in the previous tutorials (:ref:`Setting Up Sensors Guide<setup_sensors>`). The value defined in the ``footprint`` parameter is an ordered vector of 2-D points defining the robot's footprint with the ``base_link`` frame as the origin. The first and last points in the vector are joined into the last line segment to close the footprint's shape. As an alternative, you may also use the ``robot_radius`` parameter wherein circular footprint is automatically generated and centered at ``base_link``.  In cases both the ``footprint`` and ``robot_radius`` parameters have been defined in the configuration, the ``footprint`` is used."
msgstr "通过在全局和局部成本地图的``footprint``或``robot_radius``参数中设置机器人的轮廓，我们可以设置机器人的轮廓。在前面的教程中我们已经介绍了这两个参数(:ref:`设置传感器指南<setup_sensors>`)。``footprint``参数中定义的值是一个有序的二维点向量，用于定义以``base_link``帧为原点的机器人轮廓。向量中的第一个和最后一个点被连接成最后一个线段以闭合轮廓的形状。作为替代，您还可以使用``robot_radius``参数，其中圆形轮廓会自动生成，并以``base_link``为中心。如果配置中同时定义了``footprint``和``robot_radius``参数，则使用``footprint``参数。"


#: ../../setup_guides/footprint/setup_footprint.rst:16
msgid "A section in the previous guide, :ref:`Configuring nav2_costmap_2d<configuring_nav2_costmap_2d>`, explains how to configure basic costmap parameters. Please refer to that guide for more details on costmap configuration."
msgstr "上一指南中的一节， :ref:`配置nav2_costmap_2d<configuring_nav2_costmap_2d>`，解释了如何配置基本代价地图参数。请参考该指南了解有关代价地图配置的更多细节。"


#: ../../setup_guides/footprint/setup_footprint.rst:18
msgid "For the global costmap footprint, the decision to choose between the ``robot_radius`` (circular) or ``footprint`` (polygon) parameter depends on the robot, its environment, and the path planning algorithm you will use. Even if you are working with a non-circular robot, there may be situations where a circular footprint is acceptable. For example, path planning algorithms like `NavFn <https://navigation.ros.org/configuration/packages/configuring-navfn.html>`_ assume that the robot is circular since it only checks for collision per grid cell, so it will not be necessary to outline the robot's exact shape for its footprint. On the other hand, algorithms such as `Smac Planner's Hybrid-A* <https://navigation.ros.org/configuration/packages/configuring-smac-planner.html>`_ perform collision checking on the robot's polygon-shaped footprint if possible and necessary. Hence, it might be useful to use a polygon-shaped footprint. Another example is having a small RC car sized robot roaming a warehouse. This robot is so small it won't need to make confined maneuvers -- thusly approximating it with the largest cross-sectional radius is a good time-saving optimization."
msgstr "对于全局代价地图的轮廓，选择使用“robot_radius”（圆形）还是“footprint”（多边形）参数取决于机器人、其环境以及您将使用的路径规划算法。即使您使用的是非圆形机器人，也可能存在接受圆形轮廓的情况。例如，像`NavFn <https://navigation.ros.org/configuration/packages/configuring-navfn.html>`_ 这样的路径规划算法假设机器人是圆形的，因为它只在每个栅格单元格中检查碰撞，因此不需要为机器人的轮廓描绘出准确的形状。另一方面，如果可能和必要的话，像`Smac Planner's Hybrid-A* <https://navigation.ros.org/configuration/packages/configuring-smac-planner.html>`_ 这样的算法会对机器人的多边形轮廓进行碰撞检查。因此，使用多边形轮廓可能会很有用。另一个例子是有一个大小为小型遥控汽车的机器人在仓库里漫游。这个机器人非常小，不需要进行局限的机动操作，因此用最大的横截面半径来近似它是一个节省时间的优化方法。"


#: ../../setup_guides/footprint/setup_footprint.rst:20
msgid "For the local costmap footprint, it is typical for non-circular robots to be set up with ``footprint`` (polygon). Some situations where this is not recommended is when you do not have enough computing resources to implement collision avoidance algorithms on a polygon-shaped footprint. Another possible reason to use ``robot_radius`` (circular) for the local costmap is when the robot is very small relative to its environment such that precise collision avoidance is not necessary. However, generally the local trajectory planner should use the actual footprint polygon of the robot."
msgstr "对于局部代价地图足迹，非圆形机器人通常使用“足迹”（多边形）进行设置。不推荐使用多边形足迹的情况包括计算资源不足以实现多边形足迹上的碰撞避免算法，或者机器人相对其环境非常小以至于不需要精确的碰撞避免。然而，通常情况下，局部轨迹规划器应使用机器人的实际足迹多边形。"


#: ../../setup_guides/footprint/setup_footprint.rst:23
msgid "Configuring the Robot's Footprint"
msgstr "配置机器人的轮廓"


#: ../../setup_guides/footprint/setup_footprint.rst:24
msgid "In this section, we will configure the footprint of ``sam_bot`` such that ``footprint`` (polygon) is used for the local costmap and ``robot_radius`` (circular) is used for the global costmap. We will utilize the default configuration file of Nav2 with a modified footprint parameter for the global and local costmaps."
msgstr "在本节中，我们将配置“sam_bot”的足迹，以便局部代价地图使用“足迹”（多边形），而全局代价地图使用“机器人半径”（圆形）。我们将利用Nav2的默认配置文件，并修改全局和局部代价地图的足迹参数。"


#: ../../setup_guides/footprint/setup_footprint.rst:26
msgid "The complete source code for ``sam_bot`` can be found in `navigation2_tutorials <https://github.com/ros-planning/navigation2_tutorials/tree/master/sam_bot_description>`_ repository."
msgstr "完整的 ``sam_bot`` 源代码可以在 `navigation2_tutorials <https://github.com/ros-planning/navigation2_tutorials/tree/master/sam_bot_description>`_ 存储库中找到。"


#: ../../setup_guides/footprint/setup_footprint.rst:28
msgid "Under the ``config`` directory, create a new file named  ``nav2_params.yaml``. Next, copy the contents of `config/nav2_params.yaml <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/config/nav2_params.yaml>`_ and paste them into the newly created file. The contents of `config/nav2_params.yaml <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/config/nav2_params.yaml>`_ are copied from the default configuration file of Nav2 but with changes in the ``footprint`` and  ``robot_radius`` parameters to match the shape of ``sam_bot``."
msgstr "在“config”目录下，创建一个名为“nav2_params.yaml”的新文件。然后，将`config/nav2_params.yaml <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/config/nav2_params.yaml>`_的内容复制并粘贴到新创建的文件中。`config/nav2_params.yaml <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/config/nav2_params.yaml>`_的内容是从Nav2的默认配置文件复制而来，但对“足迹”和“机器人半径”参数进行了修改，以匹配“sam_bot”的形状。"


#: ../../setup_guides/footprint/setup_footprint.rst:31
msgid "The default configuration file for Nav2 can be found in the official `Navigation2 repository <https://github.com/ros-planning/navigation2/blob/galactic/nav2_bringup/bringup/params/nav2_params.yaml>`_."
msgstr "Nav2的默认配置文件可以在官方的 `Navigation2存储库 <https://github.com/ros-planning/navigation2/blob/galactic/nav2_bringup/bringup/params/nav2_params.yaml>`_ 中找到。"


#: ../../setup_guides/footprint/setup_footprint.rst:33
msgid "Below is the code snippet from ``nav2_params.yaml`` defining the local costmap footprint. In this configuration file, the ``footprint`` parameter of the local costmap has already been set with a rectangular-shaped footprint. This box is centered at the ``base_link`` frame of ``sam_bot``."
msgstr "以下是来自“nav2_params.yaml”的代码片段，定义了局部代价地图的足迹。在此配置文件中，局部代价地图"


#: ../../setup_guides/footprint/setup_footprint.rst:42
msgid "For the global costmap, we have already set the ``robot_radius`` parameter to create a circular footprint that matches ``sam_bot``'s size and centered at ``base_link``. The parameter that was modified is shown in the code snippet below."
msgstr "对于全局代价地图，我们已经将 ``robot_radius`` 参数设置为创建一个与 ``sam_bot`` 大小匹配且以 ``base_link`` 为中心的圆形轮廓。下面的代码片段显示了被修改的参数。"


#: ../../setup_guides/footprint/setup_footprint.rst:52 ../../setup_guides/odom/setup_odom.rst:294 ../../setup_guides/odom/setup_odom.rst:486 ../../setup_guides/sensors/setup_sensors.rst:248 ../../setup_guides/sensors/setup_sensors.rst:435
msgid "Build, Run and Verification"
msgstr "构建、运行和验证"


#: ../../setup_guides/footprint/setup_footprint.rst:53
msgid "We will now confirm that we have properly set up ``sam_bot``'s footprint."
msgstr "现在我们将确认我们已正确设置了 ``sam_bot`` 的轮廓。"


#: ../../setup_guides/footprint/setup_footprint.rst:55
msgid "First, we launch `launch/display.launch.py <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/launch/display.launch.py>`_ to launch the robot state publisher, spawn ``sam_bot`` in Gazebo, and visualize ``sam_bot`` and its footprint in Rviz. The robot state publisher publishes the ``base_link`` => ``sensors`` transforms defined in ``sam_bot``'s URDF, while Gazebo's differential drive plugin publishes the ``odom`` => ``base_link`` transform. Open a new terminal and execute the lines below."
msgstr "首先，我们启动 `launch/display.launch.py <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/launch/display.launch.py>`_，启动机器人状态发布器，在Gazebo中生成 ``sam_bot``，并在Rviz中可视化 ``sam_bot`` 及其足迹。机器人状态发布器发布了 ``sam_bot`` URDF 中定义的 ``base_link`` => ``sensors`` 转换，而Gazebo的差动驱动插件发布了 ``odom`` => ``base_link`` 转换。打开一个新的终端并执行以下命令行。"


#: ../../setup_guides/footprint/setup_footprint.rst:63
msgid "After launching ``display.launch.py``, RViz and Gazebo should open. RViz should show ``sam_bot``, the frames of ``sam_bot``'s parts, and the ``odom`` frame without errors. Gazebo should show ``sam_bot`` with a sphere and a cube detectable by ``sambot``'s lidar sensor."
msgstr "在启动 ``display.launch.py`` 后，RViz 和 Gazebo 应该会打开。RViz 应该显示 ``sam_bot``、``sam_bot`` 零件的坐标系以及 ``odom`` 坐标系，而且不应出现错误。Gazebo 应该显示具有一个球体和一个立方体的 ``sam_bot``，这些物体可以被 ``sambot`` 的激光雷达传感器检测到。"


#: ../../setup_guides/footprint/setup_footprint.rst:65
msgid "Next, we will publish the ``map`` => ``odom`` transform using the ``static_transform_publisher``. We publish the ``map`` => ``odom`` transform as static in this guide as a simple way to publish the transform and visualize the footprint. Open a new terminal and execute the lines below."
msgstr "接下来，我们将使用 ``static_transform_publisher`` 发布 ``map`` => ``odom`` 转换。在本指南中，我们将 ``map`` => ``odom`` 转换设置为静态转换，作为一种简单的方式来发布转换和可视化足迹。打开一个新的终端并执行以下命令行。"


#: ../../setup_guides/footprint/setup_footprint.rst:71
msgid "The ``map`` => ``odom`` transform should now be being published and the ``map`` frame should be added in RViz without errors."
msgstr "现在应该正在发布 ``map`` => ``odom`` 的变换，并且在 RViz 中添加 ``map`` 帧时不会出现错误。"


#: ../../setup_guides/footprint/setup_footprint.rst:73
msgid "Lastly, we will launch Nav2 using the ``nav2_params.yaml`` configuration file we just made and ``navigation_launch.py``, the built-in launch file of ``nav2_bringup``. Open a new terminal and execute the following:"
msgstr "最后，我们将使用刚刚创建的 ``nav2_params.yaml`` 配置文件和 ``nav2_bringup`` 的内置启动文件 ``navigation_launch.py`` 启动Nav2。打开一个新的终端并执行以下命令："


#: ../../setup_guides/footprint/setup_footprint.rst:79
msgid "We should now be able to visualize the footprints in RViz, which will be discussed in the next section."
msgstr "现在我们应该能够在 RViz 中可视化机器人的足迹，在下一节中将对此进行讨论。"


#: ../../setup_guides/footprint/setup_footprint.rst:82
msgid "Visualizing Footprint in RViz"
msgstr "在RViz中可视化足迹"


#: ../../setup_guides/footprint/setup_footprint.rst:83
msgid "To visualize the footprint of the local costmap, click the add button at the bottom-left part of the RViz window. Under the ``By topic`` tab, select the ``Polygon`` under the ``/local_costmap/published_footprint`` topic, as shown below."
msgstr "要可视化局部代价地图的足迹，请单击 RViz 窗口左下角的添加按钮。在``按主题``选项卡下，选择``/local_costmap/published_footprint`` 主题下的 ``Polygon``，如下所示。"


#: ../../setup_guides/footprint/setup_footprint.rst:89
msgid "Set the fixed frame in RViz to ``odom`` and you should see the rectangular-shaped footprint of ``sam_bot``:"
msgstr "将RViz中的固定坐标系设置为 ``odom``，您应该看到 ``sam_bot`` 的矩形足迹："


#: ../../setup_guides/footprint/setup_footprint.rst:94
msgid "On the other hand, for the global costmap, click the add button at the bottom-left part of the RViz window. Go to ``By topic`` tab then select the ``Polygon`` under the ``/global_costmap/published_footprint`` topic, as shown below."
msgstr "另一方面，要在全局代价地图中进行可视化，请单击 RViz 窗口左下角的添加按钮。转到``按主题``选项卡，然后选择 ``/global_costmap/published_footprint`` 主题下的 ``Polygon``，如下所示。"


#: ../../setup_guides/footprint/setup_footprint.rst:100
msgid "Set the fixed frame in RViz to ``map`` and you should see the circular footprint of ``sam_bot``:"
msgstr "将RViz中的固定坐标系设置为 ``map``，您应该看到 ``sam_bot`` 的圆形足迹："


#: ../../setup_guides/footprint/setup_footprint.rst:107
msgid "In this guide, we have shown how to configure a circular and polygon-shaped footprint for your robot. This footprint is important since it plays a major role in Nav2's pathfinding algorithms function."
msgstr "在本指南中，我们展示了如何为您的机器人配置圆形和多边形足迹。这个足迹非常重要，因为它在 Nav2 的路径规划算法中起着重要作用。"


#: ../../setup_guides/footprint/setup_footprint.rst:109
msgid "As a demo, we have configured the costmap footprint parameters of  ``sam_bot``. We set the local costmap to use a polygon-shaped footprint following ``sam_bot``'s shape while we set the the global costmap to use a circular footprint. Lastly, we visualized and confirmed the footprints of the local and global costmaps in RViz."
msgstr "作为演示，我们已经配置了 ``sam_bot`` 的代价地图足迹参数。我们将局部代价地图设置为使用 ``sam_bot`` 的形状的多边形足迹，而全局代价地图则使用圆形足迹。最后，我们在RViz中可视化并确认了局部和全局代价地图的足迹。"


#: ../../setup_guides/index.rst:4
msgid "First-Time Robot Setup Guide"
msgstr "首次机器人设置指南"


#: ../../setup_guides/index.rst:6
msgid "This section is a collection of guides that aims to provide readers a good resource for setting up Nav2. The objectives for this section are as follows:"
msgstr "本部分是一系列指南，旨在为读者提供一个很好的资源，用于设置Nav2。本部分的目标如下："


#: ../../setup_guides/index.rst:8
msgid "Help new users with setting up Navigation2 with a new robot"
msgstr "帮助新用户设置带有新机器人的 Navigation2"


#: ../../setup_guides/index.rst:9
msgid "Help people with custom built robots to properly set up their robots to be used in ROS/Navigation2"
msgstr "帮助使用自定义构建的机器人的人们正确设置其机器人以在ROS/Navigation2中使用"


#: ../../setup_guides/index.rst:10
msgid "Act as a checklist, template or boilerplate reference for more experienced readers"
msgstr "作为一个检查清单、模板或样板参考，供更有经验的读者使用"


#: ../../setup_guides/index.rst:11
msgid "Provide examples which can be run on simulators/tools like Gazebo or RViz to guide readers on the Nav2 setup process even without a physical robot."
msgstr "提供可以在模拟器/工具（如Gazebo或RViz）上运行的示例，以指导读者进行Nav2设置过程，即使没有物理机器人。"


#: ../../setup_guides/index.rst:12
msgid "Broad strokes, tips, and tricks for configuring certain packages and integrating different components of the robot platform (sensors, odometry, etc.)"
msgstr "用于配置特定软件包和集成机器人平台的不同组件（传感器、里程计等）的基本信息、技巧和窍门"


#: ../../setup_guides/index.rst:14
msgid "To guide you through the first-time setup of your robot, we will be tackling the following topics:"
msgstr "为了指导您完成机器人的首次设置，我们将涉及以下主题："


#: ../../setup_guides/index.rst:16
msgid "Introduce TF2 and setup your robot URDF"
msgstr "介绍TF2并设置机器人URDF"


#: ../../setup_guides/index.rst:17
msgid "Setup sensor sources for robot odometry"
msgstr "为机器人里程计设置传感器源"


#: ../../setup_guides/index.rst:18
msgid "Setup sensor sources for perception"
msgstr "设置感知的传感器源"


#: ../../setup_guides/index.rst:19
msgid "Configure round or arbitrary shaped footprints for your robot"
msgstr "为您的机器人配置圆形或任意形状的足迹"


#: ../../setup_guides/index.rst:20
msgid "Select and set up planner and controller navigation plugins for your robot's navigation tasks"
msgstr "为机器人的导航任务选择和设置规划器和控制器导航插件"


#: ../../setup_guides/index.rst:21
msgid "Lifecycle node management for easy bringup of other related sensors or nodes"
msgstr "生命周期节点管理，方便引入其他相关传感器或节点"


#: ../../setup_guides/index.rst:23
msgid "These tutorials are not meant to be full tuning and configuration guides since they only aim to help you get your robot up and running with a basic configuration. For more detailed discussions and guides on how to customize and tune Nav2 for your robot, head on to the :ref:`configuration` section."
msgstr "这些教程不旨在成为完整的调优和配置指南，因为它们只旨在帮助您使用基本配置启动和运行机器人。如需有关如何自定义和调优适用于您的机器人的Nav2的详细讨论和指南，请参阅 :ref:`configuration` 部分。"


#: ../../setup_guides/index.rst:25
msgid "**Table of Contents:**"
msgstr "**目录：**"


#: ../../setup_guides/odom/setup_odom.rst:2
msgid "Setting Up Odometry"
msgstr "设置里程计"


#: ../../setup_guides/odom/setup_odom.rst:4
msgid "In this guide, we will be looking at how to integrate our robot's odometry system with Nav2. First we will provide a brief introduction on odometry, plus the necessary messages and transforms that need to be published for Nav2 to function correctly. Next, we will show how to setup odometry with two different cases. In the first case, we will show how to setup an odometry system for a robot with already available wheel encoders. In the second case, we will build a demo that simulates a functioning odometry system on ``sam_bot`` (the robot that we built in the previous section) using Gazebo. Afterwards, we will discuss how various sources of odometry can be fused to provide a smoothed odometry using the ``robot_localization`` package. Lastly, we will also show how to publish the ``odom`` => ``base_link`` transform using ``robot_localization``."
msgstr "在本指南中，我们将介绍如何将我们机器人的里程计系统与Nav2集成。首先，我们将简要介绍里程计，以及需要发布的消息和变换，以确保Nav2的正常运行。接下来，我们将展示如何设置两种不同情况下的里程计。在第一种情况下，我们将展示如何为已有轮式编码器的机器人设置里程计系统。在第二种情况下，我们将在Gazebo中构建一个演示，模拟使用``sam_bot``（我们在上一节中构建的机器人）的正常运行的里程计系统。然后，我们将讨论如何将各种里程计来源融合，以提供平滑的里程计，使用``robot_localization``软件包。最后，我们还将展示如何使用``robot_localization``发布``odom`` => ``base_link``的变换。"


#: ../../setup_guides/odom/setup_odom.rst:7 ../../setup_guides/urdf/setup_urdf.rst:9
msgid "The complete source code in this tutorial can be found in `navigation2_tutorials <https://github.com/ros-planning/navigation2_tutorials/tree/master/sam_bot_description>`_ repository under the ``sam_bot_description`` package. Note that the repository contains the full code after accomplishing all the tutorials in this guide."
msgstr "本教程中的完整源代码可以在 `navigation2_tutorials <https://github.com/ros-planning/navigation2_tutorials/tree/master/sam_bot_description>`_ 存储库的 ``sam_bot_description`` 包中找到。请注意，该存储库包含完成本指南中所有教程后的完整代码。"


#: ../../setup_guides/odom/setup_odom.rst:10
msgid "Odometry Introduction"
msgstr "里程计简介"


#: ../../setup_guides/odom/setup_odom.rst:12
msgid "The odometry system provides a locally accurate estimate of a robot's pose and velocity based on its motion. The odometry information can be obtained from various sources such as IMU, LIDAR, RADAR, VIO, and wheel encoders. One thing to note is that IMUs drift over time while wheel encoders drift over distance traveled, thus they are often used together to counter each other's negative characteristics."
msgstr "里程计系统根据机器人的运动提供局部精确的姿态和速度估计。里程计信息可以从各种来源获取，例如惯性测量单元 (IMU)、激光雷达 (LIDAR)、雷达 (RADAR)、视觉惯性里程计 (VIO) 和轮子编码器。需要注意的是，IMU会随时间漂移，而轮子编码器会随行驶距离漂移，因此通常将它们结合使用以抵消彼此的负面特征。"


#: ../../setup_guides/odom/setup_odom.rst:14
msgid "The ``odom`` frame and the transformation associated with it use a robot's odometry system to publish localization information that is continuous but becomes less accurate over time or distance (depending on the sensor modalities and drift). In spite of this, the information can still be used by the robot to navigate its immediate vicinity (e.g collision avoidance). To obtain consistently accurate odometry information over time, the ``map`` frame provides globally accurate information that is used to correct the ``odom`` frame."
msgstr "``odom``坐标系及其相关变换使用机器人的里程计系统发布连续但随时间或距离准确性逐渐降低的定位信息（取决于传感器模态和漂移情况）。尽管如此，机器人仍然可以使用这些信息来导航其周围的环境（例如避免碰撞）。为了获得一致准确的里程计信息，``map``坐标系提供了全局准确的信息，用于校正``odom``坐标系。"


#: ../../setup_guides/odom/setup_odom.rst:16
msgid "As discussed in the previous guides and in `REP 105 <https://www.ros.org/reps/rep-0105.html>`_, the ``odom`` frame is connected to the rest of the system and Nav2 through the ``odom`` => ``base_link`` transform. This transform is published by a tf2 broadcaster or by frameworks such as ``robot_localization``, which also provide additional functionalities. We will be talking more about ``robot_localization`` in a following section."
msgstr "如前面的指南和 `REP 105 <https://www.ros.org/reps/rep-0105.html>`_ 中所讨论的那样，``odom`` 坐标系与系统的其余部分和 Nav2 通过 ``odom`` => ``base_link`` 变换相连。这个变换由 tf2 发布器或像 ``robot_localization`` 这样的框架发布。``robot_localization`` 还提供额外的功能。我们将在后面的章节中详细讨论 ``robot_localization``。"


#: ../../setup_guides/odom/setup_odom.rst:18
msgid "In addition to the required ``odom`` => ``base_link`` transform, Nav2 also requires the publishing of ``nav_msgs/Odometry`` message because this message provides the velocity information of the robot. In detail, the ``nav_msgs/Odometry`` message contains the following information:"
msgstr "除了必需的``odom`` => ``base_link``变换之外，Nav2还需要发布``nav_msgs/Odometry``消息，因为该消息提供了机器人的速度信息。具体而言，``nav_msgs/Odometry``消息包含以下信息："


#: ../../setup_guides/odom/setup_odom.rst:38
msgid "This message tells us the estimates for the pose and velocity of the robot. The ``header`` message provides the timestamped data in a given coordinate frame. The ``pose`` message provides the position and orientation of the robot relative to the frame specified in ``header.frame_id``. The ``twist`` message gives the linear and angular velocity relative to the frame defined in ``child_frame_id``."
msgstr "该消息告诉我们机器人的姿态和速度估计值。``header`` 消息在给定坐标系中提供时间戳数据。``pose`` 消息提供机器人相对于 ``header.frame_id`` 指定的坐标系的位置和方向。``twist`` 消息提供相对于 ``child_frame_id`` 中定义的坐标系的线速度和角速度。"


#: ../../setup_guides/odom/setup_odom.rst:42
msgid "Setting Up Odometry on your Robot"
msgstr "设置机器人的里程计"


#: ../../setup_guides/odom/setup_odom.rst:44
msgid "Setting up the odometry system for Nav2 for your physical robot depends a lot on which odometry sensors are available with your robot. Due to the large number of configurations your robot may have, specific setup instructions will not be within the scope of this tutorial. Instead, we will provide some basic examples and useful resources to help you configure your robot for Nav2."
msgstr "为 Nav2 设置物理机器人的里程计系统主要取决于机器人可用的里程计传感器。由于您的机器人可能有大量的配置，特定的设置说明不在本教程的范围内。相反，我们将提供一些基本示例和有用的资源，以帮助您为 Nav2 配置机器人。"


#: ../../setup_guides/odom/setup_odom.rst:46
msgid "To start, we will use an example of a robot with wheel encoders as its odometry source. Note that wheel encoders are not required for Nav2 but it is common in most setups. The goal in setting up the odometry is to compute the odometry information and publish the ``nav_msgs/Odometry`` message and ``odom`` => ``base_link`` transform over ROS 2. To calculate this information, you will need to setup some code that will translate wheel encoder information into odometry information, similar to the snippet below:"
msgstr "首先，我们将使用一个带有轮式编码器作为里程计来源的机器人示例。请注意，轮式编码器在Nav2中并不是必需的，但在大多数设置中很常见。设置里程计的目标是计算里程计信息，并通过ROS 2发布``nav_msgs/Odometry``消息和``odom`` => ``base_link``转换。为了计算这些信息，您需要设置一些代码，将轮式编码器信息转换为里程计信息，类似下面的代码片段："


#: ../../setup_guides/odom/setup_odom.rst:53
msgid "The ``right_wheel_est_vel`` and ``left_wheel_est_vel`` are the estimated velocities of the right and left wheels respectively, and the ``wheel separation`` is the distance between the wheels. The values of ``right_wheel_est_vel`` and ``left_wheel_est_vel`` can be obtained by simply getting the changes in the positions of the wheel joints over time. This information can then be used to publish the Nav2 requirements. A basic example on how to do this can be found in the Navigation documentation on odometry `located here <http://wiki.ros.org/navigation/Tutorials/RobotSetup/Odom/>`_"
msgstr "``right_wheel_est_vel`` 和 ``left_wheel_est_vel`` 分别是右轮和左轮的估计速度，而 ``wheel separation`` 是轮子之间的距离。可以通过简单地获取轮子关节随时间的位置变化来获得 ``right_wheel_est_vel`` 和 ``left_wheel_est_vel`` 的值。然后可以使用这些信息来发布 Nav2 的要求。有关如何执行此操作的基本示例，请参阅里程计导航文档中的 `此处 <http://wiki.ros.org/navigatio"


#: ../../setup_guides/odom/setup_odom.rst:55
msgid "An alternative to manually publishing this information that we recommend is through the ``ros2_control`` framework. The ``ros2_control`` framework contains various packages for real-time control of robots in ROS 2. For wheel encoders, ``ros2_control`` has a ``diff_drive_controller`` (differential drive controller) under the ``ros2_controller`` package. The ``diff_drive_controller`` takes in the ``geometry_msgs/Twist`` messages published on ``cmd_vel`` topic, computes odometry information, and publishes ``nav_msgs/Odometry`` messages on ``odom`` topic. Other packages that deal with different kind of sensors are also available in ``ros2_control``."
msgstr "我们建议的一种手动发布此信息的替代方法是通过``ros2_control``框架。``ros2_control``框架包含了用于在ROS 2中实时控制机器人的各种软件包。对于轮式编码器，``ros2_control``在``ros2_controller``软件包中提供了一个``diff_drive_controller``（差动驱动控制器）。``diff_drive_controller``接收在``cmd_vel``话题上发布的``geometry_msgs/Twist``消息，计算里程计信息，并在``odom``话题上发布``nav_msgs/Odometry``消息。``ros2_control``还提供了处理不同类型传感器的其他软件包。"


#: ../../setup_guides/odom/setup_odom.rst:58
msgid "For more information, see the `ros2_control documentation <https://ros-controls.github.io/control.ros.org/>`_ and the `Github repository of diff_drive_controller <https://github.com/ros-controls/ros2_controllers/tree/master/diff_drive_controller/>`_."
msgstr "要获取更多信息，请参阅 `ros2_control 文档 <https://ros-controls.github.io/control.ros.org/>`_ 和 `diff_drive_controller 的 Github 存储库 <https://github.com/ros-controls/ros2_controllers/tree/master/diff_drive_controller/>`_。"


#: ../../setup_guides/odom/setup_odom.rst:60
msgid "For other types of sensors such as IMU, VIO, etc, their respective ROS drivers should have documentation on how publish the odometry information. Keep in mind that Nav2 requires the ``nav_msgs/Odometry`` message and ``odom`` => ``base_link`` transforms to be published and this should be your goal when setting up your odometry system."
msgstr "对于其他类型的传感器（如IMU、VIO等），它们各自的ROS驱动程序应该有关于如何发布里程计信息的文档。请记住，Nav2要求发布``nav_msgs/Odometry``消息和``odom`` => ``base_link``转换，这应该是您在设置里程计系统时的目标。"


#: ../../setup_guides/odom/setup_odom.rst:63
msgid "Simulating an Odometry System using Gazebo"
msgstr "使用 Gazebo 模拟 Odometry 系统"


#: ../../setup_guides/odom/setup_odom.rst:65
msgid "In this section, we will be using Gazebo to simulate the odometry system of ``sam_bot``, the robot that we built in the previous section of this tutorial series. You may go through that guide first or grab the `complete source here  <https://github.com/ros-planning/navigation2_tutorials/tree/master/sam_bot_description/>`_."
msgstr "在本节中，我们将使用Gazebo模拟``sam_bot``的里程计系统，这是我们在本教程系列的上一节中构建的机器人。您可以先阅读那个指南或在 `此处获取完整源代码 <https://github.com/ros-planning/navigation2_tutorials/tree/master/sam_bot_description/>`_。"


#: ../../setup_guides/odom/setup_odom.rst:67
msgid "If you are working on your own physical robot and have already set up your odometry sensors, you may opt to skip this section and head onto the next one where we fuse IMU and odometry messages to provide a smooth ``odom`` => ``base_link`` transformation."
msgstr "如果您正在使用自己的物理机器人并已经设置好了里程计传感器，您可以选择跳过本节，直接进入下一节，在那里我们将融合 IMU 和里程计消息以提供平滑的 ``odom`` => ``base_link`` 转换。"


#: ../../setup_guides/odom/setup_odom.rst:69
msgid "As an overview for this section, we will first setup Gazebo and the necessary packages required to make it work with ROS 2. Next, we will be adding Gazebo plugins, which simulate an IMU sensor and a differential drive odometry system, in order to publish ``sensor_msgs/Imu`` and ``nav_msgs/Odometry`` messages respectively. Lastly, we will spawn ``sam_bot`` in a Gazebo environment and verify the published ``sensor_msgs/Imu`` and ``nav_msgs/Odometry`` messages over ROS 2."
msgstr "作为本节的概述，我们将首先设置Gazebo和必要的软件包，使其与ROS 2配合工作。接下来，我们将添加Gazebo插件，分别模拟IMU传感器和差动驱动里程计系统，以发布``sensor_msgs/Imu``和``nav_msgs/Odometry``消息。最后，我们将在Gazebo环境中生成``sam_bot``并通过ROS 2验证发布的``sensor_msgs/Imu``和``nav_msgs/Odometry``消息。"


#: ../../setup_guides/odom/setup_odom.rst:72
msgid "Setup and Prerequisites"
msgstr "设置和先决条件"


#: ../../setup_guides/odom/setup_odom.rst:74
msgid "`Gazebo <http://gazebosim.org/>`_ is a 3D simulator that allows us to observe how our virtual robot will function in a simulated environment. To start using Gazebo with ROS 2, follow the installation instructions in the `Gazebo Installation Documentation <http://gazebosim.org/tutorials?cat=install>`_."
msgstr "``Gazebo <http://gazebosim.org/>``_是一个3D模拟器，可以让我们观察虚拟机器人在模拟环境中的运行情况。要开始使用Gazebo和ROS 2，请按照`Gazebo安装文档 <http://ga"


#: ../../setup_guides/odom/setup_odom.rst:76
msgid "We also need to install the ``gazebo_ros_pkgs`` package to simulate odometry and control the robot with ROS 2 in Gazebo:"
msgstr "我们还需要安装 ``gazebo_ros_pkgs`` 包，以便在 Gazebo 中模拟里程计并使用 ROS 2 控制机器人："


#: ../../setup_guides/odom/setup_odom.rst:82
msgid "You can test if you have successfully set up your ROS 2 and Gazebo environments by following the instructions `given here <http://gazebosim.org/tutorials?tut=ros2_installing&cat=connect_ros#TestingGazeboandROS2integration>`_."
msgstr "您可以按照此处的说明 `（链接：<http://gazebosim.org/tutorials?tut=ros2_installing&cat=connect_ros#TestingGazeboandROS2integration>`_）测试您是否成功设置了ROS 2和Gazebo环境。"


#: ../../setup_guides/odom/setup_odom.rst:84
msgid "Note that we described ``sam_bot`` using URDF. However, Gazebo uses `Simulation Description Format (SDF) <http://sdformat.org/>`_ to describe a robot in its simulated environment. Fortunately, Gazebo automatically translates compatible URDF files into SDF. The main requirement for the URDF to be compatible with Gazebo is to have an ``<inertia>`` element within each ``<link>`` element. This requirement is already satisfied in the URDF file of ``sam_bot``, so it can already be used in Gazebo."
msgstr "请注意，我们使用 URDF 描述了 ``sam_bot``。然而，Gazebo 使用 `Simulation Description Format (SDF) <http://sdformat.org/>`_ 来描述机器人在模拟环境中的情况。幸运的是，Gazebo 可以自动将兼容的 URDF 文件转换为 SDF。使 URDF 与 Gazebo 兼容的主要要求是在每个 ``<link>`` 元素中具有一个 ``<inertia>`` 元素。``sam_bot`` 的 URDF 文件已经满足了这个要求，因此它可以直接在 Gazebo 中使用。"


#: ../../setup_guides/odom/setup_odom.rst:87
msgid "For more information on how to use URDF in Gazebo, see `Tutorial: Using a URDF in Gazebo <http://gazebosim.org/tutorials/?tut=ros_urdf>`_."
msgstr "有关如何在Gazebo中使用URDF的更多信息，请参阅 `（链接：<http://gazebosim.org/tutorials/?tut=ros_urdf>`_）教程。"


#: ../../setup_guides/odom/setup_odom.rst:90 ../../setup_guides/sensors/setup_sensors.rst:66
msgid "Adding Gazebo Plugins to a URDF"
msgstr "向 URDF 添加 Gazebo 插件"


#: ../../setup_guides/odom/setup_odom.rst:92
msgid "We will now add the IMU sensor and the differential drive plugins of Gazebo to our URDF. For an overview of the different plugins available in Gazebo, have a look at `Tutorial: Using Gazebo plugins with ROS <http://gazebosim.org/tutorials?tut=ros_gzplugins>`_."
msgstr "现在，我们将向URDF添加Gazebo的IMU传感器和差动驱动插件。要了解Gazebo中可用的不同插件的概述，请查看 `（链接：<http://gazebosim.org/tutorials?tut=ros_gzplugins>`_）教程。"


#: ../../setup_guides/odom/setup_odom.rst:94
msgid "For our robot, we will be using the `GazeboRosImuSensor <http://gazebosim.org/tutorials?tut=ros_gzplugins#IMUsensor(GazeboRosImuSensor)>`_ which is a SensorPlugin. A SensorPlugin must be attached to a link, thus we will create an ``imu_link`` to which the IMU sensor will be attached. This link will be referenced under the ``<gazebo>`` element. Next, we will set ``/demo/imu`` as the topic to which the IMU will be publishing its information, and we will comply with `REP145 <https://www.ros.org/reps/rep-0145.html>`_ by setting ``initalOrientationAsReference`` to ``false``. We will also add some noise to the sensor configuration using Gazebo's `sensor noise model <http://gazebosim.org/tutorials?tut=sensor_noise>`_."
msgstr "对于我们的机器人，我们将使用 `GazeboRosImuSensor <http://gazebosim.org/tutorials?tut=ros_gzplugins#IMUsensor(GazeboRosImuSensor)>`_，它是一个SensorPlugin。SensorPlugin必须附加到一个链接上，因此我们将创建一个``imu_link``，将IMU传感器附加到该链接上。这个链接将在``<gazebo>``元素下引用。接下来，我们将设置``/demo/imu``作为IMU将发布其信息的主题，并且我们将根据 `REP145 <https://www.ros.org/reps/rep-0145.html>`_ 设置``initalOrientationAsReference``为``false``。我们还将使用Gazebo的 `sensor noise model <http://gazebosim.org/tutorials?tut=sensor_noise>`_ 为传感器配置添加一些噪声。"


#: ../../setup_guides/odom/setup_odom.rst:96
msgid "Now, we will set up our IMU sensor plugin according to the description above by adding the following lines before the ``</robot>`` line in our URDF:"
msgstr "现在，我们将按照上述说明设置IMU传感器插件，将以下行添加到URDF中的``</robot>``行之前："


#: ../../setup_guides/odom/setup_odom.rst:192
msgid "Now, let us add the differential drive ModelPlugin. We will configure the plugin such that ``nav_msgs/Odometry`` messages are published on the ``/demo/odom`` topic. The joints of the left and right wheels will be set to the wheel joints of ``sam_bot``. The wheel separation and wheel diameter are set according to the values of the defined values of ``wheel_ygap`` and ``wheel_radius`` respectively."
msgstr "现在，让我们添加差分驱动的ModelPlugin。我们将配置插件，以便在``/demo/odom``主题上发布``nav_msgs/Odometry``消息。左右轮的关节将设置为``sam_bot``的轮关节。轮子之间的距离和轮子的直径分别根据``wheel_ygap``和``wheel_radius``的定义值设置。"


#: ../../setup_guides/odom/setup_odom.rst:194
msgid "To include this plugin in our URDF, add the following lines after the ``</gazebo>`` tag of the IMU plugin:"
msgstr "要在URDF中包含此插件，请在IMU插件的``</gazebo>``标签后添加以下行："


#: ../../setup_guides/odom/setup_odom.rst:229 ../../setup_guides/odom/setup_odom.rst:438 ../../setup_guides/sensors/setup_sensors.rst:219
msgid "Launch and Build Files"
msgstr "启动和构建文件"


#: ../../setup_guides/odom/setup_odom.rst:231
msgid "We will now edit our launch file, `launch/display.launch.py <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/launch/display.launch.py>`_, to spawn ``sam_bot`` in Gazebo. Since we will be simulating our robot, we can remove the GUI for the joint state publisher by deleting the following lines inside the ``generate_launch_description()``:"
msgstr "现在，我们将编辑我们的启动文件 `（链接：<https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/launch/display.launch.py>`_）以在Gazebo中生成``sam_bot``。由于我们将模拟我们的机器人，可以通过删除``generate_launch_description()``内部的以下行来移除关节状态发布器的GUI："


#: ../../setup_guides/odom/setup_odom.rst:242
msgid "Remove the following `gui` param:"
msgstr "移除以下的`gui`参数："


#: ../../setup_guides/odom/setup_odom.rst:249
msgid "Remove the condition from the `joint_state_publisher_node`:"
msgstr "从`joint_state_publisher_node`中删除条件："


#: ../../setup_guides/odom/setup_odom.rst:260
msgid "Next, open `package.xml <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/package.xml>`_ and delete the line:"
msgstr "接下来，打开 `package.xml <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/package.xml>`_ 并删除这行："


#: ../../setup_guides/odom/setup_odom.rst:266
msgid "To launch Gazebo, add the following before the ``joint_state_publisher_node,`` line"
msgstr "要启动 Gazebo，请在 ``joint_state_publisher_node`` 行之前添加以下内容"


#: ../../setup_guides/odom/setup_odom.rst:272
msgid "We will now add a node that spawns ``sam_bot`` in Gazebo. Open `launch/display.launch.py <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/launch/display.launch.py>`_ again and paste the following lines before the ``return launch.LaunchDescription([`` line."
msgstr "现在，我们将在Gazebo中添加一个节点，用于生成``sam_bot``。再次打开 `launch/display.launch.py <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/launch/display.launch.py>`_ ，在``return launch.LaunchDescription([``行之前粘贴以下代码行。"


#: ../../setup_guides/odom/setup_odom.rst:283
msgid "Then add the line ``spawn_entity,`` before the ``rviz_node`` line, as shown below."
msgstr "然后在 ``rviz_node`` 行之前添加一行 ``spawn_entity``，如下所示"


#: ../../setup_guides/odom/setup_odom.rst:296
msgid "Let us run our package to check if the ``/demo/imu`` and ``/demo/odom`` topics are active in the system."
msgstr "让我们运行我们的包，检查系统中是否存在活动的``/demo/imu``和``/demo/odom``主题。"


#: ../../setup_guides/odom/setup_odom.rst:298
msgid "Navigate to the root of the project and execute the following lines:"
msgstr "导航到项目的根目录并执行以下命令"


#: ../../setup_guides/odom/setup_odom.rst:306
msgid "Gazebo should launch and you should see a 3D model of ``sam_bot``:"
msgstr "Gazebo 应该会启动，您应该会看到一个名为 ``sam_bot`` 的三维模型:"


#: ../../setup_guides/odom/setup_odom.rst:312
msgid "To see the active topics in the system, open a new terminal and execute:"
msgstr "要查看系统中的活动话题，请打开一个新的终端并执行"


#: ../../setup_guides/odom/setup_odom.rst:318
msgid "You should see ``/demo/imu`` and ``/demo/odom`` in the list of topics."
msgstr "您应该在话题列表中看到 ``/demo/imu`` 和 ``/demo/odom``。"


#: ../../setup_guides/odom/setup_odom.rst:320
msgid "To see more information about the topics, execute:"
msgstr "要查看有关话题的更多信息，请执行"


#: ../../setup_guides/odom/setup_odom.rst:327
msgid "You should see an output similar to below:"
msgstr "您应该会看到类似下面的输出:"


#: ../../setup_guides/odom/setup_odom.rst:341
msgid "Observe that the ``/demo/imu`` topic publishes ``sensor_msgs/Imu`` type messages while the ``/demo/odom`` topic publishes ``nav_msgs/Odometry`` type messages. The information being published on these topics come from the gazebo simulation of the IMU sensor and the differential drive respectively. Also note that both topics currently have no subscribers. In the next section, we will create a ``robot_localization`` node that will subscribe to these two topics. It will then use the messages published on both topics to provide a fused, locally accurate and smooth odometry information for Nav2."
msgstr "注意，``/demo/imu`` 话题发布的是 ``sensor_msgs/Imu`` 类型的消息，而 ``/demo/odom`` 话题发布的是 ``nav_msgs/Odometry`` 类型的消息。这些话题上发布的信息分别来自 IMU 传感器和差分驱动的 Gazebo 仿真。还请注意，这两个话题目前都没有订阅者。在下一节中，我们将创建一个 ``robot_localization`` 节点来订阅这两个话题。然后，它将使用这两个话题上发布的消息为 Nav2 提供融合的、本地准确且平滑的里程计信息。"


#: ../../setup_guides/odom/setup_odom.rst:344
msgid "Robot Localization Demo"
msgstr "机器人定位演示"


#: ../../setup_guides/odom/setup_odom.rst:346
msgid "The ``robot_localization`` package is used to provide a fused and locally accurate smooth odometry information from the data provided by ``N`` odometry sensor inputs. These information can be provided to the package through ``nav_msgs/Odometry``, ``sensor_msgs/Imu``, ``geometry_msgs/PoseWithCovarianceStamped``, and ``geometry_msgs/TwistWithCovarianceStamped`` messages."
msgstr "``robot_localization`` 包用于从 ``N`` 个里程计传感器输入的数据中提供融合和本地准确的平滑里程计信息。这些信息可以通过 ``nav_msgs/Odometry``、``sensor_msgs/Imu``、``geometry_msgs/PoseWithCovarianceStamped`` 和 ``geometry_msgs/TwistWithCovarianceStamped`` 消息提供给该包。"


#: ../../setup_guides/odom/setup_odom.rst:348
msgid "A usual robot setup consists of at least the wheel encoders and IMU as its odometry sensor sources. When multiple sources are provided to ``robot_localization``, it is able to fuse the odometry information given by the sensors through the use of state estimation nodes. These nodes make use of either an Extended Kalman filter (``ekf_node``) or an Unscented Kalman Filter (``ukf_node``) to implement this fusion. In addition, the package also implements a ``navsat_transform_node`` which transforms geographic coordinates into the robot’s world frame when working with GPS."
msgstr "通常的机器人设置至少包括轮编码器和惯性测量单元 (IMU) 作为其里程计传感器来源。当``robot_localization``接收到多个传感器提供的里程计信息时，它可以通过使用状态估计节点来融合传感器提供的里程计信息。这些节点使用扩展卡尔曼滤波器(``ekf_node``)或无迹卡尔曼滤波器(``ukf_node``)来实现融合。此外，该软件包还实现了一个``navsat_transform_node``，在使用GPS时将地理坐标转换为机器人的世界坐标系。"


#: ../../setup_guides/odom/setup_odom.rst:350
msgid "Fused sensor data is published by the ``robot_localization`` package through the ``odometry/filtered`` and the ``accel/filtered`` topics, if enabled in its configuration. In addition, it can also publish the ``odom`` => ``base_link`` transform on the ``/tf`` topic."
msgstr "如果在配置中启用了``robot_localization``软件包，它将通过``odometry/filtered``和``accel/filtered``主题发布融合的传感器数据。此外，它还可以在``/tf``主题上发布``odom`` => ``base_link``的变换。"


#: ../../setup_guides/odom/setup_odom.rst:353
msgid "More details on ``robot_localization`` can be found in the official `Robot Localization Documentation <http://docs.ros.org/en/noetic/api/robot_localization/html/index.html>`_."
msgstr "有关``robot_localization``的更多详细信息，请参阅官方的 `Robot Localization 文档 <http://docs.ros.org/en/noetic/api/robot_localization/html/index.html>`_。"


#: ../../setup_guides/odom/setup_odom.rst:355
msgid "If your robot is only able to provide one odometry source, the use of ``robot_localization`` would have minimal effects aside from smoothing. In this case, an alternative approach is to publish transforms through a tf2 broadcaster in your single source of odometry node. Nevertheless, you can still opt to use ``robot_localization`` to publish the transforms and some smoothing properties may still be observed in the output."
msgstr "如果您的机器人只能提供一个里程计源，使用``robot_localization``除了平滑效果外，几乎没有其他影响。在这种情况下，另一种方法是通过单个里程计源节点使用tf2广播器发布变换。然而，您仍然可以选择使用``robot_localization``来发布变换，输出结果可能仍然具有一定的平滑效果。"


#: ../../setup_guides/odom/setup_odom.rst:358
msgid "For more information on how to write a tf2 broadcaster, you can check Writing a tf2 broadcaster `(C++)  <https://docs.ros.org/en/rolling/Tutorials/Tf2/Writing-A-Tf2-Broadcaster-Cpp.html>`_  `(Python)  <https://docs.ros.org/en/rolling/Tutorials/Tf2/Writing-A-Tf2-Broadcaster-Py.html>`_."
msgstr "有关如何编写 tf2 广播器的更多信息，请查阅如下链接: Writing a tf2 broadcaster `(C++)  <https://docs.ros.org/en/rolling/Tutorials/Tf2/Writing-A-Tf2-Broadcaster-Cpp.html>`_  `(Python)  <https://docs.ros.org/en/rolling/Tutorials/Tf2/Writing-A-Tf2-Broadcaster-Py.html>`_。"


#: ../../setup_guides/odom/setup_odom.rst:360
msgid "For the rest of this section, we will show how to use ``robot_localization`` to fuse the sensors of ``sam_bot``. It will use the ``sensor_msgs/Imu`` messages published on ``/demo/Imu`` and the ``nav_msgs/Odometry`` message published on ``/demo/odom`` and then it will publish data on ``odometry/filtered``,  ``accel/filtered``, and ``/tf`` topics."
msgstr "在本节的其余部分中，我们将展示如何使用``robot_localization``来融合``sam_bot``的传感器。它将使用发布在``/demo/Imu``上的``sensor_msgs/Imu``消息和发布在``/demo/odom``上的``nav_msgs/Odometry``消息，然后在``odometry/filtered``、``accel/filtered``和``/tf``主题上发布数据。"


#: ../../setup_guides/odom/setup_odom.rst:363
msgid "Configuring Robot Localization"
msgstr "配置机器人定位"


#: ../../setup_guides/odom/setup_odom.rst:365
msgid "Let us now configure the ``robot_localization`` package to use an Extended Kalman Filter (``ekf_node``) to fuse odometry information and publish the ``odom`` => ``base_link`` transform."
msgstr "现在让我们配置``robot_localization``软件包，使用扩展卡尔曼滤波器（``ekf_node``）来融合里程计信息，并发布``odom`` => ``base_link``的变换。"


#: ../../setup_guides/odom/setup_odom.rst:367
msgid "First, install the ``robot_localization`` package using your machines package manager or by executing the following command:"
msgstr "首先，使用您的机器的软件包管理器安装``robot_localization``软件包，或者执行以下命令进行安装："


#: ../../setup_guides/odom/setup_odom.rst:373
msgid "Next, we specify the parameters of the ``ekf_node`` using a YAML file. Create a directory named ``config`` at the root of your project and create a file named ``ekf.yaml``. Copy the following lines of code into your ``ekf.yaml`` file."
msgstr "接下来，我们使用一个YAML文件来指定``ekf_node``的参数。在您的项目根目录下创建一个名为``config``的目录，并创建一个名为``ekf.yaml``的文件。将以下代码复制到``ekf.yaml``文件中。"


#: ../../setup_guides/odom/setup_odom.rst:425
msgid "In this configuration, we defined the parameter values of ``frequency``, ``two_d_mode``, ``publish_acceleration``, ``publish_tf``, ``map_frame``, ``odom_frame``, ``base_link_frame``, and ``world_frame``. For more information on the other parameters you can modify, see `Parameters of state estimation nodes <http://docs.ros.org/en/melodic/api/robot_localization/html/state_estimation_nodes.html#parameters>`_, and a sample ``efk.yaml`` can be found `here <https://github.com/cra-ros-pkg/robot_localization/blob/foxy-devel/params/ekf.yaml>`_."
msgstr "在这个配置中，我们定义了``frequency``、``two_d_mode``、``publish_acceleration``、``publish_tf``、``map_frame``、``odom_frame``、``base_link_frame``和``world_frame``的参数值。有关您可以修改的其他参数的详细信息，请参阅`状态估计节点的参数 <http://docs.ros.org/en/melodic/api/robot_localization/html/state_estimation_nodes.html#parameters>`_，以及示例``efk.yaml``可以在`这里找到 <https://github.com/cra-ros-pkg/robot_localization/blob/foxy-devel/params/ekf.yaml>`_。"


#: ../../setup_guides/odom/setup_odom.rst:427
msgid "To add a sensor input to the ``ekf_filter_node``, add the next number in the sequence to its base name (odom, imu, pose, twist). In our case, we have one ``nav_msgs/Odometry`` and one ``sensor_msgs/Imu`` as inputs to the filter, thus we use ``odom0`` and ``imu0``. We set the value of ``odom0`` to ``demo/odom``, which is the topic that publishes the ``nav_msgs/Odometry``. Similarly, we set the value of ``imu0`` to the topic that publishes ``sensor_msgs/Imu``, which is ``demo/imu``."
msgstr "要将传感器输入添加到``ekf_filter_node``，请将序列中的下一个数字添加到其基本名称（odom、imu、pose、twist）。在我们的例子中，我们有一个``nav_msgs/Odometry``和一个``sensor_msgs/Imu``作为滤波器的输入，因此我们使用``odom0``和``imu0``。我们将``odom0``的值设置为``demo/odom``，它是发布``nav_msgs/Odometry``的主题。类似地，我们将``imu0``的值设置为发布``sensor_msgs/Imu``的主题，即``demo/imu``。"


#: ../../setup_guides/odom/setup_odom.rst:429
msgid "You can specify which values from a sensor are to be used by the filter using the ``_config`` parameter. The order of the values of this parameter is x, y, z, roll, pitch, yaw, vx, vy, vz, vroll, vpitch, vyaw, ax, ay, az. In our example, we set everything in ``odom0_config`` to ``false`` except the 1st, 2nd, 3rd, and 12th entries, which means the filter will only use the x, y, z, and the vyaw values of ``odom0``."
msgstr "您可以使用``_config``参数指定要由滤波器使用的传感器的值。该参数的值的顺序是x、y、z、roll、pitch、yaw、vx、vy、vz、vroll、vpitch、vyaw、ax、ay、az。在我们的例子中，我们将``odom0_config``中除了第1、2、3和12个条目以外的所有条目都设置为``false``，这意味着滤波器只会使用``odom0``的x、y、z和vyaw的值。"


#: ../../setup_guides/odom/setup_odom.rst:431
msgid "In the ``imu0_config`` matrix, you'll notice that only roll, pitch, and yaw are used. Typical mobile robot-grade IMUs will also provide angular velocities and linear accelerations. For ``robot_localization`` to work properly, you should not fuse in multiple fields that are derivative of each other. Since angular velocity is fused internally to the IMU to provide the roll, pitch and yaw estimates, we should not fuse in the angular velocities used to derive that information. We also do not fuse in angular velocity due to the noisy characteristics it has when not using exceptionally high quality (and expensive) IMUs."
msgstr "在``imu0_config``矩阵中，您会注意到只使用了滚转、俯仰和偏航。典型的移动机器人级别的IMU还会提供角速度和线性加速度。为了使``robot_localization``正常工作，您不应该融合多个彼此有导数关系的字段。由于角速度在IMU内部被融合以提供滚转、俯仰和偏航的估计，我们不应该融合用"


#: ../../setup_guides/odom/setup_odom.rst:434
msgid "For more advise on configuration of input data to ``robot_localization``, see `Preparing Your Data for Use with robot_localization <http://docs.ros.org/en/melodic/api/robot_localization/html/preparing_sensor_data.html#odometry>`_, and `Configuring robot_localization <http://docs.ros.org/en/melodic/api/robot_localization/html/configuring_robot_localization.html>`_."
msgstr "有关将输入数据配置为``robot_localization``的更多建议，请参阅`准备用于robot_localization的数据 <http://docs.ros.org/en/melodic/api/robot_localization/html/preparing_sensor_data.html#odometry>`_，以及`配置robot_localization <http://docs.ros.org/en/melodic/api/robot_localization/html/configuring_robot_localization.html>`_。"


#: ../../setup_guides/odom/setup_odom.rst:440
msgid "Now, let us add the ``ekf_node`` into the launch file. Open ``launch/display.launch.py`` and paste the following lines before the ``return launch.LaunchDescription([`` line."
msgstr "现在，让我们将``ekf_node``添加到启动文件中。打开``launch/display.launch.py``，在``return launch.LaunchDescription([``行之前粘贴以下内容。"


#: ../../setup_guides/odom/setup_odom.rst:452
msgid "Next, add the following launch arguments within the ``return launch.LaunchDescription([`` block."
msgstr "接下来，在``return launch.LaunchDescription([``块中添加以下启动参数。"


#: ../../setup_guides/odom/setup_odom.rst:459
msgid "Lastly, add ``robot_localization_node,`` above the ``rviz_node`` line to launch the robot localization node."
msgstr "最后，在``rviz_node``行上方添加``robot_localization_node,``以启动机器人定位节点。"


#: ../../setup_guides/odom/setup_odom.rst:469
msgid "Next, we need to add the ``robot_localization`` dependency to our package definition. Open ``package.xml`` and add the following line below the last ``<exec_depend>`` tag."
msgstr "接下来，我们需要将``robot_localization``依赖项添加到我们的软件包定义中。打开``package.xml``，并在最后一个``<exec_depend>``标签下面添加以下行。"


#: ../../setup_guides/odom/setup_odom.rst:475
msgid "Lastly, open ``CMakeLists.txt`` and append the ``config`` directory inside the ``install(DIRECTORY...)``, as shown in the snippet below."
msgstr "最后，打开``CMakeLists.txt``，并将``config``目录追加到``install(DIRECTORY...)``中，如下面的代码片段所示。"


#: ../../setup_guides/odom/setup_odom.rst:488
msgid "Let us now build and run our package. Navigate to the root of the project and execute the following lines:"
msgstr "现在让我们构建并运行我们的软件包。导航到项目的根目录并执行以下命令："


#: ../../setup_guides/odom/setup_odom.rst:496
msgid "Gazebo and RVIZ should launch. In the RVIZ window, you should see the model and TF frames of ``sam_bot``:"
msgstr "Gazebo和RVIZ应该会启动。在RVIZ窗口中，您应该可以看到``sam_bot``的模型和TF坐标系："


#: ../../setup_guides/odom/setup_odom.rst:502
msgid "Next, let us verify that the ``odometry/filtered``,  ``accel/filtered``, and ``/tf`` topics are active in the system. Open a new terminal and execute:"
msgstr "接下来，让我们验证系统中是否激活了 ``odometry/filtered``、``accel/filtered`` 和 ``/tf`` 主题。打开一个新的终端并执行以下命令："


#: ../../setup_guides/odom/setup_odom.rst:508
msgid "You should see ``odometry/filtered``, ``accel/filtered``, and ``/tf`` in the list of the topics."
msgstr "您应该在话题列表中看到``odometry/filtered``，``accel/filtered``和``/tf``。"


#: ../../setup_guides/odom/setup_odom.rst:510
msgid "You can also check the subscriber count of these topics again by executing:"
msgstr "您还可以通过执行以下命令再次检查这些主题的订阅者计数："


#: ../../setup_guides/odom/setup_odom.rst:517
msgid "You should see that ``/demo/imu`` and ``/demo/odom`` now both have 1 subscriber each."
msgstr "您应该看到``/demo/imu``和``/demo/odom``现在各自都有1个订阅者。"


#: ../../setup_guides/odom/setup_odom.rst:519
msgid "To verify that the ``ekf_filter_node`` are the subscribers of these topics, execute:"
msgstr "要验证 ``ekf_filter_node`` 是否是这些主题的订阅者，请执行以下命令："


#: ../../setup_guides/odom/setup_odom.rst:525
msgid "You should see an output as shown below."
msgstr "您应该看到如下所示的输出。"


#: ../../setup_guides/odom/setup_odom.rst:545
msgid "From the output above, we can see that the ``ekf_filter_node`` is subscribed to ``/demo/imu`` and ``/demo/odom``. We can also see that the ``ekf_filter_node`` publishes on the ``odometry/filtered``, ``accel/filtered``, and ``/tf`` topics."
msgstr "从上面的输出中，我们可以看到 ``ekf_filter_node`` 订阅了 ``/demo/imu`` 和 ``/demo/odom``。我们还可以看到 ``ekf_filter_node`` 在 ``odometry/filtered``、``accel/filtered`` 和 ``/tf`` 主题上发布。"


#: ../../setup_guides/odom/setup_odom.rst:547
msgid "You may also verify that ``robot_localization`` is publishing the ``odom`` => ``base_link`` transform by using the tf2_echo utility. Run the folllowing command in a separate command line terminal:"
msgstr "您还可以通过使用tf2_echo工具验证``robot_localization``是否发布了``odom`` => ``base_link``的变换。在单独的命令行终端中运行以下命令："


#: ../../setup_guides/odom/setup_odom.rst:553
msgid "You should see a continuous output similar to what is shown below."
msgstr "您应该看到类似下面所示的连续输出。"


#: ../../setup_guides/odom/setup_odom.rst:567
msgid "In this guide, we have discussed the messages and transforms that are expected by Nav2 from the odometry system. We have seen how to set up an odometry system and how to verify the published messages. We also have discussed how multiple odometry sensors can be used to provide a filtered and smoothed odometry using ``robot_localization``. We have also checked if the ``odom`` => ``base_link`` transform is being published correctly by ``robot_localization``."
msgstr "在本指南中，我们讨论了Nav2从里程计系统所期望的消息和变换。我们已经了解了如何设置里程计系统以及如何验证发布的消息。我们还讨论了如何使用``robot_localization``使用多个里程计传感器提供滤波和平滑的里程计。我们还检查了``robot_localization``是否正确发布了``odom`` => ``base_link``的变换。"


#: ../../setup_guides/sensors/setup_sensors.rst:4
msgid "Setting Up Sensors"
msgstr "设置传感器"


#: ../../setup_guides/sensors/setup_sensors.rst:6
msgid "In this guide, we will discuss the importance of the sensors in navigating a robot safely and how to set up the sensors with Nav2. In the first half of this tutorial, we will take a brief look at commonly used sensors and common sensor messages in Nav2. Next, we will add a basic sensor setup on our previously built simulated robot, ``sam_bot``. Lastly, we will then verify the simulated sensor messages of ``sam_bot`` by visualizing them in RViz."
msgstr "在本指南中，我们将讨论传感器在安全导航机器人中的重要性以及如何在Nav2中设置传感器。在本教程的前半部分，我们将简要介绍Nav2中常用的传感器和常见的传感器消息。接下来，我们将在先前构建的仿真机器人``sam_bot``上添加基本的传感器设置。最后，我们将通过在RViz中可视化它们来验证``sam_bot``的模拟传感器消息。"


#: ../../setup_guides/sensors/setup_sensors.rst:8
msgid "Once sensors have been set up on a robot, their readings can be used in mapping, localization, and perception tasks. In the second half of this guide, we will first discuss how mapping and localization use the sensor data. Then, we will also take a look at one of Nav2's packages, ``nav2_costmap_2d``, which generates costmaps that will eventually be used in Nav2 path planning. We will set up basic configuration parameters for this package so it properly takes in sensor information from ``sam_bot``. Lastly, we visualize a generated costmaps in RViz to verify its received data."
msgstr "一旦在机器人上设置了传感器，它们的读数可以用于地图创建、定位和感知任务。在本指南的后半部分，我们首先讨论了地图创建和定位如何使用传感器数据。然后，我们还将介绍 Nav2 的一个软件包 ``nav2_costmap_2d``，该软件包生成的代价图最终将用于 Nav2 的路径规划。我们将设置该软件包的基本配置参数，以便它能正确地接收来自 ``sam_bot`` 的传感器信息。最后，我们在 RViz 中可视化生成的代价图，以验证其接收到的数据。"


#: ../../setup_guides/sensors/setup_sensors.rst:11
msgid "Sensor Introduction"
msgstr "传感器介绍"


#: ../../setup_guides/sensors/setup_sensors.rst:12
msgid "Mobile robots are equipped with a multitude of sensors that allow them to see and perceive their environment. These sensors obtain information which can be used to build and maintain the map of the environment, to localize the robot on the map, and to see the obstacles in the environment. These tasks are essential to be able to safely and efficiently navigate a robot through a dynamic environment."
msgstr "移动机器人配备了许多传感器，使其能够观察和感知环境。这些传感器获取的信息可以用于构建和维护环境地图，将机器人定位在地图上，并查看环境中的障碍物。这些任务对于能够在动态环境中安全、高效地导航机器人非常重要。"


#: ../../setup_guides/sensors/setup_sensors.rst:14
msgid "Examples of commonly used sensors are lidar, radar, RGB camera, depth camera, IMU, and GPS. To standardize the message formats of these sensors and allow for easier interoperation between vendors, ROS provides the ``sensor_msgs`` package that defines the common sensor interfaces. This also allows users to use any sensor vendor as long as it follows the standard format in ``sensor_msgs``. In the next subsection, we introduce some of commonly used messages in navigation, namely the ``sensor_msgs/LaserScan``, ``sensor_msgs/PointCloud2``, ``sensor_msgs/Range``, and ``sensor_msgs/Image``."
msgstr "常用传感器的示例包括激光雷达、雷达、RGB相机、深度相机、IMU和GPS。为了标准化这些传感器的消息格式并方便不同厂商之间的互操作，ROS提供了``sensor_msgs``包，定义了常用的传感器接口。这也使用户可以使用任何遵循``sensor_msgs``标准格式的传感器供应商。在下一小节中，我们介绍了导航中常用的一些消息，即``sensor_msgs/LaserScan``、``sensor_msgs/PointCloud2``、``sensor_msgs/Range``和``sensor_msgs/Image``。"


#: ../../setup_guides/sensors/setup_sensors.rst:16
msgid "Aside from the ``sensor_msgs`` package, there are also the ``radar_msgs`` and ``vision_msgs`` standard interfaces you should be aware of.  The ``radar_msgs`` defines the messages for radar-specific sensors while the ``vision_msgs`` package defines the messages used in computer vision such as object detection, segmentation, and other machine learning models. Messages supported by this package are ``vision_msgs/Classification2D``, ``vision_msgs/Classification3D``, ``vision_msgs/Detection2D``, and ``vision_msgs/Detection3D``, to name a few."
msgstr "除了 ``sensor_msgs`` 软件包，还有一些标准接口需要您了解，例如 ``radar_msgs`` 和 ``vision_msgs``。``radar_msgs`` 定义了用于雷达特定传感器的消息，而 ``vision_msgs`` 软件包定义了计算机视觉中使用的消息，例如目标检测、分割和其他机器学习模型。该软件包支持的消息类型包括 ``vision_msgs/Classification2D``、``vision_msgs/Classification3D``、``vision_msgs/Detection2D`` 和 ``vision_msgs/Detection3D``，等等。"


#: ../../setup_guides/sensors/setup_sensors.rst:19
msgid "For more information, see the API documentation of `sensor_msgs <http://wiki.ros.org/sensor_msgs>`_, `radar_msgs <http://wiki.ros.org/radar_msgs>`_, and `vision_msgs <http://wiki.ros.org/vision_msgs>`_."
msgstr "有关更多信息，请参阅`sensor_msgs <http://wiki.ros.org/sensor_msgs>`_、`radar_msgs <http://wiki.ros.org/radar_msgs>`_和`vision_msgs <http://wiki.ros.org/vision_msgs>`_的API文档。"


#: ../../setup_guides/sensors/setup_sensors.rst:21
msgid "Your physical robot's sensors probably have ROS drivers written for them (e.g. a ROS node that connects to the sensors, populates data into messages, and publishes them for your robot to use) that follow the standard interface in the ``sensor_msgs`` package. The ``sensor_msgs`` package makes it easy for you to use many different sensors from different manufacturers. General software packages like Nav2 can then can read these standardized messages and perform tasks independent of the sensor hardware. On simulated robots such as ``sam_bot``, Gazebo has sensor plugins which also publish their information following the ``sensor_msgs`` package."
msgstr "您的物理机器人的传感器可能已经为它们编写了 ROS 驱动程序（例如连接到传感器的 ROS 节点，将数据填充到消息中，并将其发布供机器人使用），这些驱动程序遵循 ``sensor_msgs`` 软件包中的标准接口。``sensor_msgs`` 软件包使您能够轻松地使用来自不同制造商的许多不同传感器。然后，像 Nav2 这样的通用软件包可以读取这些标准化的消息，并执行与传感器硬件无关的任务。在诸如 ``sam_bot`` 的仿真机器人上，Gazebo 还具有传感器插件，这些插件也会按照 ``sensor_msgs`` 软件包发布它们的信息。"


#: ../../setup_guides/sensors/setup_sensors.rst:24
msgid "Common Sensor Messages"
msgstr "常用传感器消息"


#: ../../setup_guides/sensors/setup_sensors.rst:26
msgid "In this subsection, we discuss some of the common types of ``sensor_msgs`` you might encounter when setting up Nav2. We will provide a brief description for each sensor, an image of it being simulated in Gazebo and the corresponding visualization of the sensor readings in RViz."
msgstr "在本小节中，我们讨论了在设置 Nav2 时可能遇到的一些常见类型的 ``sensor_msgs``。我们将为每个传感器提供简要描述，在 Gazebo 中模拟其图像以及在 RViz 中对传感器"


#: ../../setup_guides/sensors/setup_sensors.rst:28
msgid "There are other types of ``sensor_msgs`` aside from the ones listed below.  The complete list of messages and their definitions can be found in the `sensor_msgs documentation <http://wiki.ros.org/sensor_msgs>`_."
msgstr "除了下面列出的类型之外，还有其他类型的``sensor_msgs``。完整的消息列表及其定义可以在 `sensor_msgs 文档 <http://wiki.ros.org/sensor_msgs>`_ 中找到。"


#: ../../setup_guides/sensors/setup_sensors.rst:31
msgid "sensor_msgs/LaserScan"
msgstr "sensor_msgs/LaserScan"


#: ../../setup_guides/sensors/setup_sensors.rst:33
msgid "This message represents a single scan from a planar laser range-finder. This message is used in ``slam_toolbox`` and ``nav2_amcl`` for localization and mapping, or in ``nav2_costmap_2d`` for perception."
msgstr "这个消息表示来自平面激光测距仪的单个扫描。这个消息在``slam_toolbox``和``nav2_amcl``中用于定位和建图，或在``nav2_costmap_2d``中用于感知。"


#: ../../setup_guides/sensors/setup_sensors.rst:38
msgid "sensor_msgs/PointCloud2"
msgstr "sensor_msgs/PointCloud2"


#: ../../setup_guides/sensors/setup_sensors.rst:40
msgid "This message holds a collection of 3D points, plus optional additional information about each point. This can be from a 3D lidar, a 2D lidar, a depth camera or more."
msgstr "这个消息包含一组3D点，以及每个点的可选附加信息。这可以来自3D激光雷达、2D激光雷达、深度相机或其他设备。"


#: ../../setup_guides/sensors/setup_sensors.rst:45
msgid "sensor_msgs/Range"
msgstr "sensor_msgs/Range"


#: ../../setup_guides/sensors/setup_sensors.rst:47
msgid "This is a single range reading from an active ranger that emits energy and reports one range reading that is valid along an arc at the distance measured. A sonar, IR sensor, or 1D range finder are examples of sensors that use this message."
msgstr "这是来自发射能量并报告沿测距的弧线上有效测距的主动测距仪的单个测距读数。声纳、红外传感器或1D测距仪是使用这个消息的传感器的示例。"


#: ../../setup_guides/sensors/setup_sensors.rst:52
msgid "sensor_msgs/Image"
msgstr "sensor_msgs/Image"


#: ../../setup_guides/sensors/setup_sensors.rst:54
msgid "This represents the sensor readings from RGB or depth camera, corresponding to RGB or range values."
msgstr "这表示来自RGB或深度相机的传感器读数，对应于RGB或深度值。"


#: ../../setup_guides/sensors/setup_sensors.rst:59
msgid "Simulating Sensors using Gazebo"
msgstr "使用Gazebo模拟传感器"


#: ../../setup_guides/sensors/setup_sensors.rst:60
msgid "To give you a better grasp of how to set up sensors on a simulated robot, we will build up on our previous tutorials and attach sensors to our simulated robot ``sam_bot``. Similar to the previous tutorial where we used Gazebo plugins to add odometry sensors to ``sam_bot``, we will be using the Gazebo plugins to simulate a lidar sensor and a depth camera on ``sam_bot``. If you are working with a real robot, most of these steps are still required for setting up your URDF frames and it will not hurt to also add in the gazebo plugins for later use."
msgstr "为了让您更好地了解如何在模拟机器人上设置传感器，我们将在之前的教程基础上为我们的模拟机器人``sam_bot``添加传感器。与之前的教程类似，在``sam_bot``上使用Gazebo插件添加里程计传感器，我们将使用Gazebo插件来模拟``sam_bot``上的激光雷达传感器和深度相机。如果您正在使用实际机器人，设置URDF框架时仍然需要执行大部分这些步骤，而且添加Gazebo插件以备将来使用也是有好处的。"


#: ../../setup_guides/sensors/setup_sensors.rst:62
msgid "To be able to follow the rest of this section, make sure that you have properly installed Gazebo. You can follow the instructions at the `Setup and Prerequisites <https://navigation.ros.org/setup_guides/odom/setup_odom.html#setup-and-prerequisites>`_ of the previous tutorial to setup Gazebo."
msgstr "为了能够跟随本节的其余部分，请确保您已正确安装了Gazebo。您可以按照先前教程中的“设置和先决条件 <https://navigation.ros.org/setup_guides/odom/setup_odom.html#setup-and-prerequisites>`_的说明来设置Gazebo。"


#: ../../setup_guides/sensors/setup_sensors.rst:68
msgid "Let us first add a lidar sensor to ``sam_bot``. Open the URDF file, `src/description/sam_bot_description.urdf <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/src/description/sam_bot_description.urdf>`_ and paste the following lines before the ``</robot>`` tag."
msgstr "首先让我们为``sam_bot``添加一个激光雷达传感器。打开URDF文件 `src/description/sam_bot_description.urdf <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/src/description/sam_bot_description.urdf>`_，并将以下行粘贴到``</robot>``标记之前。"


#: ../../setup_guides/sensors/setup_sensors.rst:136
msgid "In the code snippet above, we create a ``lidar_link`` which will be referenced by the ``gazebo_ros_ray_sensor`` plugin as the location to attach our sensor. We also set values to the simulated lidar's scan and range properties. Lastly, we set the ``/scan`` as the topic to which it will publish the ``sensor_msgs/LaserScan`` messages."
msgstr "在上面的代码片段中，我们创建了一个名为``lidar_link``的链接，它将被``gazebo_ros_ray_sensor``插件引用为附加传感器的位置。我们还设置了模拟激光雷达的扫描和范围属性的值。最后，我们将``/scan``设置为它将发布``sensor_msgs/LaserScan``消息的主题。"


#: ../../setup_guides/sensors/setup_sensors.rst:138
msgid "Next, let us add a depth camera to ``sam_bot``. Paste the following lines after the ``</gazebo>`` tag of the lidar sensor."
msgstr "接下来，让我们给``sam_bot``添加一个深度摄像头。在激光雷达传感器的``</gazebo>``标签之后，粘贴以下几行代码。"


#: ../../setup_guides/sensors/setup_sensors.rst:216
msgid "Similar to the lidar sensor, we create ``camera_link`` which will be referenced by the ``gazebo_ros_camera`` plugin as the sensor attachment location. We also create a ``camera_depth_frame`` that is attached to the ``camera_link`` and will be set as the ``<frame_name>`` of the depth camera plugin.  We also configure the plugin such that it will publish ``sensor_msgs/Image`` and ``sensor_msgs/PointCloud2`` messages to ``/depth_camera/image_raw`` and  ``/depth_camera/points`` topics respectively. Lastly, we also set up other basic configuration properties for our depth camera."
msgstr "Similar to the lidar sensor, we create ``camera_link`` which will be referenced by the ``gazebo_ros_camera`` plugin as the sensor attachment location. We also create a ``camera_depth_frame`` that is attached to the ``camera_link`` and will be set as the ``<frame_name>`` of the depth camera plugin.  We also configure the plugin such that it will publish ``sensor_msgs/Image`` and ``sensor_msgs/PointCloud2`` messages to ``/depth_camera/image_raw`` and  ``/depth_camera/points`` topics respectively. Lastly, we also set up other basic configuration properties for our depth camera."


#: ../../setup_guides/sensors/setup_sensors.rst:221
msgid "To verify that the sensors are set up properly and that they can see objects in our environemnt, let us launch ``sam_bot`` in a Gazebo world with objects. Let us create a Gazebo world with a single cube and a single sphere that are within the range of ``sam_bot``'s sensors so we can verify if it can see the objects correctly."
msgstr "为了验证传感器是否正确设置，并且能够在我们的环境中看到物体，让我们在带有物体的 Gazebo 世界中启动``sam_bot``。我们创建一个 Gazebo 世界，里面有一个立方体和一个球体，它们在``sam_bot``的传感器范围内，这样我们可以验证它是否能够正确地看到这些物体。"


#: ../../setup_guides/sensors/setup_sensors.rst:224
msgid "To create the world, create a directory named ``world`` at the root of your project and create a file named ``my_world.sdf`` inside the ``world`` folder . Then copy the contents of `world/my_world.sdf <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/world/my_world.sdf>`_ and paste them inside ``my_world.sdf``."
msgstr "To create the world, create a directory named ``world`` at the root of your project and create a file named ``my_world.sdf`` inside the ``world`` folder . Then copy the contents of `world/my_world.sdf <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/world/my_world.sdf>`_ and paste them inside ``my_world.sdf``."


#: ../../setup_guides/sensors/setup_sensors.rst:226
msgid "Now, let us edit our launch file, `launch/display.launch.py <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/launch/display.launch.py>`_, to launch Gazebo with the world we just created. First, add the path of ``my_world.sdf`` by adding the following lines inside the ``generate_launch_description()``:"
msgstr "现在，让我们编辑我们的启动文件 `launch/display.launch.py <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/launch/display.launch.py>`_，以启动包含我们刚刚创建的世界的 Gazebo。首先，在``generate_launch_description()``中添加``my_world.sdf``的路径，添加以下几行代码："


#: ../../setup_guides/sensors/setup_sensors.rst:232
msgid "Lastly, add the world path in the ``launch.actions.ExecuteProcess(cmd=['gazebo',...`` line, as shown below."
msgstr "Lastly, add the world path in the ``launch.actions.ExecuteProcess(cmd=['gazebo',...`` line, as shown below."


#: ../../setup_guides/sensors/setup_sensors.rst:238
msgid "We also have to add the ``world`` directory to our ``CMakeLists.txt`` file. Open `CmakeLists.txt <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/CMakeLists.txt>`_ and append the ``world`` directory inside the install(DIRECTORY...), as shown in the snippet below."
msgstr "我们还需要在``CMakeLists.txt``文件中添加``world``目录。打开 `CmakeLists.txt <https://github.com/ros-planning/navigation2_tutorials/blob/master/sam_bot_description/CMakeLists.txt>`_，并在 install(DIRECTORY...) 中添加``world``目录，如下面的代码片段所示。"


#: ../../setup_guides/sensors/setup_sensors.rst:250
msgid "We can now build and run our project. Navigate to the root of the project and execute the following lines:"
msgstr "We can now build and run our project. Navigate to the root of the project and execute the following lines:"


#: ../../setup_guides/sensors/setup_sensors.rst:258
msgid "RViz and the Gazebo will then be launched with ``sam_bot`` present in both. In the Gazebo window, the world that we created should be launched and ``sam_bot`` should be spawned in that world. You should now be able to observe ``sam_bot`` with the 360 lidar sensor and the depth camera, as shown in the image below."
msgstr "然后，RViz 和 Gazebo 将同时启动，``sam_bot``将存在于两者中。在 Gazebo 窗口中，我们创建的世界应该会被加载，``sam_bot``也应该会在该世界中生成。您现在应该能够观察到具有 360 度激光雷达传感器和深度摄像头的``sam_bot``，如下图所示。"


#: ../../setup_guides/sensors/setup_sensors.rst:263
msgid "In the RViz window, we can verify if we have properly modeled our sensors and if the transforms of our newly added sensors are correct:"
msgstr "In the RViz window, we can verify if we have properly modeled our sensors and if the transforms of our newly added sensors are correct:"


#: ../../setup_guides/sensors/setup_sensors.rst:268
msgid "Lastly, we can also visualize the sensor readings in RViz.  To visualize the ``sensor_msgs/LaserScan`` message published on ``/scan`` topic, click the add button at the bottom part of the RViz window. Then go to the ``By topic`` tab and select the ``LaserScan`` option under ``/scan``, as shown below."
msgstr "最后，我们还可以在 RViz 中可视化传感器读数。要可视化发布在``/scan``话题上的``sensor_msgs/LaserScan``消息，请在 RViz 窗口底部的添加按钮上点击。然后进入``By topic``选项卡，并在``/scan``下选择``LaserScan``选项，如下所示。"


#: ../../setup_guides/sensors/setup_sensors.rst:274
msgid "Next, set the ``Reliability Policy`` in RViz to ``Best Effort`` and set the ``size`` to 0.1 to see the points clearer. You should see the visualized ``LaserScan`` detection as shown below. This corresponds to the detected cube and sphere that we added to the Gazebo world."
msgstr "Next, set the ``Reliability Policy`` in RViz to ``Best Effort`` and set the ``size`` to 0.1 to see the points clearer. You should see the visualized ``LaserScan`` detection as shown below. This corresponds to the detected cube and sphere that we added to the Gazebo world."


#: ../../setup_guides/sensors/setup_sensors.rst:279
msgid "To visualize ``sensor_msgs/Image`` and ``sensor_msgs/PointCloud2``, do the same for topics ``/depth_camera/image_raw`` and ``/depth_camera/points`` respectively:"
msgstr "要可视化``sensor_msgs/Image``和``sensor_msgs/PointCloud2``，请分别对``/depth_camera/image_raw``和``/depth_camera/points``话题执行相同的操作："


#: ../../setup_guides/sensors/setup_sensors.rst:283
msgid "After adding the ``/depth_camera/image_raw`` topic in RViz, set the ``Reliability Policy`` in RViz to ``Best Effort``. Then you should see the cube in the image window at the lower-left side of the RViz window, as shown below."
msgstr "After adding the ``/depth_camera/image_raw`` topic in RViz, set the ``Reliability Policy`` in RViz to ``Best Effort``. Then you should see the cube in the image window at the lower-left side of the RViz window, as shown below."


#: ../../setup_guides/sensors/setup_sensors.rst:288
msgid "You should also see the ``sensor_msgs/PointCloud2``, as shown below."
msgstr "You should also see the ``sensor_msgs/PointCloud2``, as shown below."


#: ../../setup_guides/sensors/setup_sensors.rst:295
msgid "Mapping and Localization"
msgstr "Mapping and Localization"


#: ../../setup_guides/sensors/setup_sensors.rst:296
msgid "Now that we have a robot with its sensors set up, we can use the obtained sensor information to build a map of the environment and to localize the robot on the map. The ``slam_toolbox`` package is a set of tools and capabilities for 2D Simultaneous Localization and Mapping (SLAM) in potentially massive maps with ROS2. It is also one of the officially supported SLAM libraries in Nav2, and we recommend to use this package in situations you need to use SLAM on your robot setup. Aside from the ``slam_toolbox``, localization can also be implemented through the ``nav2_amcl`` package. This package implements Adaptive Monte Carlo Localization (AMCL) which estimates the position and orientation of the robot in a map. Other techniques may also be available, please check Nav2 documentation for more information."
msgstr "Now that we have a robot with its sensors set up, we can use the obtained sensor information to build a map of the environment and to localize the robot on the map. The ``slam_toolbox`` package is a set of tools and capabilities for 2D Simultaneous Localization and Mapping (SLAM) in potentially massive maps with ROS2. It is also one of the officially supported SLAM libraries in Nav2, and we recommend to use this package in situations you need to use SLAM on your robot setup. Aside from the ``slam_toolbox``, localization can also be implemented through the ``nav2_amcl`` package. This package implements Adaptive Monte Carlo Localization (AMCL) which estimates the position and orientation of the robot in a map. Other techniques may also be available, please check Nav2 documentation for more information."


#: ../../setup_guides/sensors/setup_sensors.rst:298
msgid "Both the ``slam_toolbox`` and ``nav2_amcl`` use information from the laser scan sensor to be able to perceive the robot's environment. Hence, to verify that they can access the laser scan sensor readings, we must make sure that they are subscribed to the correct topic that publishes the ``sensor_msgs/LaserScan`` message. This can be configured by setting their ``scan_topic`` parameters to the topic that publishes that message. It is a convention to publish the ``sensor_msgs/LaserScan`` messages to  ``/scan`` topic. Thus, by default, the ``scan_topic`` parameter is set to ``/scan``. Recall that when we added the lidar sensor to ``sam_bot`` in the previous section, we set the topic to which the lidar sensor will publish the ``sensor_msgs/LaserScan`` messages as ``/scan``."
msgstr "Both the ``slam_toolbox`` and ``nav2_amcl`` use information from the laser scan sensor to be able to perceive the robot's environment. Hence, to verify that they can access the laser scan sensor readings, we must make sure that they are subscribed to the correct topic that publishes the ``sensor_msgs/LaserScan`` message. This can be configured by setting their ``scan_topic`` parameters to the topic that publishes that message. It is a convention to publish the ``sensor_msgs/LaserScan`` messages to  ``/scan`` topic. Thus, by default, the ``scan_topic`` parameter is set to ``/scan``. Recall that when we added the lidar sensor to ``sam_bot`` in the previous section, we set the topic to which the lidar sensor will publish the ``sensor_msgs/LaserScan`` messages as ``/scan``."


#: ../../setup_guides/sensors/setup_sensors.rst:300
msgid "In-depth discussions on the complete configuration parameters will not be a scope of our tutorials since they can be pretty complex. Instead, we recommend you to have a look at their official documentation in the links below."
msgstr "In-depth discussions on the complete configuration parameters will not be a scope of our tutorials since they can be pretty complex. Instead, we recommend you to have a look at their official documentation in the links below."


#: ../../setup_guides/sensors/setup_sensors.rst
msgid "For the complete list of configuration parameters of ``slam_toolbox``, see the `Github repository of slam_toolbox <https://github.com/SteveMacenski/slam_toolbox#readme>`_."
msgstr "For the complete list of configuration parameters of ``slam_toolbox``, see the `Github repository of slam_toolbox <https://github.com/SteveMacenski/slam_toolbox#readme>`_."


#: ../../setup_guides/sensors/setup_sensors.rst
msgid "For the complete list of configuration parameters and example configuration of ``nav2_amcl``, see the `AMCL Configuration Guide <https://navigation.ros.org/configuration/packages/configuring-amcl.html>`_."
msgstr "For the complete list of configuration parameters and example configuration of ``nav2_amcl``, see the `AMCL Configuration Guide <https://navigation.ros.org/configuration/packages/configuring-amcl.html>`_."


#: ../../setup_guides/sensors/setup_sensors.rst:307
msgid "You can also refer to the `(SLAM) Navigating While Mapping guide <https://navigation.ros.org/tutorials/docs/navigation2_with_slam.html>`_ for the tutorial on how to use Nav2 with SLAM. You can verify that ``slam_toolbox`` and ``nav2_amcl`` have been correctly setup by visualizing the map and the robot's pose in RViz, similar to what was shown in the previous section."
msgstr "You can also refer to the `(SLAM) Navigating While Mapping guide <https://navigation.ros.org/tutorials/docs/navigation2_with_slam.html>`_ for the tutorial on how to use Nav2 with SLAM. You can verify that ``slam_toolbox`` and ``nav2_amcl`` have been correctly setup by visualizing the map and the robot's pose in RViz, similar to what was shown in the previous section."


#: ../../setup_guides/sensors/setup_sensors.rst:311
msgid "Costmap 2D"
msgstr "二维代价地图"


#: ../../setup_guides/sensors/setup_sensors.rst:312
msgid "The costmap 2D package makes use of the sensor information to provide a representation of the robot's environment in the form of an occupancy grid. The cells in the occupancy grid store cost values between 0-254 which denote a cost to travel through these zones. A cost of 0 means the cell is free while a cost of 254 means that the cell is lethally occupied. Values in between these extremes are used by navigation algorithms to steer your robot away from obstacles as a potential field. Costmaps in Nav2 are implemented through the ``nav2_costmap_2d`` package."
msgstr "The costmap 2D package makes use of the sensor information to provide a representation of the robot's environment in the form of an occupancy grid. The cells in the occupancy grid store cost values between 0-254 which denote a cost to travel through these zones. A cost of 0 means the cell is free while a cost of 254 means that the cell is lethally occupied. Values in between these extremes are used by navigation algorithms to steer your robot away from obstacles as a potential field. Costmaps in Nav2 are implemented through the ``nav2_costmap_2d`` package."


#: ../../setup_guides/sensors/setup_sensors.rst:314
msgid "The costmap implementation consists of multiple layers, each of which has a certain function that contributes to a cell's overall cost. The package consists of the following layers, but are plugin-based to allow customization and new layers to be used as well: static layer, inflation layer, range layer, obstacle layer, and voxel layer. The static layer represents the map section of the costmap, obtained from the messages published to the ``/map`` topic like those produced by SLAM.  The obstacle layer includes the objects detected by sensors that publish either or both the ``LaserScan`` and ``PointCloud2`` messages. The voxel layer is similar to the obstacle layer such that it can use either or both the ``LaserScan`` and ``PointCloud2`` sensor information but handles 3D data instead. The range layer allows for the inclusion of information provided by sonar and infrared sensors. Lastly, the inflation layer represents the added cost values around lethal obstacles such that our robot avoids navigating into obstacles due to the robot's geometry. In the next subsection of this tutorial, we will have some discussion about the basic configuration of the different layers in ``nav2_costmap_2d``."
msgstr "The costmap implementation consists of multiple layers, each of which has a certain function that contributes to a cell's overall cost. The package consists of the following layers, but are plugin-based to allow customization and new layers to be used as well: static layer, inflation layer, range layer, obstacle layer, and voxel layer. The static layer represents the map section of the costmap, obtained from the messages published to the ``/map`` topic like those produced by SLAM.  The obstacle layer includes the objects detected by sensors that publish either or both the ``LaserScan`` and ``PointCloud2`` messages. The voxel layer is similar to the obstacle layer such that it can use either or both the ``LaserScan`` and ``PointCloud2`` sensor information but handles 3D data instead. The range layer allows for the inclusion of information provided by sonar and infrared sensors. Lastly, the inflation layer represents the added cost values around lethal obstacles such that our robot avoids navigating into obstacles due to the robot's geometry. In the next subsection of this tutorial, we will have some discussion about the basic configuration of the different layers in ``nav2_costmap_2d``."


#: ../../setup_guides/sensors/setup_sensors.rst:316
msgid "The layers are integrated into the costmap through a plugin interface and then inflated using a user-specified `inflation radius <http://wiki.ros.org/costmap_2d/hydro/inflation>`_, if the inflation layer is enabled. For a deeper discussion on costmap concepts, you can have a look at the `ROS1 costmap_2D documentation <http://wiki.ros.org/costmap_2d>`_. Note that the ``nav2_costmap_2d`` package is mostly a straightforward ROS2 port of the ROS1 navigation stack version with minor changes required for ROS2 support and some new layer plugins."
msgstr "The layers are integrated into the costmap through a plugin interface and then inflated using a user-specified `inflation radius <http://wiki.ros.org/costmap_2d/hydro/inflation>`_, if the inflation layer is enabled. For a deeper discussion on costmap concepts, you can have a look at the `ROS1 costmap_2D documentation <http://wiki.ros.org/costmap_2d>`_. Note that the ``nav2_costmap_2d`` package is mostly a straightforward ROS2 port of the ROS1 navigation stack version with minor changes required for ROS2 support and some new layer plugins."


#: ../../setup_guides/sensors/setup_sensors.rst:321
msgid "Configuring nav2_costmap_2d"
msgstr "Configuring nav2_costmap_2d"


#: ../../setup_guides/sensors/setup_sensors.rst:322
msgid "In this subsection, we will show an example configuration of ``nav2_costmap_2d`` such that it uses the information provided by the lidar sensor of ``sam_bot``. We will show an example configuration that uses static layer, obstacle layer, voxel layer, and inflation layer. We set both the obstacle and voxel layer to use the ``LaserScan`` messages published  to the ``/scan`` topic by the lidar sensor. We also set some of the basic parameters to define how the detected obstacles are reflected in the costmap. Note that this configuration is to be included in the configuration file of Nav2."
msgstr "In this subsection, we will show an example configuration of ``nav2_costmap_2d`` such that it uses the information provided by the lidar sensor of ``sam_bot``. We will show an example configuration that uses static layer, obstacle layer, voxel layer, and inflation layer. We set both the obstacle and voxel layer to use the ``LaserScan`` messages published  to the ``/scan`` topic by the lidar sensor. We also set some of the basic parameters to define how the detected obstacles are reflected in the costmap. Note that this configuration is to be included in the configuration file of Nav2."


#: ../../setup_guides/sensors/setup_sensors.rst:399
msgid "In the configuration above, notice that we set the parameters for two different costmaps: ``global_costmap`` and ``local_costmap``. We set up two costmaps since the ``global_costmap`` is mainly used for long-term planning over the whole map while ``local_costmap`` is for short-term planning and collision avoidance."
msgstr "In the configuration above, notice that we set the parameters for two different costmaps: ``global_costmap`` and ``local_costmap``. We set up two costmaps since the ``global_costmap`` is mainly used for long-term planning over the whole map while ``local_costmap`` is for short-term planning and collision avoidance."


#: ../../setup_guides/sensors/setup_sensors.rst:401
msgid "The layers that we use for our configuration are defined in the ``plugins`` parameter, as shown in line 13 for the ``global_costmap`` and line 50 for the ``local_costmap``. These values are set as a list of mapped layer names that also serve as namespaces for the layer parameters we set up starting at lines 14 and line 51. Note that each layer/namespace in this list must have a ``plugin`` parameter (as indicated in lines 15, 18, 32, 52, and 68) defining the type of plugin to be loaded for that specific layer."
msgstr "The layers that we use for our configuration are defined in the ``plugins`` parameter, as shown in line 13 for the ``global_costmap`` and line 50 for the ``local_costmap``. These values are set as a list of mapped layer names that also serve as namespaces for the layer parameters we set up starting at lines 14 and line 51. Note that each layer/namespace in this list must have a ``plugin`` parameter (as indicated in lines 15, 18, 32, 52, and 68) defining the type of plugin to be loaded for that specific layer."


#: ../../setup_guides/sensors/setup_sensors.rst:403
msgid "For the static layer (lines 14-16), we set the ``map_subscribe_transient_local`` parameter to ``True``. This sets the QoS settings for the map topic. Another important parameter for the static layer is the ``map_topic`` which defines the map topic to subscribe to. This defaults to ``/map`` topic when not defined."
msgstr "For the static layer (lines 14-16), we set the ``map_subscribe_transient_local`` parameter to ``True``. This sets the QoS settings for the map topic. Another important parameter for the static layer is the ``map_topic`` which defines the map topic to subscribe to. This defaults to ``/map`` topic when not defined."


#: ../../setup_guides/sensors/setup_sensors.rst:405
msgid "For the obstacle layer (lines 17-30), we define its sensor source under the ``observation_sources`` parameter (line 20) as ``scan`` whose parameters are set up in lines 22-30. We set its ``topic`` parameter as the topic that publishes the defined sensor source and we set the ``data_type`` according to the sensor source it will use. In our configuration, the obstacle layer will use the ``LaserScan`` published by the lidar sensor to ``/scan``."
msgstr "For the obstacle layer (lines 17-30), we define its sensor source under the ``observation_sources`` parameter (line 20) as ``scan`` whose parameters are set up in lines 22-30. We set its ``topic`` parameter as the topic that publishes the defined sensor source and we set the ``data_type`` according to the sensor source it will use. In our configuration, the obstacle layer will use the ``LaserScan`` published by the lidar sensor to ``/scan``."


#: ../../setup_guides/sensors/setup_sensors.rst:407
msgid "Note that the obstacle layer and voxel layer can use either or both ``LaserScan`` and ``PointCloud2`` as their ``data_type`` but it is set to ``LaserScan`` by default. The code snippet below shows an example of using both the ``LaserScan`` and ``PointCloud2`` as the sensor sources. This may be particularly useful when setting up your own physical robot."
msgstr "Note that the obstacle layer and voxel layer can use either or both ``LaserScan`` and ``PointCloud2`` as their ``data_type`` but it is set to ``LaserScan`` by default. The code snippet below shows an example of using both the ``LaserScan`` and ``PointCloud2`` as the sensor sources. This may be particularly useful when setting up your own physical robot."


#: ../../setup_guides/sensors/setup_sensors.rst:422
msgid "For the other parameters of the obstacle layer, the ``max_obstacle_height`` parameter sets the maximum height of the sensor reading to return to the occupancy grid. The minimum height of the sensor reading can also be set using the ``min_obstacle_height`` parameter, which defaults to 0 since we did not set it in the configation. The ``clearing`` parameter is used to set whether the obstacle is to be removed from the costmap or not. The clearing operation is done by raytracing through the grid. The maximum and minimum range to raytrace clear objects from the costmap is set using the ``raytrace_max_range`` and ``raytrace_min_range`` respectively. The ``marking`` parameter is used to set whether the inserted obstacle is marked into the costmap or not. We also set the maximum and minimum range to mark obstacles in the costmap through the ``obstacle_max_range`` and ``obstacle_min_range`` respectively."
msgstr "For the other parameters of the obstacle layer, the ``max_obstacle_height`` parameter sets the maximum height of the sensor reading to return to the occupancy grid. The minimum height of the sensor reading can also be set using the ``min_obstacle_height`` parameter, which defaults to 0 since we did not set it in the configation. The ``clearing`` parameter is used to set whether the obstacle is to be removed from the costmap or not. The clearing operation is done by raytracing through the grid. The maximum and minimum range to raytrace clear objects from the costmap is set using the ``raytrace_max_range`` and ``raytrace_min_range`` respectively. The ``marking`` parameter is used to set whether the inserted obstacle is marked into the costmap or not. We also set the maximum and minimum range to mark obstacles in the costmap through the ``obstacle_max_range`` and ``obstacle_min_range`` respectively."


#: ../../setup_guides/sensors/setup_sensors.rst:424
msgid "For the inflation layer (lines 31-34 and 67-70), we set the exponential decay factor across the inflation radius using the ``cost_scaling_factor`` parameter. The value of the radius to inflate around lethal obstacles is defined using the ``inflation_radius``."
msgstr "For the inflation layer (lines 31-34 and 67-70), we set the exponential decay factor across the inflation radius using the ``cost_scaling_factor`` parameter. The value of the radius to inflate around lethal obstacles is defined using the ``inflation_radius``."


#: ../../setup_guides/sensors/setup_sensors.rst:426
msgid "For the voxel layer (lines 51-66), we set the ``publish_voxel_map`` parameter to ``True`` to enable the publishing of the 3D voxel grid. The resolution of the voxels in height is defined using the ``z_resolution`` parameter, while the number of voxels in each column is defined using the ``z_voxels`` parameter. The ``mark_threshold`` parameter sets the minimum number of voxels in a column to mark as occupied in the occupancy grid. We set the ``observation_sources`` parameter of the voxel layer to ``scan``, and we set the scan parameters (in lines 61-66) similar to the parameters that we have discussed for the obstacle layer. As defined in its ``topic`` and ``data_type`` parameters, the voxel layer will use the ``LaserScan`` published on the ``/scan`` topic by the lidar scanner."
msgstr "For the voxel layer (lines 51-66), we set the ``publish_voxel_map`` parameter to ``True`` to enable the publishing of the 3D voxel grid. The resolution of the voxels in height is defined using the ``z_resolution`` parameter, while the number of voxels in each column is defined using the ``z_voxels`` parameter. The ``mark_threshold`` parameter sets the minimum number of voxels in a column to mark as occupied in the occupancy grid. We set the ``observation_sources`` parameter of the voxel layer to ``scan``, and we set the scan parameters (in lines 61-66) similar to the parameters that we have discussed for the obstacle layer. As defined in its ``topic`` and ``data_type`` parameters, the voxel layer will use the ``LaserScan`` published on the ``/scan`` topic by the lidar scanner."


#: ../../setup_guides/sensors/setup_sensors.rst:428
msgid "Note that the we are not using a range layer for our configuration but it may be useful for your own robot setup. For the range layer, its basic parameters are the ``topics``, ``input_sensor_type``, and ``clear_on_max_reading`` parameters. The range topics to subscribe to are defined in the ``topics`` parameter. The ``input_sensor_type`` is set to either ``ALL``, ``VARIABLE``, or ``FIXED``. The ``clear_on_max_reading`` is a boolean parameter that sets whether to clear the sensor readings on max range.  Have a look at the configuration guide in the link below in case you need to set it up."
msgstr "Note that the we are not using a range layer for our configuration but it may be useful for your own robot setup. For the range layer, its basic parameters are the ``topics``, ``input_sensor_type``, and ``clear_on_max_reading`` parameters. The range topics to subscribe to are defined in the ``topics`` parameter. The ``input_sensor_type`` is set to either ``ALL``, ``VARIABLE``, or ``FIXED``. The ``clear_on_max_reading`` is a boolean parameter that sets whether to clear the sensor readings on max range.  Have a look at the configuration guide in the link below in case you need to set it up."


#: ../../setup_guides/sensors/setup_sensors.rst:431
msgid "For more information on ``nav2_costmap_2d`` and the complete list of layer plugin parameters, see the `Costmap 2D Configuration Guide <https://navigation.ros.org/configuration/packages/configuring-costmaps.html>`_."
msgstr "For more information on ``nav2_costmap_2d`` and the complete list of layer plugin parameters, see the `Costmap 2D Configuration Guide <https://navigation.ros.org/configuration/packages/configuring-costmaps.html>`_."


#: ../../setup_guides/sensors/setup_sensors.rst:436
msgid "We will first launch ``display.launch.py`` which launches the robot state publisher that provides the ``base_link`` => ``sensors`` transformations in our URDF. It also launches Gazebo that acts as our physics simulator and also provides the ``odom`` => ``base_link`` from the differential drive plugin, which we added to ``sam_bot`` in the previous guide, `Simulating an Odometry System Using Gazebo <https://navigation.ros.org/setup_guides/odom/setup_odom.html#simulating-an-odometry-system-using-gazebo>`_. It also launches RViz which we can use to visualize the robot and sensor information."
msgstr "We will first launch ``display.launch.py`` which launches the robot state publisher that provides the ``base_link`` => ``sensors`` transformations in our URDF. It also launches Gazebo that acts as our physics simulator and also provides the ``odom`` => ``base_link`` from the differential drive plugin, which we added to ``sam_bot`` in the previous guide, `Simulating an Odometry System Using Gazebo <https://navigation.ros.org/setup_guides/odom/setup_odom.html#simulating-an-odometry-system-using-gazebo>`_. It also launches RViz which we can use to visualize the robot and sensor information."


#: ../../setup_guides/sensors/setup_sensors.rst:438
msgid "Then we will launch ``slam_toolbox`` to publish to ``/map`` topic and provide the ``map`` => ``odom`` transform. Recall that the ``map`` => ``odom`` transform is one of the primary requirements of the Nav2 system. The messages published on the ``/map`` topic will then be used by the static layer of the ``global_costmap``."
msgstr "Then we will launch ``slam_toolbox`` to publish to ``/map`` topic and provide the ``map`` => ``odom`` transform. Recall that the ``map`` => ``odom`` transform is one of the primary requirements of the Nav2 system. The messages published on the ``/map`` topic will then be used by the static layer of the ``global_costmap``."


#: ../../setup_guides/sensors/setup_sensors.rst:440
msgid "After we have properly setup our robot description, odometry sensors, and necessary transforms, we will finally launch the Nav2 system itself. For now, we will only be exploring the costmap generation system of Nav2. After launching Nav2, we will visualize the costmaps in RViz to confirm our output."
msgstr "After we have properly setup our robot description, odometry sensors, and necessary transforms, we will finally launch the Nav2 system itself. For now, we will only be exploring the costmap generation system of Nav2. After launching Nav2, we will visualize the costmaps in RViz to confirm our output."


#: ../../setup_guides/sensors/setup_sensors.rst:443
msgid "Launching Description Nodes, RViz and Gazebo"
msgstr "Launching Description Nodes, RViz and Gazebo"


#: ../../setup_guides/sensors/setup_sensors.rst:445
msgid "Let us now launch our Robot Description Nodes, RViz and Gazebo through the launch file ``display.launch.py``. Open a new terminal and execute the lines below."
msgstr "Let us now launch our Robot Description Nodes, RViz and Gazebo through the launch file ``display.launch.py``. Open a new terminal and execute the lines below."


#: ../../setup_guides/sensors/setup_sensors.rst:453
msgid "RViz and the Gazebo should now be launched with ``sam_bot`` present in both. Recall that the ``base_link`` => ``sensors`` transform is now being published by ``robot_state_publisher`` and the ``odom`` => ``base_link`` transform by our Gazebo plugins. Both transforms should now be dislpayed show without errors in RViz."
msgstr "RViz and the Gazebo should now be launched with ``sam_bot`` present in both. Recall that the ``base_link`` => ``sensors`` transform is now being published by ``robot_state_publisher`` and the ``odom`` => ``base_link`` transform by our Gazebo plugins. Both transforms should now be dislpayed show without errors in RViz."


#: ../../setup_guides/sensors/setup_sensors.rst:456
msgid "Launching slam_toolbox"
msgstr "Launching slam_toolbox"


#: ../../setup_guides/sensors/setup_sensors.rst:458
msgid "To be able to launch ``slam_toolbox``, make sure that you have installed the ``slam_toolbox`` package by executing the following command:"
msgstr "To be able to launch ``slam_toolbox``, make sure that you have installed the ``slam_toolbox`` package by executing the following command:"


#: ../../setup_guides/sensors/setup_sensors.rst:464
msgid "We will launch the ``async_slam_toolbox_node`` of ``slam_toolbox`` using the package's built-in launch files. Open a new terminal and then execute the following lines:"
msgstr "We will launch the ``async_slam_toolbox_node`` of ``slam_toolbox`` using the package's built-in launch files. Open a new terminal and then execute the following lines:"


#: ../../setup_guides/sensors/setup_sensors.rst:470
msgid "The ``slam_toolbox`` should now be publishing to the ``/map`` topic and providing the ``map`` => ``odom`` transform."
msgstr "The ``slam_toolbox`` should now be publishing to the ``/map`` topic and providing the ``map`` => ``odom`` transform."


#: ../../setup_guides/sensors/setup_sensors.rst:472
msgid "We can verify in RViz that the ``/map`` topic is being published. In the RViz window, click the add button at the bottom-left part then go to ``By topic`` tab then select the ``Map`` under the ``/map`` topic. You should be able to visualize the message received in the ``/map`` as shown in the image below."
msgstr "We can verify in RViz that the ``/map`` topic is being published. In the RViz window, click the add button at the bottom-left part then go to ``By topic`` tab then select the ``Map`` under the ``/map`` topic. You should be able to visualize the message received in the ``/map`` as shown in the image below."


#: ../../setup_guides/sensors/setup_sensors.rst:477
msgid "We can also check that the transforms are correct by executing the following lines in a new terminal:"
msgstr "We can also check that the transforms are correct by executing the following lines in a new terminal:"


#: ../../setup_guides/sensors/setup_sensors.rst:483
msgid "Note: For Galactic and newer, it should be ``view_frames`` and not ``view_frames.py`` The line above will create a ``frames.pdf`` file that shows the current transform tree. Your tranform tree should be similar to the one shown below:"
msgstr "Note: For Galactic and newer, it should be ``view_frames`` and not ``view_frames.py`` The line above will create a ``frames.pdf`` file that shows the current transform tree. Your tranform tree should be similar to the one shown below:"


#: ../../setup_guides/sensors/setup_sensors.rst:490
msgid "Launching Nav2"
msgstr "Launching Nav2"


#: ../../setup_guides/sensors/setup_sensors.rst:491
msgid "First, Make sure you have installed the Nav2 packages by executing the following:"
msgstr "First, Make sure you have installed the Nav2 packages by executing the following:"


#: ../../setup_guides/sensors/setup_sensors.rst:498
msgid "We will now launch Nav2 using the ``nav2_bringup``'s built-in launch file, ``navigation_launch.py`` . Open a new terminal and execute the following:"
msgstr "We will now launch Nav2 using the ``nav2_bringup``'s built-in launch file, ``navigation_launch.py`` . Open a new terminal and execute the following:"


#: ../../setup_guides/sensors/setup_sensors.rst:504
msgid "Note that the parameters of the ``nav2_costmap_2d`` that we discussed in the previous subsection are included in the default parameters of ``navigation_launch.py``. Aside from the ``nav2_costmap_2d`` parameters, it also contains parameters for the other nodes that are included in Nav2 implementation."
msgstr "Note that the parameters of the ``nav2_costmap_2d`` that we discussed in the previous subsection are included in the default parameters of ``navigation_launch.py``. Aside from the ``nav2_costmap_2d`` parameters, it also contains parameters for the other nodes that are included in Nav2 implementation."


#: ../../setup_guides/sensors/setup_sensors.rst:506
msgid "After we have properly set up and launched Nav2, the ``/global_costmap`` and ``/local_costmap`` topics should now be active."
msgstr "After we have properly set up and launched Nav2, the ``/global_costmap`` and ``/local_costmap`` topics should now be active."


#: ../../setup_guides/sensors/setup_sensors.rst:509
msgid "To make the costmaps show up, run the 3 commands in this order"
msgstr "To make the costmaps show up, run the 3 commands in this order"


#: ../../setup_guides/sensors/setup_sensors.rst:511
msgid "Launching Description Nodes, RViz and Gazebo - in logs wait for \"Connected to gazebo master\""
msgstr "Launching Description Nodes, RViz and Gazebo - in logs wait for \"Connected to gazebo master\""


#: ../../setup_guides/sensors/setup_sensors.rst:512
msgid "Launching slam_toolbox - in logs wait for \"Registering sensor\""
msgstr "Launching slam_toolbox - in logs wait for \"Registering sensor\""


#: ../../setup_guides/sensors/setup_sensors.rst:513
msgid "Launching Nav2 - in logs wait for \"Creating bond timer\""
msgstr "Launching Nav2 - in logs wait for \"Creating bond timer\""


#: ../../setup_guides/sensors/setup_sensors.rst:516
msgid "Visualizing Costmaps in RViz"
msgstr "Visualizing Costmaps in RViz"


#: ../../setup_guides/sensors/setup_sensors.rst:518
msgid "The ``global_costmap``, ``local_costmap`` and the voxel representation of the detected obstacles can be visualized in RViz."
msgstr "The ``global_costmap``, ``local_costmap`` and the voxel representation of the detected obstacles can be visualized in RViz."


#: ../../setup_guides/sensors/setup_sensors.rst:520
msgid "To visualize the ``global_costmap`` in RViz, click the add button at the bottom-left part of the RViz window. Go to ``By topic`` tab then select the ``Map`` under the ``/global_costmap/costmap`` topic. The ``global_costmap`` should show in the RViz window, as shown below. The ``global_costmap`` shows areas which should be avoided (black) by our robot when it navigates our simulated world in Gazebo."
msgstr "To visualize the ``global_costmap`` in RViz, click the add button at the bottom-left part of the RViz window. Go to ``By topic`` tab then select the ``Map`` under the ``/global_costmap/costmap`` topic. The ``global_costmap`` should show in the RViz window, as shown below. The ``global_costmap`` shows areas which should be avoided (black) by our robot when it navigates our simulated world in Gazebo."


#: ../../setup_guides/sensors/setup_sensors.rst:525
msgid "To visualize the ``local_costmap`` in RViz, select the ``Map`` under the ``/local_costmap/costmap`` topic. Set the ``color scheme`` in RViz to ``costmap`` to make it appear similar to the image below."
msgstr "To visualize the ``local_costmap`` in RViz, select the ``Map`` under the ``/local_costmap/costmap`` topic. Set the ``color scheme`` in RViz to ``costmap`` to make it appear similar to the image below."


#: ../../setup_guides/sensors/setup_sensors.rst:530
msgid "To visualize the voxel representation of the detected object, open a new terminal and execute the following lines:"
msgstr "To visualize the voxel representation of the detected object, open a new terminal and execute the following lines:"


#: ../../setup_guides/sensors/setup_sensors.rst:536
msgid "The line above sets the topic where the the markers will be published to ``/my_marker``. To see the markers in RViz, select ``Marker`` under the ``/my_marker`` topic, as shown below."
msgstr "The line above sets the topic where the the markers will be published to ``/my_marker``. To see the markers in RViz, select ``Marker`` under the ``/my_marker`` topic, as shown below."


#: ../../setup_guides/sensors/setup_sensors.rst:542
msgid "Then set the ``fixed frame`` in RViz to ``odom`` and you should now see the voxels in RViz, which represent the cube and the sphere that we have in the Gazebo world:"
msgstr "Then set the ``fixed frame`` in RViz to ``odom`` and you should now see the voxels in RViz, which represent the cube and the sphere that we have in the Gazebo world:"


#: ../../setup_guides/sensors/setup_sensors.rst:550
msgid "In this section of our robot setup guide, we have discussed the importance of sensor information for different tasks associated with Nav2. More specifically, tasks such as mapping (SLAM), localization (AMCL), and perception (costmap) tasks."
msgstr "In this section of our robot setup guide, we have discussed the importance of sensor information for different tasks associated with Nav2. More specifically, tasks such as mapping (SLAM), localization (AMCL), and perception (costmap) tasks."


#: ../../setup_guides/sensors/setup_sensors.rst:552
msgid "We also had a discussion on the common types of sensor messages in Nav2 which standardize the message formats for different sensor vendors. We also discussed how to add sensors to a simulated robot using Gazebo and how to verify that the sensors are working correctly through RViz."
msgstr "We also had a discussion on the common types of sensor messages in Nav2 which standardize the message formats for different sensor vendors. We also discussed how to add sensors to a simulated robot using Gazebo and how to verify that the sensors are working correctly through RViz."


#: ../../setup_guides/sensors/setup_sensors.rst:554
msgid "Lastly, we set up a basic configuration for the ``nav2_costmap_2d`` package using different layers to produce a global and local costmap. We then verify our work by visualizing these costmaps in RViz."
msgstr "Lastly, we set up a basic configuration for the ``nav2_costmap_2d`` package using different layers to produce a global and local costmap. We then verify our work by visualizing these costmaps in RViz."


#: ../../setup_guides/transformation/setup_transforms.rst:4
msgid "Setting Up Transformations"
msgstr "Setting Up Transformations"


#: ../../setup_guides/transformation/setup_transforms.rst:6
msgid "In this guide, we will be looking at the necessary transforms required by Nav2. These transforms allow Nav2 to interpret information coming in from various sources, such as sensors and odometry, by transforming them to the coordinate frames for use. Below is what a full transform tree for a robot looks like but we'll start with something much more simpler."
msgstr "In this guide, we will be looking at the necessary transforms required by Nav2. These transforms allow Nav2 to interpret information coming in from various sources, such as sensors and odometry, by transforming them to the coordinate frames for use. Below is what a full transform tree for a robot looks like but we'll start with something much more simpler."


#: ../../setup_guides/transformation/setup_transforms.rst:11
msgid "For this tutorial, we will first provide a brief introduction to transforms in ROS. Second, we will be working on a simple command-line demo of a TF2 static publisher to see it in action. Lastly, we will outline the necessary transforms that need to be published for Nav2 to function."
msgstr "For this tutorial, we will first provide a brief introduction to transforms in ROS. Second, we will be working on a simple command-line demo of a TF2 static publisher to see it in action. Lastly, we will outline the necessary transforms that need to be published for Nav2 to function."


#: ../../setup_guides/transformation/setup_transforms.rst:14
msgid "Transforms Introduction"
msgstr "Transforms Introduction"


#: ../../setup_guides/transformation/setup_transforms.rst:17
msgid "This section of this guide has been adapted from the `Setting Up You Robot using tf <http://wiki.ros.org/navigation/Tutorials/RobotSetup/TF>`__ tutorial in the ROS (1) Navigation documentation."
msgstr "This section of this guide has been adapted from the `Setting Up You Robot using tf <http://wiki.ros.org/navigation/Tutorials/RobotSetup/TF>`__ tutorial in the ROS (1) Navigation documentation."


#: ../../setup_guides/transformation/setup_transforms.rst:19
msgid "Many ROS packages require the transform tree of a robot to be published using the TF2 ROS package. A transformation tree defines the relations between different coordinate systems, in terms of translation, rotation, and relative motion. To make this more concrete, let us apply an example of a simple robot that has a mobile base with a single laser sensor mounted on top of it."
msgstr "Many ROS packages require the transform tree of a robot to be published using the TF2 ROS package. A transformation tree defines the relations between different coordinate systems, in terms of translation, rotation, and relative motion. To make this more concrete, let us apply an example of a simple robot that has a mobile base with a single laser sensor mounted on top of it."


#: ../../setup_guides/transformation/setup_transforms.rst:21
msgid "This robot has two defined coordinate frames: one corresponding to the center point of the mobile base of the robot, and one for the center point of the laser that is mounted on top of the base. We'll call the coordinate frame attached to the mobile base  ``base_link`` and we'll call the coordinate frame attached to the laser ``base_laser``. Note that will be talking more about the naming and conventions of these coordinate frames in the next section."
msgstr "This robot has two defined coordinate frames: one corresponding to the center point of the mobile base of the robot, and one for the center point of the laser that is mounted on top of the base. We'll call the coordinate frame attached to the mobile base  ``base_link`` and we'll call the coordinate frame attached to the laser ``base_laser``. Note that will be talking more about the naming and conventions of these coordinate frames in the next section."


#: ../../setup_guides/transformation/setup_transforms.rst:23
msgid "At this point, let's assume that we have some data from the laser in the form of distance measurements from the laser's center point. In other words, we have some data in the ``base_laser`` coordinate frame."
msgstr "At this point, let's assume that we have some data from the laser in the form of distance measurements from the laser's center point. In other words, we have some data in the ``base_laser`` coordinate frame."


#: ../../setup_guides/transformation/setup_transforms.rst:25
msgid "Now, suppose we want to take this data and use it to help the mobile base avoid obstacles in the world. To do this successfully, we need a way to transform the laser scan we've received from the ``base_laser`` frame to the  ``base_link`` frame. In essence, we need to define a relationship between the ``base_laser`` and  ``base_link`` coordinate frames."
msgstr "Now, suppose we want to take this data and use it to help the mobile base avoid obstacles in the world. To do this successfully, we need a way to transform the laser scan we've received from the ``base_laser`` frame to the  ``base_link`` frame. In essence, we need to define a relationship between the ``base_laser`` and  ``base_link`` coordinate frames."


#: ../../setup_guides/transformation/setup_transforms.rst:30
msgid "In defining this relationship, let us assume that the only data we have is that the laser is mounted 10cm forward and 20cm above the center point of the mobile base. This gives us a translational offset that relates the  ``base_link`` frame to the ``base_laser`` frame. Specifically, we know that to get data from the  ``base_link`` frame to the ``base_laser`` frame, we must apply a translation of (x: 0.1m, y: 0.0m, z: 0.2m), and transversely, to get data from the ``base_laser`` frame to the  ``base_link`` frame, we must apply the opposite translation (x: -0.1m, y: 0.0m, z: -0.20m)."
msgstr "In defining this relationship, let us assume that the only data we have is that the laser is mounted 10cm forward and 20cm above the center point of the mobile base. This gives us a translational offset that relates the  ``base_link`` frame to the ``base_laser`` frame. Specifically, we know that to get data from the  ``base_link`` frame to the ``base_laser`` frame, we must apply a translation of (x: 0.1m, y: 0.0m, z: 0.2m), and transversely, to get data from the ``base_laser`` frame to the  ``base_link`` frame, we must apply the opposite translation (x: -0.1m, y: 0.0m, z: -0.20m)."


#: ../../setup_guides/transformation/setup_transforms.rst:32
msgid "We could choose to manage this relationship ourselves, meaning to store and apply the appropriate translations between the frames when necessary, but this becomes a real pain as the number of coordinate frames increases. Luckily, we don't have to do this work ourselves. Instead, we'll define the relationship between  ``base_link`` and ``base_laser`` once using TF2 and let it manage the transformation between the two coordinate frames for us. This is especially useful when working with non-static transformations, such as a set of frames that are moving relative to each other, like a robot base frame in a map frame."
msgstr "We could choose to manage this relationship ourselves, meaning to store and apply the appropriate translations between the frames when necessary, but this becomes a real pain as the number of coordinate frames increases. Luckily, we don't have to do this work ourselves. Instead, we'll define the relationship between  ``base_link`` and ``base_laser`` once using TF2 and let it manage the transformation between the two coordinate frames for us. This is especially useful when working with non-static transformations, such as a set of frames that are moving relative to each other, like a robot base frame in a map frame."


#: ../../setup_guides/transformation/setup_transforms.rst:34
msgid "To define and store the relationship between the  ``base_link`` and ``base_laser`` frames using TF2, we need to add them to a transform tree. Conceptually, each node in the transform tree corresponds to a coordinate frame, and each edge corresponds to the transform that needs to be applied to move from the current node to its child. TF2 uses a tree structure to guarantee that there is only a single traversal that links any two coordinate frames together, and assumes that all edges in the tree are directed from parent to child nodes."
msgstr "To define and store the relationship between the  ``base_link`` and ``base_laser`` frames using TF2, we need to add them to a transform tree. Conceptually, each node in the transform tree corresponds to a coordinate frame, and each edge corresponds to the transform that needs to be applied to move from the current node to its child. TF2 uses a tree structure to guarantee that there is only a single traversal that links any two coordinate frames together, and assumes that all edges in the tree are directed from parent to child nodes."


#: ../../setup_guides/transformation/setup_transforms.rst:39
msgid "To create a transform tree for our simple example, we'll create two nodes: one for the  ``base_link`` coordinate frame and one for the ``base_laser`` coordinate frame. To create the edge between them, we first need to decide which node will be the parent and which will be the child. Remember — this distinction is important because TF2 assumes that all transforms move from parent to child."
msgstr "To create a transform tree for our simple example, we'll create two nodes: one for the  ``base_link`` coordinate frame and one for the ``base_laser`` coordinate frame. To create the edge between them, we first need to decide which node will be the parent and which will be the child. Remember — this distinction is important because TF2 assumes that all transforms move from parent to child."


#: ../../setup_guides/transformation/setup_transforms.rst:41
msgid "Let's choose the  ``base_link`` coordinate frame as the parent because when other pieces/sensors are added to the robot, it will make the most sense for them to relate to the ``base_laser`` frame by traversing through the  ``base_link`` frame. This means that the transform associated with the edge connecting  ``base_link`` and ``base_laser`` should be (x: 0.1m, y: 0.0m, z: 0.2m)."
msgstr "Let's choose the  ``base_link`` coordinate frame as the parent because when other pieces/sensors are added to the robot, it will make the most sense for them to relate to the ``base_laser`` frame by traversing through the  ``base_link`` frame. This means that the transform associated with the edge connecting  ``base_link`` and ``base_laser`` should be (x: 0.1m, y: 0.0m, z: 0.2m)."


#: ../../setup_guides/transformation/setup_transforms.rst:43
msgid "With this transform tree set up, converting the laser scan received in the ``base_laser`` frame to the  ``base_link`` frame is as simple as making a call to the TF2 library. Our robot can now use this information to reason about laser scans in the  ``base_link`` frame and safely plan around obstacles in its environment."
msgstr "With this transform tree set up, converting the laser scan received in the ``base_laser`` frame to the  ``base_link`` frame is as simple as making a call to the TF2 library. Our robot can now use this information to reason about laser scans in the  ``base_link`` frame and safely plan around obstacles in its environment."


#: ../../setup_guides/transformation/setup_transforms.rst:46
msgid "Static Transform Publisher Demo"
msgstr "Static Transform Publisher Demo"


#: ../../setup_guides/transformation/setup_transforms.rst:48
msgid "If you are new to ROS 2 or do not have a working environment yet, then please take some time to properly setup your machine using the resources in the official `ROS 2 Installation Documentation <https://docs.ros.org/en/rolling/Installation.html>`__"
msgstr "If you are new to ROS 2 or do not have a working environment yet, then please take some time to properly setup your machine using the resources in the official `ROS 2 Installation Documentation <https://docs.ros.org/en/rolling/Installation.html>`__"


#: ../../setup_guides/transformation/setup_transforms.rst:50
msgid "Now let's try publishing a very simple transform using the static_transform_publisher tool provided by TF2. We will be publishing a transformation from the link ``base_link`` to the link ``base_laser`` with a translation of (x: 0.1m, y: 0.0m, z: 0.2m). Note that we will be building the transform from the diagram earlier in this tutorial."
msgstr "Now let's try publishing a very simple transform using the static_transform_publisher tool provided by TF2. We will be publishing a transformation from the link ``base_link`` to the link ``base_laser`` with a translation of (x: 0.1m, y: 0.0m, z: 0.2m). Note that we will be building the transform from the diagram earlier in this tutorial."


#: ../../setup_guides/transformation/setup_transforms.rst:52
msgid "Open up your command line and execute the following command:"
msgstr "Open up your command line and execute the following command:"


#: ../../setup_guides/transformation/setup_transforms.rst:58
msgid "With this, we are now sucessfully publishing our ``base_link`` to ``base_laser`` transform in TF2. Let us now check if it is working properly through ``tf2_echo``. Open up a separate command line window and execute the following:"
msgstr "With this, we are now sucessfully publishing our ``base_link`` to ``base_laser`` transform in TF2. Let us now check if it is working properly through ``tf2_echo``. Open up a separate command line window and execute the following:"


#: ../../setup_guides/transformation/setup_transforms.rst:64
msgid "You should be able to observe a repeated output simiar to the one below."
msgstr "You should be able to observe a repeated output simiar to the one below."


#: ../../setup_guides/transformation/setup_transforms.rst:72
msgid "And that's it for this short demo - we were able to successfully publish a transform from ``base_link`` to ``base_laser`` using the TF2 library. Note that we do not recommend using the above demo in publishing transforms for your actual robotics projects, it is just a quick demo to see TF2 in action. For a real robot system, we would create a URDF file which embeds this information and more about your robot for use of the robot_state_publisher rather than the static_transform_publisher. There are more suitable and practical ways to go about this which will be discussed in the :ref:`urdf_handson` tutorial."
msgstr "And that's it for this short demo - we were able to successfully publish a transform from ``base_link`` to ``base_laser`` using the TF2 library. Note that we do not recommend using the above demo in publishing transforms for your actual robotics projects, it is just a quick demo to see TF2 in action. For a real robot system, we would create a URDF file which embeds this information and more about your robot for use of the robot_state_publisher rather than the static_transform_publisher. There are more suitable and practical ways to go about this which will be discussed in the :ref:`urdf_handson` tutorial."


#: ../../setup_guides/transformation/setup_transforms.rst:75
msgid "If you would like to learn more about TF2 and how to create your own transform publishers, head onto the official `TF2 Documentation <https://wiki.ros.org/tf2/Tutorials>`__"
msgstr "If you would like to learn more about TF2 and how to create your own transform publishers, head onto the official `TF2 Documentation <https://wiki.ros.org/tf2/Tutorials>`__"


#: ../../setup_guides/transformation/setup_transforms.rst:79
msgid "Transforms in Navigation2"
msgstr "Transforms in Navigation2"


#: ../../setup_guides/transformation/setup_transforms.rst:81
msgid "There are two important ROS REPs which we highly suggest for you to check out. These documents detail some standards set about by the ROS community to ensure proper operation across different packages. Nav2 also adheres to these standards and conventions."
msgstr "There are two important ROS REPs which we highly suggest for you to check out. These documents detail some standards set about by the ROS community to ensure proper operation across different packages. Nav2 also adheres to these standards and conventions."


#: ../../setup_guides/transformation/setup_transforms.rst:83
msgid "`REP 105 - Coordinate Frames for Mobile Platforms <https://www.ros.org/reps/rep-0105.html>`__"
msgstr "`REP 105 - Coordinate Frames for Mobile Platforms <https://www.ros.org/reps/rep-0105.html>`__"


#: ../../setup_guides/transformation/setup_transforms.rst:84
msgid "`REP 103 - Standard Units of Measure and Coordinate Conventions <https://www.ros.org/reps/rep-0103.html>`__"
msgstr "`REP 103 - Standard Units of Measure and Coordinate Conventions <https://www.ros.org/reps/rep-0103.html>`__"


#: ../../setup_guides/transformation/setup_transforms.rst:86
msgid "To quickly summarize REP 105, this document specifies the naming conventions and semantic meanings of the different coordinate frames used in ROS. Of interest to this tutorial are the ``base_link``, ``odom`` and ``map`` coordinate frames. The ``base_link`` is a coordinate frame that is attached to a fixed position on the robot, typically at its main chassis and its rotational center. The ``odom`` coordinate frame is a fixed frame relative to the robot's starting position and is mainly used for locally-consistent representations of distances. Lastly, the ``map`` coordinate frame is a world fixed frame that is used for globally-consistent representations of distances."
msgstr "To quickly summarize REP 105, this document specifies the naming conventions and semantic meanings of the different coordinate frames used in ROS. Of interest to this tutorial are the ``base_link``, ``odom`` and ``map`` coordinate frames. The ``base_link`` is a coordinate frame that is attached to a fixed position on the robot, typically at its main chassis and its rotational center. The ``odom`` coordinate frame is a fixed frame relative to the robot's starting position and is mainly used for locally-consistent representations of distances. Lastly, the ``map`` coordinate frame is a world fixed frame that is used for globally-consistent representations of distances."


#: ../../setup_guides/transformation/setup_transforms.rst:88
msgid "REP 103, on the other hand, discusses some standard units of measure and other related conventions to keep integration issues between different ROS packages to a minimum. The basic overview is that frames are defined using the right hand rule, with Z up and X forward, and units should be standard SI units."
msgstr "REP 103, on the other hand, discusses some standard units of measure and other related conventions to keep integration issues between different ROS packages to a minimum. The basic overview is that frames are defined using the right hand rule, with Z up and X forward, and units should be standard SI units."


#: ../../setup_guides/transformation/setup_transforms.rst:90
msgid "Now let's move on to some specifics for the Navigation2 package to function correctly. Nav2 requires the following transformations to be published in ROS:"
msgstr "Now let's move on to some specifics for the Navigation2 package to function correctly. Nav2 requires the following transformations to be published in ROS:"


#: ../../setup_guides/transformation/setup_transforms.rst:92
msgid "``map`` => ``odom``"
msgstr "``map`` => ``odom``"


#: ../../setup_guides/transformation/setup_transforms.rst:93
msgid "``odom`` => ``base_link``"
msgstr "``odom`` => ``base_link``"


#: ../../setup_guides/transformation/setup_transforms.rst:94
msgid "``base_link`` => ``base_laser`` (sensor base frames)"
msgstr "``base_link`` => ``base_laser`` (sensor base frames)"


#: ../../setup_guides/transformation/setup_transforms.rst:97
msgid "The ``base_laser`` coordinate frame is not included in the REP 105 standard. For this guide, we will be using this name to refer to the coordinate frame for a laser sensor on our robot platform.  If there are multiple sensor base frames (e.g. camera_link, base_laser2, lidar_link etc.), then a transformation back to ``base_link`` for each one is required."
msgstr "The ``base_laser`` coordinate frame is not included in the REP 105 standard. For this guide, we will be using this name to refer to the coordinate frame for a laser sensor on our robot platform.  If there are multiple sensor base frames (e.g. camera_link, base_laser2, lidar_link etc.), then a transformation back to ``base_link`` for each one is required."


#: ../../setup_guides/transformation/setup_transforms.rst:99
msgid "The first transform ``map`` => ``odom`` is usually provided by a different ROS package dealing with localization and mapping such as AMCL. This transform updates live in use so we don't set static values for this in our robot's TF tree. Further detail about how to set this up may be pretty complex, so we highly suggest to have a look at the documentation of the mapping or localization package you are using for your platform. All ROS compliant SLAM and localization packages will provide you with this transformation automatically on launch."
msgstr "The first transform ``map`` => ``odom`` is usually provided by a different ROS package dealing with localization and mapping such as AMCL. This transform updates live in use so we don't set static values for this in our robot's TF tree. Further detail about how to set this up may be pretty complex, so we highly suggest to have a look at the documentation of the mapping or localization package you are using for your platform. All ROS compliant SLAM and localization packages will provide you with this transformation automatically on launch."


#: ../../setup_guides/transformation/setup_transforms.rst:101
msgid "The ``odom`` => ``base_link`` is usually published by our odometry system using sensors such as wheel encoders. This is typically computed via sensor fusion of odometry sensors (IMU, wheel encoders, VIO, etc) using the ``robot_localization`` package."
msgstr "The ``odom`` => ``base_link`` is usually published by our odometry system using sensors such as wheel encoders. This is typically computed via sensor fusion of odometry sensors (IMU, wheel encoders, VIO, etc) using the ``robot_localization`` package."


#: ../../setup_guides/transformation/setup_transforms.rst:103
msgid "All other statically defined transforms (e.g. ``base_link`` => ``base_laser``, ``base_link`` => ``wheels``, ``wheels`` => ``IMU``, etc) is what we will be talking about for the rest of this guide. This transformation tree is used by Nav2 to properly relate the information from sensors or other frame of interest to the rest of the robot. The transformation between these two coordinate frames is usually provided to Nav2 through the Robot State Publisher and the Universal Robot Descriptor File (URDF). In cases where there are more sensor coordinate frames on your platform, then a transform tree from ``base_link`` to each sensor coordinate frame needs to be published."
msgstr "All other statically defined transforms (e.g. ``base_link`` => ``base_laser``, ``base_link`` => ``wheels``, ``wheels`` => ``IMU``, etc) is what we will be talking about for the rest of this guide. This transformation tree is used by Nav2 to properly relate the information from sensors or other frame of interest to the rest of the robot. The transformation between these two coordinate frames is usually provided to Nav2 through the Robot State Publisher and the Universal Robot Descriptor File (URDF). In cases where there are more sensor coordinate frames on your platform, then a transform tree from ``base_link`` to each sensor coordinate frame needs to be published."


#: ../../setup_guides/transformation/setup_transforms.rst:106
msgid "For a more in-depth discussion on the usage of transforms and how these are used to estimate the current state of your robot, we highly recommend having a look at the State Estimation topic in :ref:`concepts`."
msgstr "For a more in-depth discussion on the usage of transforms and how these are used to estimate the current state of your robot, we highly recommend having a look at the State Estimation topic in :ref:`concepts`."


#: ../../setup_guides/transformation/setup_transforms.rst:111
msgid "In this tutorial, we have discussed about the concept of transforms and how they are used in Nav2."
msgstr "In this tutorial, we have discussed about the concept of transforms and how they are used in Nav2."


#: ../../setup_guides/transformation/setup_transforms.rst:113
msgid "In the last section, we have also explored using the static_transform_publisher of TF2 to publish our transforms. You may use this to set up your transforms for Nav2, but this is generally not the best way to do it. In most robotics projects, we make use of the Robot State Publisher since it is much easier to use and scales well as our robot gets more complex. We will be talking about the Robot State Publisher, URDF, and how to set it up in the next tutorial on :ref:`urdf_handson`."
msgstr "In the last section, we have also explored using the static_transform_publisher of TF2 to publish our transforms. You may use this to set up your transforms for Nav2, but this is generally not the best way to do it. In most robotics projects, we make use of the Robot State Publisher since it is much easier to use and scales well as our robot gets more complex. We will be talking about the Robot State Publisher, URDF, and how to set it up in the next tutorial on :ref:`urdf_handson`."


#: ../../setup_guides/transformation/setup_transforms.rst:115
msgid "Lastly, we also discussed the three published transform requirements of Nav2 and the neccessary REPs to keep in mind when setting them up."
msgstr "Lastly, we also discussed the three published transform requirements of Nav2 and the neccessary REPs to keep in mind when setting them up."


#: ../../setup_guides/urdf/setup_urdf.rst:4
msgid "Setting Up The URDF"
msgstr "Setting Up The URDF"


#: ../../setup_guides/urdf/setup_urdf.rst:6
msgid "For this guide, we will be creating the Unified Robot Description Format (URDF) file for a simple differential drive robot to give you hands-on experience on working with URDF. We will also setup the robot state publisher and visualize our model in RVIZ. Lastly, we will be adding some kinematic properties to our robot URDF to prepare it for simulation purposes. These steps are necessary to represent all the sensor, hardware, and robot transforms of your robot for use in navigation."
msgstr "For this guide, we will be creating the Unified Robot Description Format (URDF) file for a simple differential drive robot to give you hands-on experience on working with URDF. We will also setup the robot state publisher and visualize our model in RVIZ. Lastly, we will be adding some kinematic properties to our robot URDF to prepare it for simulation purposes. These steps are necessary to represent all the sensor, hardware, and robot transforms of your robot for use in navigation."


#: ../../setup_guides/urdf/setup_urdf.rst:12
msgid "URDF and the Robot State Publisher"
msgstr "URDF and the Robot State Publisher"


#: ../../setup_guides/urdf/setup_urdf.rst:14
msgid "As discussed in the previous tutorial, one of the requirements for Navigation2 is the transformation from  ``base_link`` to the various sensors and reference frames. This transformation tree can range from a simple tree with only one link from the  ``base_link`` to ``laser_link`` or a tree comprised of multiple sensors located in different locations, each having their own coordinate frame. Creating multiple publishers to handle all of these coordinate frame transformations may become tedious. Therefore, we will be making use of the Robot State Publisher package to publish our transforms."
msgstr "As discussed in the previous tutorial, one of the requirements for Navigation2 is the transformation from  ``base_link`` to the various sensors and reference frames. This transformation tree can range from a simple tree with only one link from the  ``base_link`` to ``laser_link`` or a tree comprised of multiple sensors located in different locations, each having their own coordinate frame. Creating multiple publishers to handle all of these coordinate frame transformations may become tedious. Therefore, we will be making use of the Robot State Publisher package to publish our transforms."


#: ../../setup_guides/urdf/setup_urdf.rst:16
msgid "The Robot State Publisher is a package of ROS 2 that interacts with the tf2 package to publish all of the necessary transforms that can be directly inferred from the geometry and structure of the robot. We need to provide it with the correct URDF and it will automatically handle publishing the transforms. This is very useful for complex transformations but it is still recommended for simpler transform trees."
msgstr "The Robot State Publisher is a package of ROS 2 that interacts with the tf2 package to publish all of the necessary transforms that can be directly inferred from the geometry and structure of the robot. We need to provide it with the correct URDF and it will automatically handle publishing the transforms. This is very useful for complex transformations but it is still recommended for simpler transform trees."


#: ../../setup_guides/urdf/setup_urdf.rst:18
msgid "The Unified Robot Description Format (URDF) is an XML file that represents a robot model. In this tutorial, it will mainly be used to build transformations trees related with the robot geometry, but it also has other uses. One example is how it can be used in visualizing your robot model in RVIZ, a 3D Visualization tool for ROS, by defining visual components such as materials and meshes. Another example is how the URDF can be used to define the physical properties of the robot. These properties are then used in physics simulators such as Gazebo to simulate how your robot will interact in an environment."
msgstr "The Unified Robot Description Format (URDF) is an XML file that represents a robot model. In this tutorial, it will mainly be used to build transformations trees related with the robot geometry, but it also has other uses. One example is how it can be used in visualizing your robot model in RVIZ, a 3D Visualization tool for ROS, by defining visual components such as materials and meshes. Another example is how the URDF can be used to define the physical properties of the robot. These properties are then used in physics simulators such as Gazebo to simulate how your robot will interact in an environment."


#: ../../setup_guides/urdf/setup_urdf.rst:20
msgid "Another major feature of URDF is that it also supports Xacro (XML Macros) to help you create a shorter and readable XML to help in defining complex robots. We can use these macros to eliminate the need for repeating blocks of XML in our URDF. Xacro is also useful in defining configuration constants which can be reused throughout the URDF."
msgstr "Another major feature of URDF is that it also supports Xacro (XML Macros) to help you create a shorter and readable XML to help in defining complex robots. We can use these macros to eliminate the need for repeating blocks of XML in our URDF. Xacro is also useful in defining configuration constants which can be reused throughout the URDF."


#: ../../setup_guides/urdf/setup_urdf.rst:23
msgid "If you want to learn more about the URDF and the Robot State Publisher, we encourage you to have a look at the official `URDF Documentation <http://wiki.ros.org/urdf>`__ and `Robot State Publisher Documentation <http://wiki.ros.org/robot_state_publisher>`__"
msgstr "If you want to learn more about the URDF and the Robot State Publisher, we encourage you to have a look at the official `URDF Documentation <http://wiki.ros.org/urdf>`__ and `Robot State Publisher Documentation <http://wiki.ros.org/robot_state_publisher>`__"


#: ../../setup_guides/urdf/setup_urdf.rst:26
msgid "Setting Up the Environment"
msgstr "Setting Up the Environment"


#: ../../setup_guides/urdf/setup_urdf.rst:28
msgid "In this guide, we are assuming that you are already familiar with ROS 2 and how to setup your development environment, so we'll breeze through the steps in this section."
msgstr "In this guide, we are assuming that you are already familiar with ROS 2 and how to setup your development environment, so we'll breeze through the steps in this section."


#: ../../setup_guides/urdf/setup_urdf.rst:30
msgid "Let's begin by installing some additional ROS 2 packages that we will be using during this tutorial."
msgstr "Let's begin by installing some additional ROS 2 packages that we will be using during this tutorial."


#: ../../setup_guides/urdf/setup_urdf.rst:37
msgid "Next, create a directory for your project, initialize a ROS 2 workspace and give your robot a name. For ours, we'll be calling it ``sam_bot``."
msgstr "Next, create a directory for your project, initialize a ROS 2 workspace and give your robot a name. For ours, we'll be calling it ``sam_bot``."


#: ../../setup_guides/urdf/setup_urdf.rst:44
msgid "Writing the URDF"
msgstr "Writing the URDF"


#: ../../setup_guides/urdf/setup_urdf.rst:46
msgid "This section aims to provide you with a beginner-friendly introduction to building URDFs for your robot. If you would like to learn more about URDF and XAcro, we suggest for you to have a look at the official `URDF Documentation <http://wiki.ros.org/urdf>`__"
msgstr "This section aims to provide you with a beginner-friendly introduction to building URDFs for your robot. If you would like to learn more about URDF and XAcro, we suggest for you to have a look at the official `URDF Documentation <http://wiki.ros.org/urdf>`__"


#: ../../setup_guides/urdf/setup_urdf.rst:48
msgid "Now that we have our project workspace set up, let's dive straight into writing the URDF. Below is an image of the robot we will be trying to build."
msgstr "Now that we have our project workspace set up, let's dive straight into writing the URDF. Below is an image of the robot we will be trying to build."


#: ../../setup_guides/urdf/setup_urdf.rst:57
msgid "To get started, create a file named ``sam_bot_description.urdf`` under ``src/description`` and input the following as the initial contents of the file."
msgstr "To get started, create a file named ``sam_bot_description.urdf`` under ``src/description`` and input the following as the initial contents of the file."


#: ../../setup_guides/urdf/setup_urdf.rst:69
msgid "The following code snippets should be placed within the ``<robot>`` tags. We suggest to add them in the same order as introduced in this tutorial. We have also included some line numbers to give you a rough idea on where to input the code. This may differ from the actual file you are writing depending on your usage of whitespaces. Also note that the line numbers assume that you are putting in code as they appear in this guide."
msgstr "The following code snippets should be placed within the ``<robot>`` tags. We suggest to add them in the same order as introduced in this tutorial. We have also included some line numbers to give you a rough idea on where to input the code. This may differ from the actual file you are writing depending on your usage of whitespaces. Also note that the line numbers assume that you are putting in code as they appear in this guide."


#: ../../setup_guides/urdf/setup_urdf.rst:71
msgid "Next, let us define some constants using XAcro properties that will be reused throughout the URDF."
msgstr "Next, let us define some constants using XAcro properties that will be reused throughout the URDF."


#: ../../setup_guides/urdf/setup_urdf.rst:89
msgid "Here is a brief discussion on what these properties will represent in our urdf. The ``base_*`` properties all define the size of the robot's main chassis. The ``wheel_radius`` and ``wheel_width`` define the shape of the robot's two back wheels. The ``wheel_ygap`` adjusts the gap between the wheel and the chassis along the y-axis whilst ``wheel_zoff`` and ``wheel_xoff`` position the back wheels along the z-axis and x-axis appropriately. Lastly, the ``caster_xoff`` positions the front caster wheel along the x-axis."
msgstr "Here is a brief discussion on what these properties will represent in our urdf. The ``base_*`` properties all define the size of the robot's main chassis. The ``wheel_radius`` and ``wheel_width`` define the shape of the robot's two back wheels. The ``wheel_ygap`` adjusts the gap between the wheel and the chassis along the y-axis whilst ``wheel_zoff`` and ``wheel_xoff`` position the back wheels along the z-axis and x-axis appropriately. Lastly, the ``caster_xoff`` positions the front caster wheel along the x-axis."


#: ../../setup_guides/urdf/setup_urdf.rst:91
msgid "Let us then define our ``base_link`` - this link will be a large box and will act as the main chassis of our robot. In URDF, a ``link`` element describes a rigid part or component of our robot. The robot state publisher then utilizes these definitions to determine coordinate frames for each link and publish the transformations between them."
msgstr "Let us then define our ``base_link`` - this link will be a large box and will act as the main chassis of our robot. In URDF, a ``link`` element describes a rigid part or component of our robot. The robot state publisher then utilizes these definitions to determine coordinate frames for each link and publish the transformations between them."


#: ../../setup_guides/urdf/setup_urdf.rst:93
msgid "We will also be defining some of the link's visual properties which can be used by tools such as Gazebo and Rviz to show us a 3D model of our robot. Amongst these properties are ``<geometry>`` which describes the link's shape and ``<material>`` which describes it's color."
msgstr "We will also be defining some of the link's visual properties which can be used by tools such as Gazebo and Rviz to show us a 3D model of our robot. Amongst these properties are ``<geometry>`` which describes the link's shape and ``<material>`` which describes it's color."


#: ../../setup_guides/urdf/setup_urdf.rst:95
msgid "For the code block block below, we access the ``base`` properties from the robot constants sections we defined before using the ``${property}`` syntax. In addition, we also set the material color of the main chassis to ``Cyan``. Note that we set these parameters under the ``<visual>`` tag so they will only be applied as visual parameters which dont affect any collision or physical properties."
msgstr "For the code block block below, we access the ``base`` properties from the robot constants sections we defined before using the ``${property}`` syntax. In addition, we also set the material color of the main chassis to ``Cyan``. Note that we set these parameters under the ``<visual>`` tag so they will only be applied as visual parameters which dont affect any collision or physical properties."


#: ../../setup_guides/urdf/setup_urdf.rst:112
msgid "Next, let us define a ``base_footprint`` link. The ``base_footprint`` link is a virtual (non-physical) link which has no dimensions or collision areas. Its primary purpose is to enable various packages determine the center of a robot projected to the ground. For example, Navigation2 uses this link to determine the center of a circular footprint used in its obstacle avoidance algorithms. Again, we set this link with no dimensions and to which position the robot's center is in when it is projected to the ground plane."
msgstr "Next, let us define a ``base_footprint`` link. The ``base_footprint`` link is a virtual (non-physical) link which has no dimensions or collision areas. Its primary purpose is to enable various packages determine the center of a robot projected to the ground. For example, Navigation2 uses this link to determine the center of a circular footprint used in its obstacle avoidance algorithms. Again, we set this link with no dimensions and to which position the robot's center is in when it is projected to the ground plane."


#: ../../setup_guides/urdf/setup_urdf.rst:114
msgid "After defining our base_link, we then add a joint to connect it to ``base_link``. In URDF, a ``joint`` element describes the kinematic and dynamic properties between coordinate frames. For this case, we will be defining a ``fixed`` joint with the appropriate offsets to place our ``base_footprint`` link in the proper location based on the description above. Remember that we want to set our base_footprint to be at the ground plane when projected from the center of the main chassis, hence we get the sum of the ``wheel_radius`` and the ``wheel_zoff`` to get the appropriate location along the z-axis."
msgstr "After defining our base_link, we then add a joint to connect it to ``base_link``. In URDF, a ``joint`` element describes the kinematic and dynamic properties between coordinate frames. For this case, we will be defining a ``fixed`` joint with the appropriate offsets to place our ``base_footprint`` link in the proper location based on the description above. Remember that we want to set our base_footprint to be at the ground plane when projected from the center of the main chassis, hence we get the sum of the ``wheel_radius`` and the ``wheel_zoff`` to get the appropriate location along the z-axis."


#: ../../setup_guides/urdf/setup_urdf.rst:128
msgid "Now, we will be adding two large drive wheels to our robot. To make our code cleaner and avoid repetition, we will make use of macros to define a block of code that will be repeated with differing parameters. Our macro will have 3 params: ``prefix`` which simply adds a prefix to our link and joint names, and ``x_reflect`` and ``y_reflect`` which allows us to flip the positions of our wheels with respect to the x and y axis respectively. Within this macro, we can also define the visual properties of a single wheel. Lastly, we will also define a ``continuous`` joint to allow our wheels to freely rotate about an axis. This joint also connects our wheel to the ``base_link`` at the appropriate location."
msgstr "Now, we will be adding two large drive wheels to our robot. To make our code cleaner and avoid repetition, we will make use of macros to define a block of code that will be repeated with differing parameters. Our macro will have 3 params: ``prefix`` which simply adds a prefix to our link and joint names, and ``x_reflect`` and ``y_reflect`` which allows us to flip the positions of our wheels with respect to the x and y axis respectively. Within this macro, we can also define the visual properties of a single wheel. Lastly, we will also define a ``continuous`` joint to allow our wheels to freely rotate about an axis. This joint also connects our wheel to the ``base_link`` at the appropriate location."


#: ../../setup_guides/urdf/setup_urdf.rst:130
msgid "At the end of this code block, we will be instantiating two wheels using the macro we just made through the ``xacro:wheel`` tags. Note that we also define the parameters to have one wheel on both sides at the back of our robot."
msgstr "At the end of this code block, we will be instantiating two wheels using the macro we just made through the ``xacro:wheel`` tags. Note that we also define the parameters to have one wheel on both sides at the back of our robot."


#: ../../setup_guides/urdf/setup_urdf.rst:160
msgid "Next, we will be adding a caster wheel at the front of our robot. We will be modelling this wheel as a sphere to keep things simple. Again, we define the wheel's geometry, material and the joint to connect it to ``base_link`` at the appropriate location."
msgstr "Next, we will be adding a caster wheel at the front of our robot. We will be modelling this wheel as a sphere to keep things simple. Again, we define the wheel's geometry, material and the joint to connect it to ``base_link`` at the appropriate location."


#: ../../setup_guides/urdf/setup_urdf.rst:183
msgid "And that's it! We have built a URDF for a simple differential drive robot. In the next section, we will focus on building the ROS Package containing our URDF, launching the robot state publisher, and visualizing the robot in RVIz."
msgstr "And that's it! We have built a URDF for a simple differential drive robot. In the next section, we will focus on building the ROS Package containing our URDF, launching the robot state publisher, and visualizing the robot in RVIz."


#: ../../setup_guides/urdf/setup_urdf.rst:186
msgid "Build and Launch"
msgstr "Build and Launch"


#: ../../setup_guides/urdf/setup_urdf.rst:188
msgid "The launch files from this tutorial were adapted from the official `URDF Tutorials for ROS 2 <https://github.com/ros/urdf_tutorial/tree/ros2>`__"
msgstr "The launch files from this tutorial were adapted from the official `URDF Tutorials for ROS 2 <https://github.com/ros/urdf_tutorial/tree/ros2>`__"


#: ../../setup_guides/urdf/setup_urdf.rst:190
msgid "Let's start this section by adding some dependencies that will be required once we build this project. Open up the root of your project directory and add the following lines to your ``package.xml`` (preferably after the ``<buildtool_depend>`` tag)"
msgstr "Let's start this section by adding some dependencies that will be required once we build this project. Open up the root of your project directory and add the following lines to your ``package.xml`` (preferably after the ``<buildtool_depend>`` tag)"


#: ../../setup_guides/urdf/setup_urdf.rst:200
msgid "Next, let us create our launch file. Launch files are used by ROS 2 to bring up the necessary nodes for our package. From the root of the project, create a directory named ``launch`` and a ``display.launch.py`` file within it. The launch file below launches a robot publisher node in ROS 2 that uses our URDF to publish the transforms for our robot. In addition, the launch file also automatically launches RVIZ so we can visualize our robot as defined by the URDF. Copy and paste the snippet below into your ``display.launch.py`` file."
msgstr "Next, let us create our launch file. Launch files are used by ROS 2 to bring up the necessary nodes for our package. From the root of the project, create a directory named ``launch`` and a ``display.launch.py`` file within it. The launch file below launches a robot publisher node in ROS 2 that uses our URDF to publish the transforms for our robot. In addition, the launch file also automatically launches RVIZ so we can visualize our robot as defined by the URDF. Copy and paste the snippet below into your ``display.launch.py`` file."


#: ../../setup_guides/urdf/setup_urdf.rst:252
msgid "For more information regarding the launch system in ROS 2, you can have a look at the official `ROS 2 Launch System Documentation <https://docs.ros.org/en/rolling/Tutorials/Launch-system.html>`__"
msgstr "For more information regarding the launch system in ROS 2, you can have a look at the official `ROS 2 Launch System Documentation <https://docs.ros.org/en/rolling/Tutorials/Launch-system.html>`__"


#: ../../setup_guides/urdf/setup_urdf.rst:254
msgid "To keep things simpler when we get to visualization, we have provided an RVIz config file that will be loaded when we launch our package. This configuration file initializes RVIz with the proper settings so you can view the robot immediately once it launches. Create a directory named ``rviz`` in the root of your project and a file named ``urdf_config.rviz`` under it. Place the following as the contents of ``urdf_config.rviz``"
msgstr "To keep things simpler when we get to visualization, we have provided an RVIz config file that will be loaded when we launch our package. This configuration file initializes RVIz with the proper settings so you can view the robot immediately once it launches. Create a directory named ``rviz`` in the root of your project and a file named ``urdf_config.rviz`` under it. Place the following as the contents of ``urdf_config.rviz``"


#: ../../setup_guides/urdf/setup_urdf.rst:323
msgid "Lastly, let us modify the ``CMakeLists.txt`` file in the project root directory to include the files we just created during the package installation process. Add the following snippet to ``CMakeLists.txt`` file preferrably above the ``if(BUILD_TESTING)`` line:"
msgstr "Lastly, let us modify the ``CMakeLists.txt`` file in the project root directory to include the files we just created during the package installation process. Add the following snippet to ``CMakeLists.txt`` file preferrably above the ``if(BUILD_TESTING)`` line:"


#: ../../setup_guides/urdf/setup_urdf.rst:332
msgid "We are now ready to build our project using colcon. Navigate to the project root and execute the following commands."
msgstr "We are now ready to build our project using colcon. Navigate to the project root and execute the following commands."


#: ../../setup_guides/urdf/setup_urdf.rst:339
msgid "After a successful build, execute the following commands to install the ROS 2 package and launch our project."
msgstr "After a successful build, execute the following commands to install the ROS 2 package and launch our project."


#: ../../setup_guides/urdf/setup_urdf.rst:345
msgid "ROS 2 should now launch a robot publisher node and start up RVIZ using our URDF. We'll be taking a look at our robot using RVIZ in the next section."
msgstr "ROS 2 should now launch a robot publisher node and start up RVIZ using our URDF. We'll be taking a look at our robot using RVIZ in the next section."


#: ../../setup_guides/urdf/setup_urdf.rst:348
msgid "Visualization using RVIZ"
msgstr "Visualization using RVIZ"


#: ../../setup_guides/urdf/setup_urdf.rst:350
msgid "RVIZ is a robot visualization tool that allows us to see a 3D model of our robot using its URDF. Upon a successful launch using the commands in the previous section, RVIZ should now be visible on your screen and should look like the image below. You may need to move around and manipulate the view to get a good look at your robot."
msgstr "RVIZ is a robot visualization tool that allows us to see a 3D model of our robot using its URDF. Upon a successful launch using the commands in the previous section, RVIZ should now be visible on your screen and should look like the image below. You may need to move around and manipulate the view to get a good look at your robot."


#: ../../setup_guides/urdf/setup_urdf.rst:354
msgid "As you can see, we have successfully created a simple differential drive robot and visualized it in RVIz. It is not necessary to visualize your robot in RVIz, but it's a good step in order to see if you have properly defined your URDF. This helps you ensure that the robot state publisher is publishing the correct transformations."
msgstr "As you can see, we have successfully created a simple differential drive robot and visualized it in RVIz. It is not necessary to visualize your robot in RVIz, but it's a good step in order to see if you have properly defined your URDF. This helps you ensure that the robot state publisher is publishing the correct transformations."


#: ../../setup_guides/urdf/setup_urdf.rst:356
msgid "You may have noticed that another window was launched - this is a GUI for the joint state publisher. The joint state publisher is another ROS 2 package which publishes the state for our non-fixed joints. You can manipulate this publisher through the small GUI and the new pose of the joints will be reflected in RVIz. Sliding the bars for any of the two wheels will rotate these joints. You can see this in action by viewing RVIZ as you sweep the sliders in the Joint State Publisher GUI."
msgstr "You may have noticed that another window was launched - this is a GUI for the joint state publisher. The joint state publisher is another ROS 2 package which publishes the state for our non-fixed joints. You can manipulate this publisher through the small GUI and the new pose of the joints will be reflected in RVIz. Sliding the bars for any of the two wheels will rotate these joints. You can see this in action by viewing RVIZ as you sweep the sliders in the Joint State Publisher GUI."


#: ../../setup_guides/urdf/setup_urdf.rst:360
msgid "We won't be interacting much with this package for Nav2, but if you would like to know more about the joint state publisher, feel free to have a look at the official `Joint State Publisher Documentation <http://wiki.ros.org/joint_state_publisher>`_."
msgstr "We won't be interacting much with this package for Nav2, but if you would like to know more about the joint state publisher, feel free to have a look at the official `Joint State Publisher Documentation <http://wiki.ros.org/joint_state_publisher>`_."


#: ../../setup_guides/urdf/setup_urdf.rst:362
msgid "At this point, you may already decide to stop with this tutorial since we have already achieved our objective of creating a URDF for a simple differential drive robot. The robot state publisher is now publishing the transforms derived from the URDF. These transforms can now be used by other packages (such as Nav2) to get information regarding the shape and structure of your robot. However, to properly use this URDF in a simulation, we need physical properties so that the robot reacts to physical environments like a real robot would. The visualization fields are only for visualization, not collision, so your robot will drive straight through obstacles. We'll get into adding these properties in our URDF in the next section."
msgstr "At this point, you may already decide to stop with this tutorial since we have already achieved our objective of creating a URDF for a simple differential drive robot. The robot state publisher is now publishing the transforms derived from the URDF. These transforms can now be used by other packages (such as Nav2) to get information regarding the shape and structure of your robot. However, to properly use this URDF in a simulation, we need physical properties so that the robot reacts to physical environments like a real robot would. The visualization fields are only for visualization, not collision, so your robot will drive straight through obstacles. We'll get into adding these properties in our URDF in the next section."


#: ../../setup_guides/urdf/setup_urdf.rst:365
msgid "Adding Physical Properties"
msgstr "Adding Physical Properties"


#: ../../setup_guides/urdf/setup_urdf.rst:367
msgid "As an additional section to this guide, we will be modifying our current URDF to include some of our robot's kinematic properties. This information may be used by physics simulators such as Gazebo to model and simulate how our robot will act in the virtual environment."
msgstr "As an additional section to this guide, we will be modifying our current URDF to include some of our robot's kinematic properties. This information may be used by physics simulators such as Gazebo to model and simulate how our robot will act in the virtual environment."


#: ../../setup_guides/urdf/setup_urdf.rst:369
msgid "Let us first define macros containing the inertial properties of the geometric primitives we used in our project. Place the snippet below after our constants section in the URDF:"
msgstr "Let us first define macros containing the inertial properties of the geometric primitives we used in our project. Place the snippet below after our constants section in the URDF:"


#: ../../setup_guides/urdf/setup_urdf.rst:398
msgid "Let us start by adding collision areas to our ``base_link`` using the ``<collision>`` tag. We will also be using the box_inertia macro we defined before to add some inertial properties to our ``base_link``. Include the following code snippet within ``<link name=\"base_link\">`` tag of base_link in our URDF."
msgstr "Let us start by adding collision areas to our ``base_link`` using the ``<collision>`` tag. We will also be using the box_inertia macro we defined before to add some inertial properties to our ``base_link``. Include the following code snippet within ``<link name=\"base_link\">`` tag of base_link in our URDF."


#: ../../setup_guides/urdf/setup_urdf.rst:411
msgid "Next, let us do the same for our wheel macros. Include the following code snippet within the ``<link name=\"${prefix}_link\">`` tag of our wheel macros in our URDF."
msgstr "Next, let us do the same for our wheel macros. Include the following code snippet within the ``<link name=\"${prefix}_link\">`` tag of our wheel macros in our URDF."


#: ../../setup_guides/urdf/setup_urdf.rst:425
msgid "Lastly, let us add the similar properties to our spherical caster wheels. Include the following in the ``<link name=\"front_caster\">`` tag of our caster wheel in the URDF."
msgstr "Lastly, let us add the similar properties to our spherical caster wheels. Include the following in the ``<link name=\"front_caster\">`` tag of our caster wheel in the URDF."


#: ../../setup_guides/urdf/setup_urdf.rst:439
msgid "We did not add any inertial or collision properties to our ``base_footprint`` link since this is a virtual and non-physical link."
msgstr "We did not add any inertial or collision properties to our ``base_footprint`` link since this is a virtual and non-physical link."


#: ../../setup_guides/urdf/setup_urdf.rst:441
msgid "Build your project and then launch RViz using the same commands in the previous section."
msgstr "Build your project and then launch RViz using the same commands in the previous section."


#: ../../setup_guides/urdf/setup_urdf.rst:449
msgid "You can verify whether you have properly set up the collision areas by enabling ``Collision Enabled`` under ``RobotModel`` on the left pane (it may be easier to see if you also turn off ``Visual Enabled``). For this tutorial we defined a collision area which is similar to our visual properties. Note that this may not always be the case since you may opt for simpler collision areas based on how your robot looks."
msgstr "You can verify whether you have properly set up the collision areas by enabling ``Collision Enabled`` under ``RobotModel`` on the left pane (it may be easier to see if you also turn off ``Visual Enabled``). For this tutorial we defined a collision area which is similar to our visual properties. Note that this may not always be the case since you may opt for simpler collision areas based on how your robot looks."


#: ../../setup_guides/urdf/setup_urdf.rst:453
msgid "For now, we will have to stop here since we will need to set up a lot more components to actually start simulating our robot in Gazebo. We will be coming back to this project during the course of these setup guides, and we will eventually see our robot move in a virtual environment once we get to the simulation sections. The major components that are missing from this work are the simulation plugins required to mimic your robot controllers. We will introduce those and add them to this URDF in the appropriate section."
msgstr "For now, we will have to stop here since we will need to set up a lot more components to actually start simulating our robot in Gazebo. We will be coming back to this project during the course of these setup guides, and we will eventually see our robot move in a virtual environment once we get to the simulation sections. The major components that are missing from this work are the simulation plugins required to mimic your robot controllers. We will introduce those and add them to this URDF in the appropriate section."


#: ../../setup_guides/urdf/setup_urdf.rst:458
msgid "And that's it. In this tutorial, you have successfully created a URDF for a simple differential drive robot. You have also set up a ROS 2 project that launches a robot publisher node, which then uses your URDF to publish the robot's transforms. We have also used RViz to visualize our robot to verify whether our URDF is correct. Lastly, we have added in some physical properties to our URDF in order to prepare it for simulation."
msgstr "And that's it. In this tutorial, you have successfully created a URDF for a simple differential drive robot. You have also set up a ROS 2 project that launches a robot publisher node, which then uses your URDF to publish the robot's transforms. We have also used RViz to visualize our robot to verify whether our URDF is correct. Lastly, we have added in some physical properties to our URDF in order to prepare it for simulation."


#: ../../setup_guides/urdf/setup_urdf.rst:460
msgid "Feel free to use this tutorial as a template for your own robot. Remember that your main goal is to publish the correct transforms from your base_link up to your sensor_frames. Once these have been setup, then you may proceed to our other setup guides."
msgstr "Feel free to use this tutorial as a template for your own robot. Remember that your main goal is to publish the correct transforms from your base_link up to your sensor_frames. Once these have been setup, then you may proceed to our other setup guides."

